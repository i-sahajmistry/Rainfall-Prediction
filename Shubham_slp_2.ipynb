{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "7MhPzk45Ry1d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import ReLU\n",
        "from tensorflow.keras.activations import tanh\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "FE62XMFpR7nU",
        "outputId": "7d619ef5-aa17-4191-a86f-351145365125"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>JAN</th>\n",
              "      <th>FEB</th>\n",
              "      <th>MAR</th>\n",
              "      <th>APR</th>\n",
              "      <th>MAY</th>\n",
              "      <th>JUN</th>\n",
              "      <th>JUL</th>\n",
              "      <th>AUG</th>\n",
              "      <th>SEP</th>\n",
              "      <th>OCT</th>\n",
              "      <th>NOV</th>\n",
              "      <th>DEC</th>\n",
              "      <th>ANN</th>\n",
              "      <th>Jan-Feb</th>\n",
              "      <th>Mar-May</th>\n",
              "      <th>Jun-Sep</th>\n",
              "      <th>Oct-Dec</th>\n",
              "      <th>Anomaly</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1901</td>\n",
              "      <td>34.7</td>\n",
              "      <td>38.6</td>\n",
              "      <td>17.8</td>\n",
              "      <td>38.9</td>\n",
              "      <td>50.6</td>\n",
              "      <td>113.2</td>\n",
              "      <td>241.4</td>\n",
              "      <td>271.6</td>\n",
              "      <td>124.7</td>\n",
              "      <td>52.4</td>\n",
              "      <td>38.7</td>\n",
              "      <td>8.2</td>\n",
              "      <td>1030.8</td>\n",
              "      <td>73.2</td>\n",
              "      <td>107.3</td>\n",
              "      <td>751.0</td>\n",
              "      <td>99.3</td>\n",
              "      <td>-122.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1902</td>\n",
              "      <td>7.4</td>\n",
              "      <td>4.2</td>\n",
              "      <td>19.0</td>\n",
              "      <td>44.1</td>\n",
              "      <td>48.8</td>\n",
              "      <td>111.7</td>\n",
              "      <td>284.9</td>\n",
              "      <td>201.0</td>\n",
              "      <td>200.2</td>\n",
              "      <td>62.5</td>\n",
              "      <td>29.4</td>\n",
              "      <td>25.2</td>\n",
              "      <td>1038.4</td>\n",
              "      <td>11.6</td>\n",
              "      <td>111.9</td>\n",
              "      <td>797.8</td>\n",
              "      <td>117.2</td>\n",
              "      <td>-75.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1903</td>\n",
              "      <td>16.7</td>\n",
              "      <td>8.0</td>\n",
              "      <td>31.1</td>\n",
              "      <td>17.1</td>\n",
              "      <td>59.5</td>\n",
              "      <td>120.3</td>\n",
              "      <td>293.2</td>\n",
              "      <td>274.0</td>\n",
              "      <td>198.1</td>\n",
              "      <td>119.5</td>\n",
              "      <td>40.3</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1195.9</td>\n",
              "      <td>24.7</td>\n",
              "      <td>107.7</td>\n",
              "      <td>885.6</td>\n",
              "      <td>177.8</td>\n",
              "      <td>11.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1904</td>\n",
              "      <td>14.9</td>\n",
              "      <td>9.7</td>\n",
              "      <td>31.4</td>\n",
              "      <td>33.7</td>\n",
              "      <td>73.8</td>\n",
              "      <td>165.5</td>\n",
              "      <td>260.3</td>\n",
              "      <td>207.7</td>\n",
              "      <td>130.8</td>\n",
              "      <td>69.8</td>\n",
              "      <td>11.2</td>\n",
              "      <td>16.4</td>\n",
              "      <td>1025.1</td>\n",
              "      <td>24.5</td>\n",
              "      <td>138.8</td>\n",
              "      <td>764.3</td>\n",
              "      <td>97.4</td>\n",
              "      <td>-109.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1905</td>\n",
              "      <td>24.7</td>\n",
              "      <td>20.3</td>\n",
              "      <td>41.8</td>\n",
              "      <td>33.8</td>\n",
              "      <td>55.8</td>\n",
              "      <td>93.7</td>\n",
              "      <td>253.0</td>\n",
              "      <td>201.7</td>\n",
              "      <td>178.1</td>\n",
              "      <td>54.9</td>\n",
              "      <td>9.6</td>\n",
              "      <td>10.1</td>\n",
              "      <td>977.5</td>\n",
              "      <td>45.0</td>\n",
              "      <td>131.4</td>\n",
              "      <td>726.4</td>\n",
              "      <td>74.7</td>\n",
              "      <td>-147.22</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   YEAR   JAN   FEB   MAR   APR   MAY    JUN    JUL    AUG    SEP    OCT  \\\n",
              "0  1901  34.7  38.6  17.8  38.9  50.6  113.2  241.4  271.6  124.7   52.4   \n",
              "1  1902   7.4   4.2  19.0  44.1  48.8  111.7  284.9  201.0  200.2   62.5   \n",
              "2  1903  16.7   8.0  31.1  17.1  59.5  120.3  293.2  274.0  198.1  119.5   \n",
              "3  1904  14.9   9.7  31.4  33.7  73.8  165.5  260.3  207.7  130.8   69.8   \n",
              "4  1905  24.7  20.3  41.8  33.8  55.8   93.7  253.0  201.7  178.1   54.9   \n",
              "\n",
              "    NOV   DEC     ANN  Jan-Feb  Mar-May  Jun-Sep  Oct-Dec  Anomaly  \n",
              "0  38.7   8.2  1030.8     73.2    107.3    751.0     99.3  -122.62  \n",
              "1  29.4  25.2  1038.4     11.6    111.9    797.8    117.2   -75.82  \n",
              "2  40.3  18.0  1195.9     24.7    107.7    885.6    177.8    11.98  \n",
              "3  11.2  16.4  1025.1     24.5    138.8    764.3     97.4  -109.32  \n",
              "4   9.6  10.1   977.5     45.0    131.4    726.4     74.7  -147.22  "
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rain = pd.read_csv(\"./Data/Rainfall.csv\")\n",
        "rain.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "oKfrIAk81UYc"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "_cCB2xteGTjJ",
        "outputId": "7ef763f4-4e80-4e04-c089-0c7aeec7ae2e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>NINO_34</th>\n",
              "      <th>EastAsiaSurfacePressure</th>\n",
              "      <th>NorthAtlantaicSurfcePressure</th>\n",
              "      <th>NorthAtlanticOcean_SST</th>\n",
              "      <th>EQ_WIN</th>\n",
              "      <th>AO_oct</th>\n",
              "      <th>PDO_Jun</th>\n",
              "      <th>North_central_Pacific_zonal_Wind</th>\n",
              "      <th>SOI_Jun</th>\n",
              "      <th>SEI_Ocean_SST</th>\n",
              "      <th>ISMR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1950</td>\n",
              "      <td>0.365675</td>\n",
              "      <td>-0.386439</td>\n",
              "      <td>-2.546593</td>\n",
              "      <td>0.572334</td>\n",
              "      <td>-0.195580</td>\n",
              "      <td>-0.212910</td>\n",
              "      <td>-2.293911</td>\n",
              "      <td>-9.595640</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.039908</td>\n",
              "      <td>876.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1951</td>\n",
              "      <td>1.090162</td>\n",
              "      <td>-0.157037</td>\n",
              "      <td>-1.704145</td>\n",
              "      <td>-0.359634</td>\n",
              "      <td>-1.003503</td>\n",
              "      <td>-0.437170</td>\n",
              "      <td>-1.466423</td>\n",
              "      <td>-8.201849</td>\n",
              "      <td>0.2</td>\n",
              "      <td>-0.908400</td>\n",
              "      <td>738.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1952</td>\n",
              "      <td>-0.150832</td>\n",
              "      <td>1.845762</td>\n",
              "      <td>-2.880367</td>\n",
              "      <td>0.585410</td>\n",
              "      <td>-1.739785</td>\n",
              "      <td>-0.194460</td>\n",
              "      <td>-1.982165</td>\n",
              "      <td>-8.985010</td>\n",
              "      <td>0.7</td>\n",
              "      <td>-0.672092</td>\n",
              "      <td>792.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1953</td>\n",
              "      <td>0.347131</td>\n",
              "      <td>1.401160</td>\n",
              "      <td>-2.243482</td>\n",
              "      <td>-0.393405</td>\n",
              "      <td>-1.669605</td>\n",
              "      <td>0.512570</td>\n",
              "      <td>-0.226286</td>\n",
              "      <td>-9.018811</td>\n",
              "      <td>0.1</td>\n",
              "      <td>-0.672323</td>\n",
              "      <td>922.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1954</td>\n",
              "      <td>-1.080947</td>\n",
              "      <td>1.755364</td>\n",
              "      <td>-0.979263</td>\n",
              "      <td>0.021049</td>\n",
              "      <td>0.699660</td>\n",
              "      <td>0.099053</td>\n",
              "      <td>0.475692</td>\n",
              "      <td>-8.474271</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.012831</td>\n",
              "      <td>885.3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Year   NINO_34  EastAsiaSurfacePressure  NorthAtlantaicSurfcePressure  \\\n",
              "0  1950  0.365675                -0.386439                     -2.546593   \n",
              "1  1951  1.090162                -0.157037                     -1.704145   \n",
              "2  1952 -0.150832                 1.845762                     -2.880367   \n",
              "3  1953  0.347131                 1.401160                     -2.243482   \n",
              "4  1954 -1.080947                 1.755364                     -0.979263   \n",
              "\n",
              "   NorthAtlanticOcean_SST    EQ_WIN    AO_oct   PDO_Jun  \\\n",
              "0                0.572334 -0.195580 -0.212910 -2.293911   \n",
              "1               -0.359634 -1.003503 -0.437170 -1.466423   \n",
              "2                0.585410 -1.739785 -0.194460 -1.982165   \n",
              "3               -0.393405 -1.669605  0.512570 -0.226286   \n",
              "4                0.021049  0.699660  0.099053  0.475692   \n",
              "\n",
              "   North_central_Pacific_zonal_Wind  SOI_Jun  SEI_Ocean_SST   ISMR  \n",
              "0                         -9.595640      2.0       0.039908  876.9  \n",
              "1                         -8.201849      0.2      -0.908400  738.8  \n",
              "2                         -8.985010      0.7      -0.672092  792.9  \n",
              "3                         -9.018811      0.1      -0.672323  922.9  \n",
              "4                         -8.474271      0.1       0.012831  885.3  "
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictor = pd.read_csv(\"./Data/10_para_Data.csv\")\n",
        "predictor.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsCqe_IPGmEL",
        "outputId": "5bf53e2a-3b88-4a82-bd4f-b166e04a9840"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Year                                1950.000000\n",
              "NINO_34                                0.365675\n",
              "EastAsiaSurfacePressure               -0.386439\n",
              "NorthAtlantaicSurfcePressure          -2.546593\n",
              "NorthAtlanticOcean_SST                 0.572334\n",
              "EQ_WIN                                -0.195580\n",
              "AO_oct                                -0.212910\n",
              "PDO_Jun                               -2.293911\n",
              "North_central_Pacific_zonal_Wind      -9.595640\n",
              "SOI_Jun                                2.000000\n",
              "SEI_Ocean_SST                          0.039908\n",
              "ISMR                                 876.900000\n",
              "Name: 0, dtype: float64"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictor.iloc[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fwu9h_TuSK93",
        "outputId": "ac1cf7b5-adc4-42d9-be5e-1001831eef75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['./Data/slp\\\\01_slp.csv', './Data/slp\\\\02_slp.csv', './Data/slp\\\\03_slp.csv', './Data/slp\\\\04_slp.csv', './Data/slp\\\\05_slp.csv', './Data/slp\\\\06_slp.csv', './Data/slp\\\\07_slp.csv', './Data/slp\\\\08_slp.csv', './Data/slp\\\\09_slp.csv', './Data/slp\\\\10_slp.csv', './Data/slp\\\\11_slp.csv', './Data/slp\\\\12_slp.csv']\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "\n",
        "slp_path = \"./Data/slp/*\"\n",
        "\n",
        "slp_months = []\n",
        "for i in glob.glob(slp_path):\n",
        "  slp_months.append(i)\n",
        "  \n",
        "slp_months.sort()\n",
        "print(slp_months)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "DTXjIAx0W9DI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "878.0689655172414\n",
            "110.74300973923971\n",
            "108.34000942507068\n",
            "103.12401822180333\n",
            "86.94077913917687\n",
            "94.40032987747408\n",
            "109.83191957273013\n",
            "104.92342130065975\n",
            "107.50863964813068\n",
            "111.98437009110901\n",
            "96.92860508953818\n",
            "112.89546025761858\n",
            "119.31864593151116\n",
            "104.19454916745208\n",
            "119.80835689601005\n",
            "103.2492931196984\n",
            "103.43151115300032\n",
            "113.54461200125667\n",
            "80.68842287150487\n",
            "89.71960414703109\n",
            "100.69824065347157\n",
            "91.3026233113415\n",
            "101.81432610744581\n",
            "112.41713792020107\n",
            "103.72761545711593\n",
            "76.7935124096764\n",
            "104.80953502984605\n",
            "89.21850455545083\n",
            "114.27348413446434\n",
            "101.66627395538801\n",
            "102.93041156142004\n",
            "107.3605874960729\n",
            "82.86365064404649\n",
            "106.1875589066918\n",
            "100.44769085768144\n",
            "87.73798303487276\n",
            "112.62213320766573\n",
            "100.834904178448\n",
            "94.28644360666037\n",
            "91.51900722588752\n",
            "85.5741438894125\n",
            "119.53502984605717\n",
            "100.93740182218032\n",
            "109.9230285893811\n",
            "99.38854853911405\n",
            "96.57555765001571\n",
            "101.27906063462142\n",
            "112.45130380144516\n",
            "104.17177191328935\n",
            "100.92601319509897\n",
            "98.68245366006911\n",
            "100.51602262016965\n",
            "94.28644360666037\n",
            "90.8926327364122\n",
            "93.66006911718505\n",
            "84.28722902921773\n",
            "107.9527961043041\n",
            "88.15936223688344\n",
            "99.58215519949732\n",
            "101.27906063462142\n",
            "107.39475337731699\n",
            "99.96936852026388\n",
            "79.52678290920514\n",
            "103.76178133836005\n",
            "102.64569588438579\n",
            "93.8308985234056\n",
            "106.73421300659756\n",
            "89.07045240339303\n",
            "87.21410618912975\n",
            "98.44329249136035\n",
            "96.33639648130693\n",
            "91.4165095821552\n",
            "113.24850769714105\n",
            "109.11443606660383\n"
          ]
        }
      ],
      "source": [
        "#Here i am just storing rainfall data of Jun to sep from 1949 to 2014\n",
        "# index 47= 1948,\n",
        "import statistics\n",
        "lpa = statistics.mean(list(rain['Jun-Sep'][60:89]))\n",
        "print(lpa)\n",
        "rain_fall_data = list(rain['Jun-Sep'][47:2020])\n",
        "rain_data = []\n",
        "for i in range(len(rain_fall_data)):\n",
        "  temp = (rain_fall_data[i]/lpa)*100\n",
        "  rain_data.append(temp)\n",
        "  print(temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "0OJAucr4Snsf",
        "outputId": "b8ff0b78-5923-49a5-e6af-7059867fdd33"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>315</th>\n",
              "      <th>316</th>\n",
              "      <th>317</th>\n",
              "      <th>318</th>\n",
              "      <th>319</th>\n",
              "      <th>320</th>\n",
              "      <th>321</th>\n",
              "      <th>322</th>\n",
              "      <th>323</th>\n",
              "      <th>324</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1948</td>\n",
              "      <td>-163.789145</td>\n",
              "      <td>10.608730</td>\n",
              "      <td>188.665968</td>\n",
              "      <td>201.223873</td>\n",
              "      <td>127.864248</td>\n",
              "      <td>32.278713</td>\n",
              "      <td>24.352798</td>\n",
              "      <td>16.966268</td>\n",
              "      <td>12.275152</td>\n",
              "      <td>...</td>\n",
              "      <td>7.510439</td>\n",
              "      <td>-0.419870</td>\n",
              "      <td>-10.222766</td>\n",
              "      <td>5.329311</td>\n",
              "      <td>6.772387</td>\n",
              "      <td>-31.013266</td>\n",
              "      <td>44.577556</td>\n",
              "      <td>271.336094</td>\n",
              "      <td>253.514316</td>\n",
              "      <td>270.482500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1949</td>\n",
              "      <td>-145.274314</td>\n",
              "      <td>-396.000828</td>\n",
              "      <td>-160.813463</td>\n",
              "      <td>170.886043</td>\n",
              "      <td>345.893728</td>\n",
              "      <td>206.242886</td>\n",
              "      <td>118.891189</td>\n",
              "      <td>34.684408</td>\n",
              "      <td>6.571417</td>\n",
              "      <td>...</td>\n",
              "      <td>2.001589</td>\n",
              "      <td>-3.169931</td>\n",
              "      <td>-34.453357</td>\n",
              "      <td>-50.756383</td>\n",
              "      <td>-42.205152</td>\n",
              "      <td>-56.292135</td>\n",
              "      <td>217.152446</td>\n",
              "      <td>487.232273</td>\n",
              "      <td>639.986117</td>\n",
              "      <td>890.509599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1950</td>\n",
              "      <td>-108.747946</td>\n",
              "      <td>-101.054661</td>\n",
              "      <td>-279.047167</td>\n",
              "      <td>-285.888493</td>\n",
              "      <td>-75.985850</td>\n",
              "      <td>91.758328</td>\n",
              "      <td>73.875747</td>\n",
              "      <td>-7.529032</td>\n",
              "      <td>-3.538690</td>\n",
              "      <td>...</td>\n",
              "      <td>-10.827330</td>\n",
              "      <td>-13.938852</td>\n",
              "      <td>-34.146533</td>\n",
              "      <td>-27.083470</td>\n",
              "      <td>51.104358</td>\n",
              "      <td>84.588724</td>\n",
              "      <td>9.822490</td>\n",
              "      <td>125.580296</td>\n",
              "      <td>386.674472</td>\n",
              "      <td>503.094255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1951</td>\n",
              "      <td>4.037088</td>\n",
              "      <td>34.271511</td>\n",
              "      <td>-52.911547</td>\n",
              "      <td>-255.556889</td>\n",
              "      <td>-254.734019</td>\n",
              "      <td>-83.716892</td>\n",
              "      <td>-48.382981</td>\n",
              "      <td>-90.506266</td>\n",
              "      <td>-19.968988</td>\n",
              "      <td>...</td>\n",
              "      <td>-11.054075</td>\n",
              "      <td>-9.903818</td>\n",
              "      <td>-17.248095</td>\n",
              "      <td>-7.619115</td>\n",
              "      <td>58.900744</td>\n",
              "      <td>79.077250</td>\n",
              "      <td>44.820659</td>\n",
              "      <td>125.627415</td>\n",
              "      <td>265.421908</td>\n",
              "      <td>269.103532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1952</td>\n",
              "      <td>152.176126</td>\n",
              "      <td>114.775173</td>\n",
              "      <td>-102.570177</td>\n",
              "      <td>-59.142765</td>\n",
              "      <td>-17.956553</td>\n",
              "      <td>-42.883823</td>\n",
              "      <td>-76.263169</td>\n",
              "      <td>-94.947306</td>\n",
              "      <td>-36.176752</td>\n",
              "      <td>...</td>\n",
              "      <td>-31.225889</td>\n",
              "      <td>-30.600595</td>\n",
              "      <td>-34.589282</td>\n",
              "      <td>-16.766148</td>\n",
              "      <td>21.897693</td>\n",
              "      <td>71.644205</td>\n",
              "      <td>177.624797</td>\n",
              "      <td>323.772373</td>\n",
              "      <td>258.057407</td>\n",
              "      <td>218.790361</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 325 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   year           1           2           3           4           5  \\\n",
              "0  1948 -163.789145   10.608730  188.665968  201.223873  127.864248   \n",
              "1  1949 -145.274314 -396.000828 -160.813463  170.886043  345.893728   \n",
              "2  1950 -108.747946 -101.054661 -279.047167 -285.888493  -75.985850   \n",
              "3  1951    4.037088   34.271511  -52.911547 -255.556889 -254.734019   \n",
              "4  1952  152.176126  114.775173 -102.570177  -59.142765  -17.956553   \n",
              "\n",
              "            6           7          8          9  ...        315        316  \\\n",
              "0   32.278713   24.352798  16.966268  12.275152  ...   7.510439  -0.419870   \n",
              "1  206.242886  118.891189  34.684408   6.571417  ...   2.001589  -3.169931   \n",
              "2   91.758328   73.875747  -7.529032  -3.538690  ... -10.827330 -13.938852   \n",
              "3  -83.716892  -48.382981 -90.506266 -19.968988  ... -11.054075  -9.903818   \n",
              "4  -42.883823  -76.263169 -94.947306 -36.176752  ... -31.225889 -30.600595   \n",
              "\n",
              "         317        318        319        320         321         322  \\\n",
              "0 -10.222766   5.329311   6.772387 -31.013266   44.577556  271.336094   \n",
              "1 -34.453357 -50.756383 -42.205152 -56.292135  217.152446  487.232273   \n",
              "2 -34.146533 -27.083470  51.104358  84.588724    9.822490  125.580296   \n",
              "3 -17.248095  -7.619115  58.900744  79.077250   44.820659  125.627415   \n",
              "4 -34.589282 -16.766148  21.897693  71.644205  177.624797  323.772373   \n",
              "\n",
              "          323         324  \n",
              "0  253.514316  270.482500  \n",
              "1  639.986117  890.509599  \n",
              "2  386.674472  503.094255  \n",
              "3  265.421908  269.103532  \n",
              "4  258.057407  218.790361  \n",
              "\n",
              "[5 rows x 325 columns]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from scipy.stats import pearsonr\n",
        "correlation = []\n",
        "\n",
        "# chacking for each MONTH\n",
        "month_path = slp_months[1] #0th in dex means january\n",
        "# reading month data\n",
        "month_data = pd.read_csv(month_path)\n",
        "month_data.head()\n",
        "# len(month_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "TggTzCDmSR-T"
      },
      "outputs": [],
      "source": [
        "# define encoder\n",
        "def get_model_1(n_inputs=324):\n",
        "  visible = Input(shape=(n_inputs,))\n",
        "  # encoder level 1\n",
        "  e = Dense(n_inputs)(visible)\n",
        "  # e = BatchNormalization()(e)\n",
        "  e = ReLU()(e)\n",
        "  \n",
        "\n",
        "  # bottleneck\n",
        "  # n_bottleneck = round(float(n_inputs) / 2.0)\n",
        "  bottleneck = Dense(97)(e)\n",
        "  # e = BatchNormalization()(bottleneck)\n",
        "\n",
        "  # decoder level 1\n",
        "  # d = Dense(n_inputs*2)(bottleneck)\n",
        "  # d = BatchNormalization()(d)\n",
        "  # d = LeakyReLU()(d)\n",
        "  # output layer\n",
        "  output = Dense(n_inputs, activation='linear')(bottleneck)\n",
        "  # define autoencoder model\n",
        "  model = Model(inputs=visible, outputs=output)\n",
        "  # compile autoencoder model\n",
        "  model.compile(optimizer='adam', loss='mse')\n",
        "  # plot the autoencoder\n",
        "  # plot_model(model, 'autoencoder_compress.png', show_shapes=True)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJoOXleUSWfq",
        "outputId": "445be784-a13a-4ffb-ffb6-f6488a5ff73a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(636, 324)"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "month_data.iloc[0]\n",
        "# To extract only the relavant infromation from data frame for autoencoder\n",
        "def get_feature(data):\n",
        "  new_data = []\n",
        "  for i in range(len(data)):\n",
        "    d = data.iloc[i]\n",
        "    new_data.append(list(d[1:]))\n",
        "  # print(new_data)\n",
        "  return np.array(new_data)\n",
        "\n",
        "# to combine all the features together\n",
        "combine = []\n",
        "for i in range(12):\n",
        "  # chacking for each MONTH\n",
        "  month_path = slp_months[i] #0th in dex means january\n",
        "  # reading month data\n",
        "  month_data = pd.read_csv(month_path)\n",
        "  feature = get_feature(month_data)\n",
        "  feature = feature[0:53]  #Here i am using anly data from 1948 to 2000\n",
        "  for i in feature:\n",
        "    combine.append(i)\n",
        "x = np.array(combine)\n",
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "SD5AxjEXS0_c"
      },
      "outputs": [],
      "source": [
        "# define encoder\n",
        "def get_model_1(n_inputs=324):\n",
        "  visible = Input(shape=(n_inputs,))\n",
        "  # encoder level 1\n",
        "  e = Dense(n_inputs)(visible)\n",
        "  # e = BatchNormalization()(e)\n",
        "  e = ReLU()(e)\n",
        "  \n",
        "\n",
        "  # bottleneck\n",
        "  # n_bottleneck = round(float(n_inputs) / 2.0)\n",
        "  bottleneck = Dense(97)(e)\n",
        "  # e = BatchNormalization()(bottleneck)\n",
        "\n",
        "  # decoder level 1\n",
        "  # d = Dense(n_inputs*2)(bottleneck)\n",
        "  # d = BatchNormalization()(d)\n",
        "  # d = LeakyReLU()(d)\n",
        "  # output layer\n",
        "  output = Dense(n_inputs, activation='linear')(bottleneck)\n",
        "  # define autoencoder model\n",
        "  model = Model(inputs=visible, outputs=output)\n",
        "  # compile autoencoder model\n",
        "  model.compile(optimizer='adam', loss='mse')\n",
        "  # plot the autoencoder\n",
        "  # plot_model(model, 'autoencoder_compress.png', show_shapes=True)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWuOJiwaS3_Z",
        "outputId": "3592939d-c50f-4cc5-c866-70b86fcc27b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 324)]             0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 324)               105300    \n",
            "                                                                 \n",
            " re_lu_9 (ReLU)              (None, 324)               0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 97)                31525     \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 324)               31752     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 168,577\n",
            "Trainable params: 168,577\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_1 = get_model_1()\n",
        "model_1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVmrlbpcS9wx",
        "outputId": "1d609147-b619-47ef-9c3f-227eef2672d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/800\n",
            "40/40 - 0s - loss: 10848.7607 - val_loss: 6481.9526 - 345ms/epoch - 9ms/step\n",
            "Epoch 2/800\n",
            "40/40 - 0s - loss: 5446.8960 - val_loss: 4263.8984 - 69ms/epoch - 2ms/step\n",
            "Epoch 3/800\n",
            "40/40 - 0s - loss: 3758.1482 - val_loss: 3101.6677 - 64ms/epoch - 2ms/step\n",
            "Epoch 4/800\n",
            "40/40 - 0s - loss: 2875.0691 - val_loss: 2456.5217 - 70ms/epoch - 2ms/step\n",
            "Epoch 5/800\n",
            "40/40 - 0s - loss: 2330.2480 - val_loss: 2029.5629 - 66ms/epoch - 2ms/step\n",
            "Epoch 6/800\n",
            "40/40 - 0s - loss: 1965.1333 - val_loss: 1735.5861 - 66ms/epoch - 2ms/step\n",
            "Epoch 7/800\n",
            "40/40 - 0s - loss: 1720.1460 - val_loss: 1529.6947 - 67ms/epoch - 2ms/step\n",
            "Epoch 8/800\n",
            "40/40 - 0s - loss: 1505.4967 - val_loss: 1341.5588 - 68ms/epoch - 2ms/step\n",
            "Epoch 9/800\n",
            "40/40 - 0s - loss: 1345.2627 - val_loss: 1212.1031 - 67ms/epoch - 2ms/step\n",
            "Epoch 10/800\n",
            "40/40 - 0s - loss: 1223.3984 - val_loss: 1109.9922 - 72ms/epoch - 2ms/step\n",
            "Epoch 11/800\n",
            "40/40 - 0s - loss: 1129.7435 - val_loss: 1024.2832 - 65ms/epoch - 2ms/step\n",
            "Epoch 12/800\n",
            "40/40 - 0s - loss: 1044.8667 - val_loss: 957.2331 - 68ms/epoch - 2ms/step\n",
            "Epoch 13/800\n",
            "40/40 - 0s - loss: 978.6294 - val_loss: 892.1714 - 64ms/epoch - 2ms/step\n",
            "Epoch 14/800\n",
            "40/40 - 0s - loss: 917.6551 - val_loss: 838.4573 - 64ms/epoch - 2ms/step\n",
            "Epoch 15/800\n",
            "40/40 - 0s - loss: 863.9927 - val_loss: 799.9382 - 65ms/epoch - 2ms/step\n",
            "Epoch 16/800\n",
            "40/40 - 0s - loss: 818.1878 - val_loss: 749.0579 - 66ms/epoch - 2ms/step\n",
            "Epoch 17/800\n",
            "40/40 - 0s - loss: 776.5015 - val_loss: 717.8341 - 67ms/epoch - 2ms/step\n",
            "Epoch 18/800\n",
            "40/40 - 0s - loss: 739.5060 - val_loss: 676.9905 - 66ms/epoch - 2ms/step\n",
            "Epoch 19/800\n",
            "40/40 - 0s - loss: 708.3345 - val_loss: 656.3315 - 107ms/epoch - 3ms/step\n",
            "Epoch 20/800\n",
            "40/40 - 0s - loss: 677.8430 - val_loss: 622.5946 - 90ms/epoch - 2ms/step\n",
            "Epoch 21/800\n",
            "40/40 - 0s - loss: 656.6348 - val_loss: 607.5474 - 80ms/epoch - 2ms/step\n",
            "Epoch 22/800\n",
            "40/40 - 0s - loss: 633.3416 - val_loss: 594.7761 - 67ms/epoch - 2ms/step\n",
            "Epoch 23/800\n",
            "40/40 - 0s - loss: 615.9439 - val_loss: 564.3132 - 74ms/epoch - 2ms/step\n",
            "Epoch 24/800\n",
            "40/40 - 0s - loss: 588.8636 - val_loss: 545.4722 - 68ms/epoch - 2ms/step\n",
            "Epoch 25/800\n",
            "40/40 - 0s - loss: 569.2670 - val_loss: 528.2237 - 64ms/epoch - 2ms/step\n",
            "Epoch 26/800\n",
            "40/40 - 0s - loss: 552.9451 - val_loss: 512.4418 - 69ms/epoch - 2ms/step\n",
            "Epoch 27/800\n",
            "40/40 - 0s - loss: 548.1292 - val_loss: 506.1764 - 72ms/epoch - 2ms/step\n",
            "Epoch 28/800\n",
            "40/40 - 0s - loss: 529.1757 - val_loss: 488.5866 - 67ms/epoch - 2ms/step\n",
            "Epoch 29/800\n",
            "40/40 - 0s - loss: 520.6686 - val_loss: 486.7339 - 66ms/epoch - 2ms/step\n",
            "Epoch 30/800\n",
            "40/40 - 0s - loss: 514.1031 - val_loss: 473.5330 - 65ms/epoch - 2ms/step\n",
            "Epoch 31/800\n",
            "40/40 - 0s - loss: 498.6712 - val_loss: 465.3050 - 65ms/epoch - 2ms/step\n",
            "Epoch 32/800\n",
            "40/40 - 0s - loss: 487.1077 - val_loss: 450.6320 - 66ms/epoch - 2ms/step\n",
            "Epoch 33/800\n",
            "40/40 - 0s - loss: 475.1353 - val_loss: 444.4064 - 66ms/epoch - 2ms/step\n",
            "Epoch 34/800\n",
            "40/40 - 0s - loss: 464.9488 - val_loss: 432.6983 - 66ms/epoch - 2ms/step\n",
            "Epoch 35/800\n",
            "40/40 - 0s - loss: 450.1216 - val_loss: 410.7994 - 66ms/epoch - 2ms/step\n",
            "Epoch 36/800\n",
            "40/40 - 0s - loss: 442.8852 - val_loss: 426.3424 - 67ms/epoch - 2ms/step\n",
            "Epoch 37/800\n",
            "40/40 - 0s - loss: 438.6603 - val_loss: 410.3044 - 68ms/epoch - 2ms/step\n",
            "Epoch 38/800\n",
            "40/40 - 0s - loss: 440.6591 - val_loss: 447.1264 - 65ms/epoch - 2ms/step\n",
            "Epoch 39/800\n",
            "40/40 - 0s - loss: 455.4728 - val_loss: 426.4562 - 66ms/epoch - 2ms/step\n",
            "Epoch 40/800\n",
            "40/40 - 0s - loss: 434.2221 - val_loss: 395.4386 - 67ms/epoch - 2ms/step\n",
            "Epoch 41/800\n",
            "40/40 - 0s - loss: 414.4448 - val_loss: 382.1237 - 68ms/epoch - 2ms/step\n",
            "Epoch 42/800\n",
            "40/40 - 0s - loss: 410.5909 - val_loss: 375.5444 - 67ms/epoch - 2ms/step\n",
            "Epoch 43/800\n",
            "40/40 - 0s - loss: 395.3883 - val_loss: 375.9495 - 68ms/epoch - 2ms/step\n",
            "Epoch 44/800\n",
            "40/40 - 0s - loss: 391.8649 - val_loss: 365.5609 - 67ms/epoch - 2ms/step\n",
            "Epoch 45/800\n",
            "40/40 - 0s - loss: 384.7878 - val_loss: 361.5880 - 65ms/epoch - 2ms/step\n",
            "Epoch 46/800\n",
            "40/40 - 0s - loss: 393.9309 - val_loss: 367.4760 - 65ms/epoch - 2ms/step\n",
            "Epoch 47/800\n",
            "40/40 - 0s - loss: 386.1652 - val_loss: 366.8357 - 66ms/epoch - 2ms/step\n",
            "Epoch 48/800\n",
            "40/40 - 0s - loss: 390.9554 - val_loss: 356.0129 - 65ms/epoch - 2ms/step\n",
            "Epoch 49/800\n",
            "40/40 - 0s - loss: 391.6239 - val_loss: 371.4499 - 64ms/epoch - 2ms/step\n",
            "Epoch 50/800\n",
            "40/40 - 0s - loss: 395.5250 - val_loss: 369.9179 - 67ms/epoch - 2ms/step\n",
            "Epoch 51/800\n",
            "40/40 - 0s - loss: 390.7072 - val_loss: 359.0814 - 67ms/epoch - 2ms/step\n",
            "Epoch 52/800\n",
            "40/40 - 0s - loss: 381.9828 - val_loss: 356.4088 - 67ms/epoch - 2ms/step\n",
            "Epoch 53/800\n",
            "40/40 - 0s - loss: 369.2966 - val_loss: 345.9694 - 65ms/epoch - 2ms/step\n",
            "Epoch 54/800\n",
            "40/40 - 0s - loss: 356.1975 - val_loss: 340.2791 - 68ms/epoch - 2ms/step\n",
            "Epoch 55/800\n",
            "40/40 - 0s - loss: 360.7767 - val_loss: 328.2466 - 66ms/epoch - 2ms/step\n",
            "Epoch 56/800\n",
            "40/40 - 0s - loss: 387.2227 - val_loss: 386.6992 - 69ms/epoch - 2ms/step\n",
            "Epoch 57/800\n",
            "40/40 - 0s - loss: 376.3945 - val_loss: 335.0635 - 66ms/epoch - 2ms/step\n",
            "Epoch 58/800\n",
            "40/40 - 0s - loss: 357.1696 - val_loss: 321.7963 - 66ms/epoch - 2ms/step\n",
            "Epoch 59/800\n",
            "40/40 - 0s - loss: 344.0899 - val_loss: 307.0065 - 68ms/epoch - 2ms/step\n",
            "Epoch 60/800\n",
            "40/40 - 0s - loss: 327.0255 - val_loss: 299.7224 - 66ms/epoch - 2ms/step\n",
            "Epoch 61/800\n",
            "40/40 - 0s - loss: 312.8772 - val_loss: 291.4194 - 70ms/epoch - 2ms/step\n",
            "Epoch 62/800\n",
            "40/40 - 0s - loss: 308.9648 - val_loss: 293.3716 - 68ms/epoch - 2ms/step\n",
            "Epoch 63/800\n",
            "40/40 - 0s - loss: 310.7856 - val_loss: 284.5899 - 66ms/epoch - 2ms/step\n",
            "Epoch 64/800\n",
            "40/40 - 0s - loss: 300.7369 - val_loss: 277.9582 - 65ms/epoch - 2ms/step\n",
            "Epoch 65/800\n",
            "40/40 - 0s - loss: 296.7949 - val_loss: 275.4804 - 66ms/epoch - 2ms/step\n",
            "Epoch 66/800\n",
            "40/40 - 0s - loss: 303.2949 - val_loss: 283.1110 - 66ms/epoch - 2ms/step\n",
            "Epoch 67/800\n",
            "40/40 - 0s - loss: 301.5201 - val_loss: 285.3664 - 66ms/epoch - 2ms/step\n",
            "Epoch 68/800\n",
            "40/40 - 0s - loss: 302.1910 - val_loss: 281.7224 - 65ms/epoch - 2ms/step\n",
            "Epoch 69/800\n",
            "40/40 - 0s - loss: 307.2399 - val_loss: 282.7310 - 66ms/epoch - 2ms/step\n",
            "Epoch 70/800\n",
            "40/40 - 0s - loss: 313.4839 - val_loss: 304.8453 - 68ms/epoch - 2ms/step\n",
            "Epoch 71/800\n",
            "40/40 - 0s - loss: 321.9555 - val_loss: 300.3445 - 67ms/epoch - 2ms/step\n",
            "Epoch 72/800\n",
            "40/40 - 0s - loss: 350.8341 - val_loss: 325.3857 - 68ms/epoch - 2ms/step\n",
            "Epoch 73/800\n",
            "40/40 - 0s - loss: 337.6936 - val_loss: 311.0987 - 64ms/epoch - 2ms/step\n",
            "Epoch 74/800\n",
            "40/40 - 0s - loss: 325.8952 - val_loss: 301.3387 - 65ms/epoch - 2ms/step\n",
            "Epoch 75/800\n",
            "40/40 - 0s - loss: 320.9940 - val_loss: 293.0658 - 67ms/epoch - 2ms/step\n",
            "Epoch 76/800\n",
            "40/40 - 0s - loss: 306.1255 - val_loss: 297.7651 - 66ms/epoch - 2ms/step\n",
            "Epoch 77/800\n",
            "40/40 - 0s - loss: 294.9235 - val_loss: 274.3556 - 68ms/epoch - 2ms/step\n",
            "Epoch 78/800\n",
            "40/40 - 0s - loss: 299.2460 - val_loss: 284.2643 - 61ms/epoch - 2ms/step\n",
            "Epoch 79/800\n",
            "40/40 - 0s - loss: 295.6918 - val_loss: 286.1089 - 69ms/epoch - 2ms/step\n",
            "Epoch 80/800\n",
            "40/40 - 0s - loss: 292.4399 - val_loss: 272.8713 - 66ms/epoch - 2ms/step\n",
            "Epoch 81/800\n",
            "40/40 - 0s - loss: 296.2145 - val_loss: 294.5585 - 68ms/epoch - 2ms/step\n",
            "Epoch 82/800\n",
            "40/40 - 0s - loss: 314.5199 - val_loss: 289.9330 - 67ms/epoch - 2ms/step\n",
            "Epoch 83/800\n",
            "40/40 - 0s - loss: 305.4494 - val_loss: 286.1414 - 68ms/epoch - 2ms/step\n",
            "Epoch 84/800\n",
            "40/40 - 0s - loss: 297.1777 - val_loss: 304.6667 - 67ms/epoch - 2ms/step\n",
            "Epoch 85/800\n",
            "40/40 - 0s - loss: 313.9765 - val_loss: 296.1101 - 70ms/epoch - 2ms/step\n",
            "Epoch 86/800\n",
            "40/40 - 0s - loss: 301.7336 - val_loss: 290.0043 - 65ms/epoch - 2ms/step\n",
            "Epoch 87/800\n",
            "40/40 - 0s - loss: 325.1454 - val_loss: 311.4497 - 66ms/epoch - 2ms/step\n",
            "Epoch 88/800\n",
            "40/40 - 0s - loss: 343.0587 - val_loss: 322.9668 - 64ms/epoch - 2ms/step\n",
            "Epoch 89/800\n",
            "40/40 - 0s - loss: 320.2584 - val_loss: 328.7193 - 64ms/epoch - 2ms/step\n",
            "Epoch 90/800\n",
            "40/40 - 0s - loss: 345.4194 - val_loss: 335.0729 - 65ms/epoch - 2ms/step\n",
            "Epoch 91/800\n",
            "40/40 - 0s - loss: 321.8409 - val_loss: 293.5700 - 65ms/epoch - 2ms/step\n",
            "Epoch 92/800\n",
            "40/40 - 0s - loss: 290.5673 - val_loss: 273.1988 - 68ms/epoch - 2ms/step\n",
            "Epoch 93/800\n",
            "40/40 - 0s - loss: 288.2209 - val_loss: 261.0736 - 65ms/epoch - 2ms/step\n",
            "Epoch 94/800\n",
            "40/40 - 0s - loss: 276.8106 - val_loss: 252.6483 - 65ms/epoch - 2ms/step\n",
            "Epoch 95/800\n",
            "40/40 - 0s - loss: 266.0571 - val_loss: 251.9704 - 60ms/epoch - 1ms/step\n",
            "Epoch 96/800\n",
            "40/40 - 0s - loss: 260.2337 - val_loss: 233.2400 - 72ms/epoch - 2ms/step\n",
            "Epoch 97/800\n",
            "40/40 - 0s - loss: 260.0858 - val_loss: 250.3323 - 66ms/epoch - 2ms/step\n",
            "Epoch 98/800\n",
            "40/40 - 0s - loss: 258.3914 - val_loss: 239.2013 - 67ms/epoch - 2ms/step\n",
            "Epoch 99/800\n",
            "40/40 - 0s - loss: 260.6175 - val_loss: 246.2083 - 67ms/epoch - 2ms/step\n",
            "Epoch 100/800\n",
            "40/40 - 0s - loss: 256.9489 - val_loss: 239.5220 - 69ms/epoch - 2ms/step\n",
            "Epoch 101/800\n",
            "40/40 - 0s - loss: 255.7085 - val_loss: 237.4889 - 67ms/epoch - 2ms/step\n",
            "Epoch 102/800\n",
            "40/40 - 0s - loss: 261.3105 - val_loss: 245.6342 - 70ms/epoch - 2ms/step\n",
            "Epoch 103/800\n",
            "40/40 - 0s - loss: 266.5980 - val_loss: 253.2819 - 70ms/epoch - 2ms/step\n",
            "Epoch 104/800\n",
            "40/40 - 0s - loss: 280.3828 - val_loss: 262.0414 - 70ms/epoch - 2ms/step\n",
            "Epoch 105/800\n",
            "40/40 - 0s - loss: 288.6517 - val_loss: 270.6554 - 70ms/epoch - 2ms/step\n",
            "Epoch 106/800\n",
            "40/40 - 0s - loss: 280.8728 - val_loss: 270.3297 - 70ms/epoch - 2ms/step\n",
            "Epoch 107/800\n",
            "40/40 - 0s - loss: 282.2920 - val_loss: 270.1737 - 74ms/epoch - 2ms/step\n",
            "Epoch 108/800\n",
            "40/40 - 0s - loss: 295.0037 - val_loss: 264.9305 - 70ms/epoch - 2ms/step\n",
            "Epoch 109/800\n",
            "40/40 - 0s - loss: 312.0690 - val_loss: 294.0360 - 68ms/epoch - 2ms/step\n",
            "Epoch 110/800\n",
            "40/40 - 0s - loss: 291.7472 - val_loss: 261.6423 - 65ms/epoch - 2ms/step\n",
            "Epoch 111/800\n",
            "40/40 - 0s - loss: 269.1082 - val_loss: 248.1655 - 67ms/epoch - 2ms/step\n",
            "Epoch 112/800\n",
            "40/40 - 0s - loss: 287.5224 - val_loss: 264.8500 - 66ms/epoch - 2ms/step\n",
            "Epoch 113/800\n",
            "40/40 - 0s - loss: 292.3408 - val_loss: 273.4718 - 68ms/epoch - 2ms/step\n",
            "Epoch 114/800\n",
            "40/40 - 0s - loss: 287.0144 - val_loss: 275.4136 - 68ms/epoch - 2ms/step\n",
            "Epoch 115/800\n",
            "40/40 - 0s - loss: 283.5107 - val_loss: 257.4051 - 67ms/epoch - 2ms/step\n",
            "Epoch 116/800\n",
            "40/40 - 0s - loss: 265.7510 - val_loss: 248.3155 - 67ms/epoch - 2ms/step\n",
            "Epoch 117/800\n",
            "40/40 - 0s - loss: 257.0719 - val_loss: 242.7512 - 65ms/epoch - 2ms/step\n",
            "Epoch 118/800\n",
            "40/40 - 0s - loss: 257.8996 - val_loss: 248.5603 - 68ms/epoch - 2ms/step\n",
            "Epoch 119/800\n",
            "40/40 - 0s - loss: 253.6663 - val_loss: 240.2184 - 66ms/epoch - 2ms/step\n",
            "Epoch 120/800\n",
            "40/40 - 0s - loss: 251.2651 - val_loss: 228.0573 - 68ms/epoch - 2ms/step\n",
            "Epoch 121/800\n",
            "40/40 - 0s - loss: 249.4251 - val_loss: 238.1311 - 68ms/epoch - 2ms/step\n",
            "Epoch 122/800\n",
            "40/40 - 0s - loss: 254.1333 - val_loss: 241.4019 - 70ms/epoch - 2ms/step\n",
            "Epoch 123/800\n",
            "40/40 - 0s - loss: 250.1635 - val_loss: 274.5707 - 66ms/epoch - 2ms/step\n",
            "Epoch 124/800\n",
            "40/40 - 0s - loss: 264.4077 - val_loss: 227.3260 - 65ms/epoch - 2ms/step\n",
            "Epoch 125/800\n",
            "40/40 - 0s - loss: 246.9986 - val_loss: 246.7905 - 76ms/epoch - 2ms/step\n",
            "Epoch 126/800\n",
            "40/40 - 0s - loss: 247.3498 - val_loss: 248.1127 - 80ms/epoch - 2ms/step\n",
            "Epoch 127/800\n",
            "40/40 - 0s - loss: 256.1082 - val_loss: 230.1230 - 68ms/epoch - 2ms/step\n",
            "Epoch 128/800\n",
            "40/40 - 0s - loss: 254.9910 - val_loss: 229.3387 - 68ms/epoch - 2ms/step\n",
            "Epoch 129/800\n",
            "40/40 - 0s - loss: 257.0516 - val_loss: 259.0378 - 68ms/epoch - 2ms/step\n",
            "Epoch 130/800\n",
            "40/40 - 0s - loss: 292.0726 - val_loss: 315.4671 - 65ms/epoch - 2ms/step\n",
            "Epoch 131/800\n",
            "40/40 - 0s - loss: 307.7051 - val_loss: 283.9533 - 66ms/epoch - 2ms/step\n",
            "Epoch 132/800\n",
            "40/40 - 0s - loss: 294.3689 - val_loss: 272.7321 - 69ms/epoch - 2ms/step\n",
            "Epoch 133/800\n",
            "40/40 - 0s - loss: 271.2153 - val_loss: 256.7916 - 67ms/epoch - 2ms/step\n",
            "Epoch 134/800\n",
            "40/40 - 0s - loss: 265.9409 - val_loss: 238.4977 - 66ms/epoch - 2ms/step\n",
            "Epoch 135/800\n",
            "40/40 - 0s - loss: 254.4185 - val_loss: 224.7363 - 65ms/epoch - 2ms/step\n",
            "Epoch 136/800\n",
            "40/40 - 0s - loss: 244.6981 - val_loss: 232.0241 - 68ms/epoch - 2ms/step\n",
            "Epoch 137/800\n",
            "40/40 - 0s - loss: 253.4818 - val_loss: 250.7847 - 67ms/epoch - 2ms/step\n",
            "Epoch 138/800\n",
            "40/40 - 0s - loss: 260.0561 - val_loss: 249.2848 - 69ms/epoch - 2ms/step\n",
            "Epoch 139/800\n",
            "40/40 - 0s - loss: 280.7778 - val_loss: 257.4622 - 85ms/epoch - 2ms/step\n",
            "Epoch 140/800\n",
            "40/40 - 0s - loss: 270.0879 - val_loss: 240.8993 - 83ms/epoch - 2ms/step\n",
            "Epoch 141/800\n",
            "40/40 - 0s - loss: 255.2748 - val_loss: 232.6594 - 90ms/epoch - 2ms/step\n",
            "Epoch 142/800\n",
            "40/40 - 0s - loss: 253.7005 - val_loss: 242.9658 - 81ms/epoch - 2ms/step\n",
            "Epoch 143/800\n",
            "40/40 - 0s - loss: 284.2912 - val_loss: 291.2795 - 79ms/epoch - 2ms/step\n",
            "Epoch 144/800\n",
            "40/40 - 0s - loss: 313.3747 - val_loss: 330.0664 - 87ms/epoch - 2ms/step\n",
            "Epoch 145/800\n",
            "40/40 - 0s - loss: 299.0456 - val_loss: 278.9358 - 88ms/epoch - 2ms/step\n",
            "Epoch 146/800\n",
            "40/40 - 0s - loss: 285.5609 - val_loss: 247.6116 - 74ms/epoch - 2ms/step\n",
            "Epoch 147/800\n",
            "40/40 - 0s - loss: 265.3123 - val_loss: 235.9012 - 69ms/epoch - 2ms/step\n",
            "Epoch 148/800\n",
            "40/40 - 0s - loss: 245.1952 - val_loss: 215.5714 - 79ms/epoch - 2ms/step\n",
            "Epoch 149/800\n",
            "40/40 - 0s - loss: 235.9109 - val_loss: 213.2348 - 76ms/epoch - 2ms/step\n",
            "Epoch 150/800\n",
            "40/40 - 0s - loss: 234.0283 - val_loss: 215.2471 - 83ms/epoch - 2ms/step\n",
            "Epoch 151/800\n",
            "40/40 - 0s - loss: 225.7823 - val_loss: 205.3053 - 77ms/epoch - 2ms/step\n",
            "Epoch 152/800\n",
            "40/40 - 0s - loss: 219.7263 - val_loss: 203.9651 - 75ms/epoch - 2ms/step\n",
            "Epoch 153/800\n",
            "40/40 - 0s - loss: 221.2316 - val_loss: 212.8844 - 77ms/epoch - 2ms/step\n",
            "Epoch 154/800\n",
            "40/40 - 0s - loss: 220.0908 - val_loss: 197.2953 - 68ms/epoch - 2ms/step\n",
            "Epoch 155/800\n",
            "40/40 - 0s - loss: 214.6428 - val_loss: 198.7332 - 68ms/epoch - 2ms/step\n",
            "Epoch 156/800\n",
            "40/40 - 0s - loss: 227.8196 - val_loss: 215.2100 - 65ms/epoch - 2ms/step\n",
            "Epoch 157/800\n",
            "40/40 - 0s - loss: 234.8680 - val_loss: 213.2368 - 76ms/epoch - 2ms/step\n",
            "Epoch 158/800\n",
            "40/40 - 0s - loss: 233.7296 - val_loss: 222.8171 - 71ms/epoch - 2ms/step\n",
            "Epoch 159/800\n",
            "40/40 - 0s - loss: 244.7032 - val_loss: 240.2283 - 72ms/epoch - 2ms/step\n",
            "Epoch 160/800\n",
            "40/40 - 0s - loss: 246.8171 - val_loss: 234.7720 - 68ms/epoch - 2ms/step\n",
            "Epoch 161/800\n",
            "40/40 - 0s - loss: 246.7127 - val_loss: 241.5263 - 67ms/epoch - 2ms/step\n",
            "Epoch 162/800\n",
            "40/40 - 0s - loss: 266.0816 - val_loss: 243.7589 - 65ms/epoch - 2ms/step\n",
            "Epoch 163/800\n",
            "40/40 - 0s - loss: 257.3568 - val_loss: 234.2213 - 66ms/epoch - 2ms/step\n",
            "Epoch 164/800\n",
            "40/40 - 0s - loss: 252.2240 - val_loss: 237.7166 - 68ms/epoch - 2ms/step\n",
            "Epoch 165/800\n",
            "40/40 - 0s - loss: 246.8775 - val_loss: 230.4453 - 68ms/epoch - 2ms/step\n",
            "Epoch 166/800\n",
            "40/40 - 0s - loss: 253.8474 - val_loss: 239.6747 - 68ms/epoch - 2ms/step\n",
            "Epoch 167/800\n",
            "40/40 - 0s - loss: 254.5559 - val_loss: 246.1902 - 67ms/epoch - 2ms/step\n",
            "Epoch 168/800\n",
            "40/40 - 0s - loss: 263.2474 - val_loss: 243.3483 - 68ms/epoch - 2ms/step\n",
            "Epoch 169/800\n",
            "40/40 - 0s - loss: 285.2965 - val_loss: 291.6887 - 70ms/epoch - 2ms/step\n",
            "Epoch 170/800\n",
            "40/40 - 0s - loss: 299.1200 - val_loss: 256.3613 - 66ms/epoch - 2ms/step\n",
            "Epoch 171/800\n",
            "40/40 - 0s - loss: 274.4375 - val_loss: 251.4657 - 68ms/epoch - 2ms/step\n",
            "Epoch 172/800\n",
            "40/40 - 0s - loss: 291.2726 - val_loss: 263.4227 - 67ms/epoch - 2ms/step\n",
            "Epoch 173/800\n",
            "40/40 - 0s - loss: 303.5837 - val_loss: 284.8530 - 65ms/epoch - 2ms/step\n",
            "Epoch 174/800\n",
            "40/40 - 0s - loss: 282.6843 - val_loss: 251.0424 - 66ms/epoch - 2ms/step\n",
            "Epoch 175/800\n",
            "40/40 - 0s - loss: 251.8716 - val_loss: 221.3965 - 65ms/epoch - 2ms/step\n",
            "Epoch 176/800\n",
            "40/40 - 0s - loss: 234.2446 - val_loss: 207.7554 - 68ms/epoch - 2ms/step\n",
            "Epoch 177/800\n",
            "40/40 - 0s - loss: 225.6106 - val_loss: 203.6888 - 69ms/epoch - 2ms/step\n",
            "Epoch 178/800\n",
            "40/40 - 0s - loss: 217.2942 - val_loss: 201.6233 - 66ms/epoch - 2ms/step\n",
            "Epoch 179/800\n",
            "40/40 - 0s - loss: 216.7290 - val_loss: 201.5893 - 67ms/epoch - 2ms/step\n",
            "Epoch 180/800\n",
            "40/40 - 0s - loss: 213.8135 - val_loss: 199.4296 - 66ms/epoch - 2ms/step\n",
            "Epoch 181/800\n",
            "40/40 - 0s - loss: 223.1533 - val_loss: 210.2374 - 65ms/epoch - 2ms/step\n",
            "Epoch 182/800\n",
            "40/40 - 0s - loss: 226.2979 - val_loss: 202.0956 - 66ms/epoch - 2ms/step\n",
            "Epoch 183/800\n",
            "40/40 - 0s - loss: 217.5316 - val_loss: 199.0263 - 66ms/epoch - 2ms/step\n",
            "Epoch 184/800\n",
            "40/40 - 0s - loss: 215.5220 - val_loss: 199.8533 - 64ms/epoch - 2ms/step\n",
            "Epoch 185/800\n",
            "40/40 - 0s - loss: 214.1053 - val_loss: 196.5670 - 65ms/epoch - 2ms/step\n",
            "Epoch 186/800\n",
            "40/40 - 0s - loss: 234.4922 - val_loss: 229.1172 - 81ms/epoch - 2ms/step\n",
            "Epoch 187/800\n",
            "40/40 - 0s - loss: 245.0428 - val_loss: 255.0795 - 74ms/epoch - 2ms/step\n",
            "Epoch 188/800\n",
            "40/40 - 0s - loss: 259.0251 - val_loss: 236.2852 - 71ms/epoch - 2ms/step\n",
            "Epoch 189/800\n",
            "40/40 - 0s - loss: 279.2715 - val_loss: 340.9690 - 67ms/epoch - 2ms/step\n",
            "Epoch 190/800\n",
            "40/40 - 0s - loss: 339.4500 - val_loss: 327.2340 - 77ms/epoch - 2ms/step\n",
            "Epoch 191/800\n",
            "40/40 - 0s - loss: 345.6342 - val_loss: 329.3597 - 71ms/epoch - 2ms/step\n",
            "Epoch 192/800\n",
            "40/40 - 0s - loss: 304.1589 - val_loss: 257.5370 - 64ms/epoch - 2ms/step\n",
            "Epoch 193/800\n",
            "40/40 - 0s - loss: 267.6787 - val_loss: 242.5260 - 70ms/epoch - 2ms/step\n",
            "Epoch 194/800\n",
            "40/40 - 0s - loss: 254.2784 - val_loss: 222.8017 - 67ms/epoch - 2ms/step\n",
            "Epoch 195/800\n",
            "40/40 - 0s - loss: 241.1042 - val_loss: 228.4127 - 64ms/epoch - 2ms/step\n",
            "Epoch 196/800\n",
            "40/40 - 0s - loss: 238.3551 - val_loss: 218.6397 - 67ms/epoch - 2ms/step\n",
            "Epoch 197/800\n",
            "40/40 - 0s - loss: 232.2477 - val_loss: 217.2092 - 74ms/epoch - 2ms/step\n",
            "Epoch 198/800\n",
            "40/40 - 0s - loss: 237.4708 - val_loss: 214.2753 - 70ms/epoch - 2ms/step\n",
            "Epoch 199/800\n",
            "40/40 - 0s - loss: 225.6404 - val_loss: 207.8610 - 65ms/epoch - 2ms/step\n",
            "Epoch 200/800\n",
            "40/40 - 0s - loss: 246.5423 - val_loss: 233.1981 - 65ms/epoch - 2ms/step\n",
            "Epoch 201/800\n",
            "40/40 - 0s - loss: 238.1680 - val_loss: 209.3820 - 65ms/epoch - 2ms/step\n",
            "Epoch 202/800\n",
            "40/40 - 0s - loss: 225.6372 - val_loss: 211.1513 - 65ms/epoch - 2ms/step\n",
            "Epoch 203/800\n",
            "40/40 - 0s - loss: 220.4518 - val_loss: 202.3782 - 65ms/epoch - 2ms/step\n",
            "Epoch 204/800\n",
            "40/40 - 0s - loss: 222.8556 - val_loss: 207.2674 - 67ms/epoch - 2ms/step\n",
            "Epoch 205/800\n",
            "40/40 - 0s - loss: 225.4529 - val_loss: 213.9702 - 66ms/epoch - 2ms/step\n",
            "Epoch 206/800\n",
            "40/40 - 0s - loss: 233.8928 - val_loss: 236.0019 - 66ms/epoch - 2ms/step\n",
            "Epoch 207/800\n",
            "40/40 - 0s - loss: 239.2868 - val_loss: 210.1131 - 64ms/epoch - 2ms/step\n",
            "Epoch 208/800\n",
            "40/40 - 0s - loss: 234.3887 - val_loss: 216.2692 - 67ms/epoch - 2ms/step\n",
            "Epoch 209/800\n",
            "40/40 - 0s - loss: 229.8050 - val_loss: 212.0495 - 66ms/epoch - 2ms/step\n",
            "Epoch 210/800\n",
            "40/40 - 0s - loss: 225.6402 - val_loss: 213.6972 - 67ms/epoch - 2ms/step\n",
            "Epoch 211/800\n",
            "40/40 - 0s - loss: 225.8827 - val_loss: 218.4664 - 67ms/epoch - 2ms/step\n",
            "Epoch 212/800\n",
            "40/40 - 0s - loss: 248.5580 - val_loss: 237.5605 - 69ms/epoch - 2ms/step\n",
            "Epoch 213/800\n",
            "40/40 - 0s - loss: 250.2624 - val_loss: 231.4899 - 65ms/epoch - 2ms/step\n",
            "Epoch 214/800\n",
            "40/40 - 0s - loss: 237.5126 - val_loss: 215.0956 - 66ms/epoch - 2ms/step\n",
            "Epoch 215/800\n",
            "40/40 - 0s - loss: 228.3775 - val_loss: 207.8694 - 65ms/epoch - 2ms/step\n",
            "Epoch 216/800\n",
            "40/40 - 0s - loss: 224.7691 - val_loss: 214.5960 - 66ms/epoch - 2ms/step\n",
            "Epoch 217/800\n",
            "40/40 - 0s - loss: 232.6128 - val_loss: 225.3789 - 70ms/epoch - 2ms/step\n",
            "Epoch 218/800\n",
            "40/40 - 0s - loss: 240.3639 - val_loss: 220.6333 - 65ms/epoch - 2ms/step\n",
            "Epoch 219/800\n",
            "40/40 - 0s - loss: 230.7823 - val_loss: 217.7966 - 64ms/epoch - 2ms/step\n",
            "Epoch 220/800\n",
            "40/40 - 0s - loss: 229.5305 - val_loss: 206.4851 - 65ms/epoch - 2ms/step\n",
            "Epoch 221/800\n",
            "40/40 - 0s - loss: 229.4855 - val_loss: 229.7428 - 66ms/epoch - 2ms/step\n",
            "Epoch 222/800\n",
            "40/40 - 0s - loss: 245.9404 - val_loss: 242.7695 - 67ms/epoch - 2ms/step\n",
            "Epoch 223/800\n",
            "40/40 - 0s - loss: 279.1341 - val_loss: 258.4163 - 66ms/epoch - 2ms/step\n",
            "Epoch 224/800\n",
            "40/40 - 0s - loss: 289.7196 - val_loss: 256.3911 - 67ms/epoch - 2ms/step\n",
            "Epoch 225/800\n",
            "40/40 - 0s - loss: 285.7609 - val_loss: 252.2918 - 66ms/epoch - 2ms/step\n",
            "Epoch 226/800\n",
            "40/40 - 0s - loss: 273.4406 - val_loss: 248.3729 - 68ms/epoch - 2ms/step\n",
            "Epoch 227/800\n",
            "40/40 - 0s - loss: 260.1787 - val_loss: 249.0809 - 70ms/epoch - 2ms/step\n",
            "Epoch 228/800\n",
            "40/40 - 0s - loss: 249.4709 - val_loss: 224.5360 - 66ms/epoch - 2ms/step\n",
            "Epoch 229/800\n",
            "40/40 - 0s - loss: 236.3162 - val_loss: 214.6109 - 68ms/epoch - 2ms/step\n",
            "Epoch 230/800\n",
            "40/40 - 0s - loss: 228.1100 - val_loss: 221.3441 - 65ms/epoch - 2ms/step\n",
            "Epoch 231/800\n",
            "40/40 - 0s - loss: 228.8194 - val_loss: 208.9515 - 71ms/epoch - 2ms/step\n",
            "Epoch 232/800\n",
            "40/40 - 0s - loss: 233.1635 - val_loss: 212.1343 - 66ms/epoch - 2ms/step\n",
            "Epoch 233/800\n",
            "40/40 - 0s - loss: 229.8989 - val_loss: 207.6598 - 66ms/epoch - 2ms/step\n",
            "Epoch 234/800\n",
            "40/40 - 0s - loss: 220.3356 - val_loss: 202.3225 - 66ms/epoch - 2ms/step\n",
            "Epoch 235/800\n",
            "40/40 - 0s - loss: 217.5391 - val_loss: 199.2350 - 67ms/epoch - 2ms/step\n",
            "Epoch 236/800\n",
            "40/40 - 0s - loss: 213.4527 - val_loss: 196.8707 - 68ms/epoch - 2ms/step\n",
            "Epoch 237/800\n",
            "40/40 - 0s - loss: 215.0174 - val_loss: 197.0586 - 65ms/epoch - 2ms/step\n",
            "Epoch 238/800\n",
            "40/40 - 0s - loss: 216.9570 - val_loss: 205.2862 - 65ms/epoch - 2ms/step\n",
            "Epoch 239/800\n",
            "40/40 - 0s - loss: 223.0320 - val_loss: 220.3713 - 66ms/epoch - 2ms/step\n",
            "Epoch 240/800\n",
            "40/40 - 0s - loss: 247.8732 - val_loss: 236.2397 - 63ms/epoch - 2ms/step\n",
            "Epoch 241/800\n",
            "40/40 - 0s - loss: 246.5934 - val_loss: 243.1351 - 73ms/epoch - 2ms/step\n",
            "Epoch 242/800\n",
            "40/40 - 0s - loss: 255.0827 - val_loss: 237.1889 - 72ms/epoch - 2ms/step\n",
            "Epoch 243/800\n",
            "40/40 - 0s - loss: 255.9884 - val_loss: 237.4973 - 74ms/epoch - 2ms/step\n",
            "Epoch 244/800\n",
            "40/40 - 0s - loss: 248.4279 - val_loss: 234.2075 - 69ms/epoch - 2ms/step\n",
            "Epoch 245/800\n",
            "40/40 - 0s - loss: 247.1326 - val_loss: 236.0316 - 66ms/epoch - 2ms/step\n",
            "Epoch 246/800\n",
            "40/40 - 0s - loss: 249.8082 - val_loss: 234.1789 - 69ms/epoch - 2ms/step\n",
            "Epoch 247/800\n",
            "40/40 - 0s - loss: 240.2105 - val_loss: 220.9655 - 65ms/epoch - 2ms/step\n",
            "Epoch 248/800\n",
            "40/40 - 0s - loss: 234.9418 - val_loss: 207.1631 - 67ms/epoch - 2ms/step\n",
            "Epoch 249/800\n",
            "40/40 - 0s - loss: 240.3971 - val_loss: 264.9211 - 71ms/epoch - 2ms/step\n",
            "Epoch 250/800\n",
            "40/40 - 0s - loss: 267.6249 - val_loss: 242.2110 - 79ms/epoch - 2ms/step\n",
            "Epoch 251/800\n",
            "40/40 - 0s - loss: 249.6832 - val_loss: 245.0257 - 71ms/epoch - 2ms/step\n",
            "Epoch 252/800\n",
            "40/40 - 0s - loss: 255.8280 - val_loss: 242.2951 - 67ms/epoch - 2ms/step\n",
            "Epoch 253/800\n",
            "40/40 - 0s - loss: 253.7113 - val_loss: 244.6497 - 70ms/epoch - 2ms/step\n",
            "Epoch 254/800\n",
            "40/40 - 0s - loss: 255.1126 - val_loss: 236.6185 - 70ms/epoch - 2ms/step\n",
            "Epoch 255/800\n",
            "40/40 - 0s - loss: 239.5578 - val_loss: 212.3290 - 74ms/epoch - 2ms/step\n",
            "Epoch 256/800\n",
            "40/40 - 0s - loss: 232.6156 - val_loss: 218.8668 - 64ms/epoch - 2ms/step\n",
            "Epoch 257/800\n",
            "40/40 - 0s - loss: 241.5798 - val_loss: 221.9800 - 64ms/epoch - 2ms/step\n",
            "Epoch 258/800\n",
            "40/40 - 0s - loss: 239.2479 - val_loss: 221.2960 - 65ms/epoch - 2ms/step\n",
            "Epoch 259/800\n",
            "40/40 - 0s - loss: 238.9639 - val_loss: 216.4281 - 72ms/epoch - 2ms/step\n",
            "Epoch 260/800\n",
            "40/40 - 0s - loss: 234.1164 - val_loss: 208.9741 - 66ms/epoch - 2ms/step\n",
            "Epoch 261/800\n",
            "40/40 - 0s - loss: 226.2920 - val_loss: 207.7119 - 69ms/epoch - 2ms/step\n",
            "Epoch 262/800\n",
            "40/40 - 0s - loss: 225.2461 - val_loss: 208.0184 - 77ms/epoch - 2ms/step\n",
            "Epoch 263/800\n",
            "40/40 - 0s - loss: 230.2088 - val_loss: 221.8784 - 64ms/epoch - 2ms/step\n",
            "Epoch 264/800\n",
            "40/40 - 0s - loss: 231.8678 - val_loss: 213.8331 - 63ms/epoch - 2ms/step\n",
            "Epoch 265/800\n",
            "40/40 - 0s - loss: 234.3956 - val_loss: 218.2655 - 65ms/epoch - 2ms/step\n",
            "Epoch 266/800\n",
            "40/40 - 0s - loss: 235.6684 - val_loss: 223.4933 - 66ms/epoch - 2ms/step\n",
            "Epoch 267/800\n",
            "40/40 - 0s - loss: 236.2431 - val_loss: 208.3856 - 63ms/epoch - 2ms/step\n",
            "Epoch 268/800\n",
            "40/40 - 0s - loss: 223.0154 - val_loss: 208.2281 - 73ms/epoch - 2ms/step\n",
            "Epoch 269/800\n",
            "40/40 - 0s - loss: 235.7119 - val_loss: 236.4383 - 68ms/epoch - 2ms/step\n",
            "Epoch 270/800\n",
            "40/40 - 0s - loss: 247.4510 - val_loss: 226.7609 - 70ms/epoch - 2ms/step\n",
            "Epoch 271/800\n",
            "40/40 - 0s - loss: 244.9801 - val_loss: 227.3069 - 71ms/epoch - 2ms/step\n",
            "Epoch 272/800\n",
            "40/40 - 0s - loss: 237.3569 - val_loss: 212.2754 - 72ms/epoch - 2ms/step\n",
            "Epoch 273/800\n",
            "40/40 - 0s - loss: 224.6309 - val_loss: 205.6618 - 83ms/epoch - 2ms/step\n",
            "Epoch 274/800\n",
            "40/40 - 0s - loss: 227.8743 - val_loss: 210.1173 - 72ms/epoch - 2ms/step\n",
            "Epoch 275/800\n",
            "40/40 - 0s - loss: 234.8690 - val_loss: 225.9420 - 78ms/epoch - 2ms/step\n",
            "Epoch 276/800\n",
            "40/40 - 0s - loss: 246.3866 - val_loss: 248.5697 - 81ms/epoch - 2ms/step\n",
            "Epoch 277/800\n",
            "40/40 - 0s - loss: 261.6685 - val_loss: 240.1580 - 75ms/epoch - 2ms/step\n",
            "Epoch 278/800\n",
            "40/40 - 0s - loss: 261.3129 - val_loss: 246.3597 - 71ms/epoch - 2ms/step\n",
            "Epoch 279/800\n",
            "40/40 - 0s - loss: 261.6777 - val_loss: 241.5834 - 66ms/epoch - 2ms/step\n",
            "Epoch 280/800\n",
            "40/40 - 0s - loss: 246.8263 - val_loss: 216.0994 - 72ms/epoch - 2ms/step\n",
            "Epoch 281/800\n",
            "40/40 - 0s - loss: 253.1205 - val_loss: 226.4760 - 71ms/epoch - 2ms/step\n",
            "Epoch 282/800\n",
            "40/40 - 0s - loss: 246.7363 - val_loss: 225.0960 - 72ms/epoch - 2ms/step\n",
            "Epoch 283/800\n",
            "40/40 - 0s - loss: 249.4088 - val_loss: 235.7227 - 65ms/epoch - 2ms/step\n",
            "Epoch 284/800\n",
            "40/40 - 0s - loss: 243.2383 - val_loss: 234.3271 - 65ms/epoch - 2ms/step\n",
            "Epoch 285/800\n",
            "40/40 - 0s - loss: 233.9451 - val_loss: 206.6351 - 70ms/epoch - 2ms/step\n",
            "Epoch 286/800\n",
            "40/40 - 0s - loss: 223.9966 - val_loss: 213.3655 - 66ms/epoch - 2ms/step\n",
            "Epoch 287/800\n",
            "40/40 - 0s - loss: 235.7798 - val_loss: 225.2430 - 65ms/epoch - 2ms/step\n",
            "Epoch 288/800\n",
            "40/40 - 0s - loss: 226.8715 - val_loss: 218.4645 - 69ms/epoch - 2ms/step\n",
            "Epoch 289/800\n",
            "40/40 - 0s - loss: 224.6111 - val_loss: 198.9078 - 65ms/epoch - 2ms/step\n",
            "Epoch 290/800\n",
            "40/40 - 0s - loss: 214.8484 - val_loss: 199.5047 - 69ms/epoch - 2ms/step\n",
            "Epoch 291/800\n",
            "40/40 - 0s - loss: 209.7671 - val_loss: 190.1505 - 86ms/epoch - 2ms/step\n",
            "Epoch 292/800\n",
            "40/40 - 0s - loss: 206.6265 - val_loss: 189.5094 - 102ms/epoch - 3ms/step\n",
            "Epoch 293/800\n",
            "40/40 - 0s - loss: 206.6511 - val_loss: 197.5412 - 78ms/epoch - 2ms/step\n",
            "Epoch 294/800\n",
            "40/40 - 0s - loss: 217.1835 - val_loss: 215.4322 - 69ms/epoch - 2ms/step\n",
            "Epoch 295/800\n",
            "40/40 - 0s - loss: 220.2297 - val_loss: 203.3267 - 66ms/epoch - 2ms/step\n",
            "Epoch 296/800\n",
            "40/40 - 0s - loss: 222.2395 - val_loss: 206.8277 - 66ms/epoch - 2ms/step\n",
            "Epoch 297/800\n",
            "40/40 - 0s - loss: 222.3925 - val_loss: 206.2303 - 71ms/epoch - 2ms/step\n",
            "Epoch 298/800\n",
            "40/40 - 0s - loss: 221.7357 - val_loss: 209.2205 - 74ms/epoch - 2ms/step\n",
            "Epoch 299/800\n",
            "40/40 - 0s - loss: 225.6903 - val_loss: 213.3338 - 79ms/epoch - 2ms/step\n",
            "Epoch 300/800\n",
            "40/40 - 0s - loss: 224.4503 - val_loss: 204.8889 - 66ms/epoch - 2ms/step\n",
            "Epoch 301/800\n",
            "40/40 - 0s - loss: 226.9050 - val_loss: 222.4882 - 67ms/epoch - 2ms/step\n",
            "Epoch 302/800\n",
            "40/40 - 0s - loss: 231.6069 - val_loss: 216.5504 - 65ms/epoch - 2ms/step\n",
            "Epoch 303/800\n",
            "40/40 - 0s - loss: 233.4970 - val_loss: 211.4327 - 67ms/epoch - 2ms/step\n",
            "Epoch 304/800\n",
            "40/40 - 0s - loss: 240.8289 - val_loss: 229.1250 - 70ms/epoch - 2ms/step\n",
            "Epoch 305/800\n",
            "40/40 - 0s - loss: 248.3626 - val_loss: 231.4308 - 66ms/epoch - 2ms/step\n",
            "Epoch 306/800\n",
            "40/40 - 0s - loss: 243.5484 - val_loss: 229.6698 - 67ms/epoch - 2ms/step\n",
            "Epoch 307/800\n",
            "40/40 - 0s - loss: 258.6319 - val_loss: 247.0049 - 64ms/epoch - 2ms/step\n",
            "Epoch 308/800\n",
            "40/40 - 0s - loss: 257.6473 - val_loss: 227.6105 - 64ms/epoch - 2ms/step\n",
            "Epoch 309/800\n",
            "40/40 - 0s - loss: 257.3245 - val_loss: 240.5039 - 66ms/epoch - 2ms/step\n",
            "Epoch 310/800\n",
            "40/40 - 0s - loss: 264.1443 - val_loss: 244.9526 - 66ms/epoch - 2ms/step\n",
            "Epoch 311/800\n",
            "40/40 - 0s - loss: 273.6008 - val_loss: 243.3432 - 66ms/epoch - 2ms/step\n",
            "Epoch 312/800\n",
            "40/40 - 0s - loss: 259.6630 - val_loss: 238.4854 - 66ms/epoch - 2ms/step\n",
            "Epoch 313/800\n",
            "40/40 - 0s - loss: 242.5861 - val_loss: 217.0159 - 100ms/epoch - 3ms/step\n",
            "Epoch 314/800\n",
            "40/40 - 0s - loss: 236.4059 - val_loss: 208.9140 - 84ms/epoch - 2ms/step\n",
            "Epoch 315/800\n",
            "40/40 - 0s - loss: 226.7189 - val_loss: 210.2378 - 73ms/epoch - 2ms/step\n",
            "Epoch 316/800\n",
            "40/40 - 0s - loss: 221.1204 - val_loss: 201.6835 - 66ms/epoch - 2ms/step\n",
            "Epoch 317/800\n",
            "40/40 - 0s - loss: 221.9734 - val_loss: 204.0225 - 65ms/epoch - 2ms/step\n",
            "Epoch 318/800\n",
            "40/40 - 0s - loss: 220.0877 - val_loss: 199.7469 - 65ms/epoch - 2ms/step\n",
            "Epoch 319/800\n",
            "40/40 - 0s - loss: 226.3440 - val_loss: 220.7782 - 66ms/epoch - 2ms/step\n",
            "Epoch 320/800\n",
            "40/40 - 0s - loss: 238.5327 - val_loss: 220.5041 - 68ms/epoch - 2ms/step\n",
            "Epoch 321/800\n",
            "40/40 - 0s - loss: 239.6222 - val_loss: 225.7497 - 65ms/epoch - 2ms/step\n",
            "Epoch 322/800\n",
            "40/40 - 0s - loss: 235.0649 - val_loss: 216.6958 - 66ms/epoch - 2ms/step\n",
            "Epoch 323/800\n",
            "40/40 - 0s - loss: 234.6955 - val_loss: 219.4299 - 65ms/epoch - 2ms/step\n",
            "Epoch 324/800\n",
            "40/40 - 0s - loss: 225.6521 - val_loss: 204.0624 - 69ms/epoch - 2ms/step\n",
            "Epoch 325/800\n",
            "40/40 - 0s - loss: 220.8876 - val_loss: 200.1036 - 65ms/epoch - 2ms/step\n",
            "Epoch 326/800\n",
            "40/40 - 0s - loss: 216.8233 - val_loss: 199.7606 - 69ms/epoch - 2ms/step\n",
            "Epoch 327/800\n",
            "40/40 - 0s - loss: 220.3581 - val_loss: 212.1320 - 65ms/epoch - 2ms/step\n",
            "Epoch 328/800\n",
            "40/40 - 0s - loss: 224.8671 - val_loss: 213.8679 - 67ms/epoch - 2ms/step\n",
            "Epoch 329/800\n",
            "40/40 - 0s - loss: 245.8148 - val_loss: 233.1372 - 66ms/epoch - 2ms/step\n",
            "Epoch 330/800\n",
            "40/40 - 0s - loss: 246.3649 - val_loss: 228.3760 - 66ms/epoch - 2ms/step\n",
            "Epoch 331/800\n",
            "40/40 - 0s - loss: 243.3833 - val_loss: 219.4860 - 66ms/epoch - 2ms/step\n",
            "Epoch 332/800\n",
            "40/40 - 0s - loss: 233.2658 - val_loss: 213.6751 - 72ms/epoch - 2ms/step\n",
            "Epoch 333/800\n",
            "40/40 - 0s - loss: 226.5224 - val_loss: 209.2982 - 69ms/epoch - 2ms/step\n",
            "Epoch 334/800\n",
            "40/40 - 0s - loss: 227.7299 - val_loss: 204.2086 - 67ms/epoch - 2ms/step\n",
            "Epoch 335/800\n",
            "40/40 - 0s - loss: 224.8850 - val_loss: 211.4860 - 69ms/epoch - 2ms/step\n",
            "Epoch 336/800\n",
            "40/40 - 0s - loss: 223.8609 - val_loss: 212.2558 - 66ms/epoch - 2ms/step\n",
            "Epoch 337/800\n",
            "40/40 - 0s - loss: 221.4710 - val_loss: 203.3376 - 69ms/epoch - 2ms/step\n",
            "Epoch 338/800\n",
            "40/40 - 0s - loss: 220.5584 - val_loss: 204.3482 - 72ms/epoch - 2ms/step\n",
            "Epoch 339/800\n",
            "40/40 - 0s - loss: 217.6790 - val_loss: 202.4688 - 72ms/epoch - 2ms/step\n",
            "Epoch 340/800\n",
            "40/40 - 0s - loss: 218.5900 - val_loss: 209.8662 - 67ms/epoch - 2ms/step\n",
            "Epoch 341/800\n",
            "40/40 - 0s - loss: 223.8717 - val_loss: 211.6579 - 64ms/epoch - 2ms/step\n",
            "Epoch 342/800\n",
            "40/40 - 0s - loss: 233.3035 - val_loss: 216.2020 - 66ms/epoch - 2ms/step\n",
            "Epoch 343/800\n",
            "40/40 - 0s - loss: 237.8707 - val_loss: 225.9106 - 67ms/epoch - 2ms/step\n",
            "Epoch 344/800\n",
            "40/40 - 0s - loss: 242.3417 - val_loss: 225.3286 - 65ms/epoch - 2ms/step\n",
            "Epoch 345/800\n",
            "40/40 - 0s - loss: 241.5514 - val_loss: 234.1017 - 64ms/epoch - 2ms/step\n",
            "Epoch 346/800\n",
            "40/40 - 0s - loss: 250.3010 - val_loss: 270.3927 - 64ms/epoch - 2ms/step\n",
            "Epoch 347/800\n",
            "40/40 - 0s - loss: 273.9524 - val_loss: 308.3785 - 67ms/epoch - 2ms/step\n",
            "Epoch 348/800\n",
            "40/40 - 0s - loss: 286.1571 - val_loss: 240.2668 - 65ms/epoch - 2ms/step\n",
            "Epoch 349/800\n",
            "40/40 - 0s - loss: 261.8757 - val_loss: 264.8198 - 64ms/epoch - 2ms/step\n",
            "Epoch 350/800\n",
            "40/40 - 0s - loss: 276.4207 - val_loss: 266.8592 - 71ms/epoch - 2ms/step\n",
            "Epoch 351/800\n",
            "40/40 - 0s - loss: 260.6842 - val_loss: 222.7253 - 65ms/epoch - 2ms/step\n",
            "Epoch 352/800\n",
            "40/40 - 0s - loss: 233.7144 - val_loss: 207.6660 - 66ms/epoch - 2ms/step\n",
            "Epoch 353/800\n",
            "40/40 - 0s - loss: 220.1394 - val_loss: 200.3830 - 67ms/epoch - 2ms/step\n",
            "Epoch 354/800\n",
            "40/40 - 0s - loss: 211.4957 - val_loss: 189.4344 - 65ms/epoch - 2ms/step\n",
            "Epoch 355/800\n",
            "40/40 - 0s - loss: 207.9089 - val_loss: 189.6514 - 68ms/epoch - 2ms/step\n",
            "Epoch 356/800\n",
            "40/40 - 0s - loss: 207.9026 - val_loss: 190.9363 - 67ms/epoch - 2ms/step\n",
            "Epoch 357/800\n",
            "40/40 - 0s - loss: 208.2613 - val_loss: 190.6353 - 67ms/epoch - 2ms/step\n",
            "Epoch 358/800\n",
            "40/40 - 0s - loss: 205.7272 - val_loss: 199.5447 - 68ms/epoch - 2ms/step\n",
            "Epoch 359/800\n",
            "40/40 - 0s - loss: 212.6407 - val_loss: 196.1510 - 68ms/epoch - 2ms/step\n",
            "Epoch 360/800\n",
            "40/40 - 0s - loss: 216.0849 - val_loss: 203.9876 - 67ms/epoch - 2ms/step\n",
            "Epoch 361/800\n",
            "40/40 - 0s - loss: 218.4479 - val_loss: 206.3975 - 67ms/epoch - 2ms/step\n",
            "Epoch 362/800\n",
            "40/40 - 0s - loss: 221.7248 - val_loss: 214.3259 - 64ms/epoch - 2ms/step\n",
            "Epoch 363/800\n",
            "40/40 - 0s - loss: 225.7768 - val_loss: 204.2345 - 66ms/epoch - 2ms/step\n",
            "Epoch 364/800\n",
            "40/40 - 0s - loss: 231.7400 - val_loss: 212.3672 - 65ms/epoch - 2ms/step\n",
            "Epoch 365/800\n",
            "40/40 - 0s - loss: 255.0436 - val_loss: 240.1518 - 64ms/epoch - 2ms/step\n",
            "Epoch 366/800\n",
            "40/40 - 0s - loss: 249.7183 - val_loss: 230.6650 - 68ms/epoch - 2ms/step\n",
            "Epoch 367/800\n",
            "40/40 - 0s - loss: 251.0691 - val_loss: 250.4509 - 63ms/epoch - 2ms/step\n",
            "Epoch 368/800\n",
            "40/40 - 0s - loss: 254.8239 - val_loss: 225.1954 - 64ms/epoch - 2ms/step\n",
            "Epoch 369/800\n",
            "40/40 - 0s - loss: 245.4448 - val_loss: 226.4035 - 65ms/epoch - 2ms/step\n",
            "Epoch 370/800\n",
            "40/40 - 0s - loss: 249.4505 - val_loss: 225.7963 - 65ms/epoch - 2ms/step\n",
            "Epoch 371/800\n",
            "40/40 - 0s - loss: 236.8576 - val_loss: 210.6475 - 66ms/epoch - 2ms/step\n",
            "Epoch 372/800\n",
            "40/40 - 0s - loss: 234.0595 - val_loss: 222.9211 - 65ms/epoch - 2ms/step\n",
            "Epoch 373/800\n",
            "40/40 - 0s - loss: 229.0030 - val_loss: 208.3580 - 63ms/epoch - 2ms/step\n",
            "Epoch 374/800\n",
            "40/40 - 0s - loss: 228.0851 - val_loss: 212.3125 - 67ms/epoch - 2ms/step\n",
            "Epoch 375/800\n",
            "40/40 - 0s - loss: 237.7245 - val_loss: 218.5075 - 65ms/epoch - 2ms/step\n",
            "Epoch 376/800\n",
            "40/40 - 0s - loss: 228.4810 - val_loss: 214.8218 - 65ms/epoch - 2ms/step\n",
            "Epoch 377/800\n",
            "40/40 - 0s - loss: 231.5047 - val_loss: 215.3773 - 68ms/epoch - 2ms/step\n",
            "Epoch 378/800\n",
            "40/40 - 0s - loss: 236.1092 - val_loss: 211.3957 - 71ms/epoch - 2ms/step\n",
            "Epoch 379/800\n",
            "40/40 - 0s - loss: 230.3789 - val_loss: 210.5943 - 69ms/epoch - 2ms/step\n",
            "Epoch 380/800\n",
            "40/40 - 0s - loss: 225.8354 - val_loss: 208.1445 - 68ms/epoch - 2ms/step\n",
            "Epoch 381/800\n",
            "40/40 - 0s - loss: 221.3152 - val_loss: 199.1826 - 66ms/epoch - 2ms/step\n",
            "Epoch 382/800\n",
            "40/40 - 0s - loss: 221.4184 - val_loss: 212.8936 - 69ms/epoch - 2ms/step\n",
            "Epoch 383/800\n",
            "40/40 - 0s - loss: 228.2436 - val_loss: 209.5177 - 65ms/epoch - 2ms/step\n",
            "Epoch 384/800\n",
            "40/40 - 0s - loss: 220.9904 - val_loss: 209.1083 - 64ms/epoch - 2ms/step\n",
            "Epoch 385/800\n",
            "40/40 - 0s - loss: 225.9758 - val_loss: 208.4730 - 67ms/epoch - 2ms/step\n",
            "Epoch 386/800\n",
            "40/40 - 0s - loss: 228.4300 - val_loss: 209.7515 - 65ms/epoch - 2ms/step\n",
            "Epoch 387/800\n",
            "40/40 - 0s - loss: 225.0484 - val_loss: 204.3527 - 65ms/epoch - 2ms/step\n",
            "Epoch 388/800\n",
            "40/40 - 0s - loss: 223.9228 - val_loss: 203.6208 - 67ms/epoch - 2ms/step\n",
            "Epoch 389/800\n",
            "40/40 - 0s - loss: 225.2688 - val_loss: 210.7387 - 67ms/epoch - 2ms/step\n",
            "Epoch 390/800\n",
            "40/40 - 0s - loss: 229.9604 - val_loss: 209.8598 - 66ms/epoch - 2ms/step\n",
            "Epoch 391/800\n",
            "40/40 - 0s - loss: 236.1165 - val_loss: 215.7318 - 65ms/epoch - 2ms/step\n",
            "Epoch 392/800\n",
            "40/40 - 0s - loss: 243.5394 - val_loss: 217.0116 - 66ms/epoch - 2ms/step\n",
            "Epoch 393/800\n",
            "40/40 - 0s - loss: 227.6175 - val_loss: 216.2672 - 66ms/epoch - 2ms/step\n",
            "Epoch 394/800\n",
            "40/40 - 0s - loss: 244.5122 - val_loss: 228.8965 - 67ms/epoch - 2ms/step\n",
            "Epoch 395/800\n",
            "40/40 - 0s - loss: 256.8506 - val_loss: 235.1233 - 66ms/epoch - 2ms/step\n",
            "Epoch 396/800\n",
            "40/40 - 0s - loss: 244.9642 - val_loss: 221.9644 - 68ms/epoch - 2ms/step\n",
            "Epoch 397/800\n",
            "40/40 - 0s - loss: 236.9931 - val_loss: 224.7739 - 67ms/epoch - 2ms/step\n",
            "Epoch 398/800\n",
            "40/40 - 0s - loss: 235.0862 - val_loss: 229.1350 - 69ms/epoch - 2ms/step\n",
            "Epoch 399/800\n",
            "40/40 - 0s - loss: 234.8974 - val_loss: 221.8804 - 73ms/epoch - 2ms/step\n",
            "Epoch 400/800\n",
            "40/40 - 0s - loss: 243.3603 - val_loss: 221.7150 - 78ms/epoch - 2ms/step\n",
            "Epoch 401/800\n",
            "40/40 - 0s - loss: 234.0081 - val_loss: 232.8692 - 67ms/epoch - 2ms/step\n",
            "Epoch 402/800\n",
            "40/40 - 0s - loss: 228.4883 - val_loss: 210.5328 - 64ms/epoch - 2ms/step\n",
            "Epoch 403/800\n",
            "40/40 - 0s - loss: 228.8539 - val_loss: 205.1960 - 67ms/epoch - 2ms/step\n",
            "Epoch 404/800\n",
            "40/40 - 0s - loss: 233.1513 - val_loss: 220.0408 - 76ms/epoch - 2ms/step\n",
            "Epoch 405/800\n",
            "40/40 - 0s - loss: 224.0148 - val_loss: 203.3374 - 80ms/epoch - 2ms/step\n",
            "Epoch 406/800\n",
            "40/40 - 0s - loss: 216.7417 - val_loss: 197.8946 - 68ms/epoch - 2ms/step\n",
            "Epoch 407/800\n",
            "40/40 - 0s - loss: 218.1066 - val_loss: 201.2443 - 66ms/epoch - 2ms/step\n",
            "Epoch 408/800\n",
            "40/40 - 0s - loss: 215.2344 - val_loss: 199.4962 - 73ms/epoch - 2ms/step\n",
            "Epoch 409/800\n",
            "40/40 - 0s - loss: 214.9340 - val_loss: 200.6625 - 80ms/epoch - 2ms/step\n",
            "Epoch 410/800\n",
            "40/40 - 0s - loss: 215.9960 - val_loss: 206.8346 - 82ms/epoch - 2ms/step\n",
            "Epoch 411/800\n",
            "40/40 - 0s - loss: 216.2488 - val_loss: 206.3122 - 68ms/epoch - 2ms/step\n",
            "Epoch 412/800\n",
            "40/40 - 0s - loss: 217.0728 - val_loss: 200.1237 - 70ms/epoch - 2ms/step\n",
            "Epoch 413/800\n",
            "40/40 - 0s - loss: 210.9646 - val_loss: 195.2599 - 76ms/epoch - 2ms/step\n",
            "Epoch 414/800\n",
            "40/40 - 0s - loss: 219.1080 - val_loss: 202.2206 - 66ms/epoch - 2ms/step\n",
            "Epoch 415/800\n",
            "40/40 - 0s - loss: 218.1260 - val_loss: 204.5197 - 68ms/epoch - 2ms/step\n",
            "Epoch 416/800\n",
            "40/40 - 0s - loss: 229.3304 - val_loss: 219.7250 - 66ms/epoch - 2ms/step\n",
            "Epoch 417/800\n",
            "40/40 - 0s - loss: 236.8853 - val_loss: 214.7110 - 81ms/epoch - 2ms/step\n",
            "Epoch 418/800\n",
            "40/40 - 0s - loss: 231.0233 - val_loss: 214.4594 - 75ms/epoch - 2ms/step\n",
            "Epoch 419/800\n",
            "40/40 - 0s - loss: 235.7971 - val_loss: 218.0453 - 68ms/epoch - 2ms/step\n",
            "Epoch 420/800\n",
            "40/40 - 0s - loss: 253.2868 - val_loss: 223.8007 - 68ms/epoch - 2ms/step\n",
            "Epoch 421/800\n",
            "40/40 - 0s - loss: 245.4964 - val_loss: 235.4326 - 67ms/epoch - 2ms/step\n",
            "Epoch 422/800\n",
            "40/40 - 0s - loss: 252.4044 - val_loss: 237.6367 - 80ms/epoch - 2ms/step\n",
            "Epoch 423/800\n",
            "40/40 - 0s - loss: 243.6258 - val_loss: 224.0715 - 66ms/epoch - 2ms/step\n",
            "Epoch 424/800\n",
            "40/40 - 0s - loss: 240.2698 - val_loss: 215.5300 - 64ms/epoch - 2ms/step\n",
            "Epoch 425/800\n",
            "40/40 - 0s - loss: 244.3456 - val_loss: 218.8785 - 67ms/epoch - 2ms/step\n",
            "Epoch 426/800\n",
            "40/40 - 0s - loss: 230.8855 - val_loss: 205.4538 - 68ms/epoch - 2ms/step\n",
            "Epoch 427/800\n",
            "40/40 - 0s - loss: 226.3000 - val_loss: 203.5517 - 67ms/epoch - 2ms/step\n",
            "Epoch 428/800\n",
            "40/40 - 0s - loss: 225.1751 - val_loss: 205.6847 - 64ms/epoch - 2ms/step\n",
            "Epoch 429/800\n",
            "40/40 - 0s - loss: 216.4136 - val_loss: 203.7122 - 67ms/epoch - 2ms/step\n",
            "Epoch 430/800\n",
            "40/40 - 0s - loss: 217.2924 - val_loss: 194.5279 - 67ms/epoch - 2ms/step\n",
            "Epoch 431/800\n",
            "40/40 - 0s - loss: 220.1316 - val_loss: 205.2251 - 64ms/epoch - 2ms/step\n",
            "Epoch 432/800\n",
            "40/40 - 0s - loss: 221.6553 - val_loss: 203.4719 - 68ms/epoch - 2ms/step\n",
            "Epoch 433/800\n",
            "40/40 - 0s - loss: 223.7934 - val_loss: 201.8920 - 68ms/epoch - 2ms/step\n",
            "Epoch 434/800\n",
            "40/40 - 0s - loss: 226.6277 - val_loss: 218.4778 - 65ms/epoch - 2ms/step\n",
            "Epoch 435/800\n",
            "40/40 - 0s - loss: 230.0977 - val_loss: 229.9639 - 64ms/epoch - 2ms/step\n",
            "Epoch 436/800\n",
            "40/40 - 0s - loss: 242.3618 - val_loss: 221.2307 - 66ms/epoch - 2ms/step\n",
            "Epoch 437/800\n",
            "40/40 - 0s - loss: 234.2290 - val_loss: 235.0570 - 69ms/epoch - 2ms/step\n",
            "Epoch 438/800\n",
            "40/40 - 0s - loss: 228.8110 - val_loss: 206.1495 - 67ms/epoch - 2ms/step\n",
            "Epoch 439/800\n",
            "40/40 - 0s - loss: 219.1008 - val_loss: 198.8341 - 66ms/epoch - 2ms/step\n",
            "Epoch 440/800\n",
            "40/40 - 0s - loss: 216.6497 - val_loss: 209.8357 - 68ms/epoch - 2ms/step\n",
            "Epoch 441/800\n",
            "40/40 - 0s - loss: 227.5122 - val_loss: 204.9025 - 73ms/epoch - 2ms/step\n",
            "Epoch 442/800\n",
            "40/40 - 0s - loss: 219.5293 - val_loss: 196.0307 - 71ms/epoch - 2ms/step\n",
            "Epoch 443/800\n",
            "40/40 - 0s - loss: 214.2695 - val_loss: 196.3142 - 86ms/epoch - 2ms/step\n",
            "Epoch 444/800\n",
            "40/40 - 0s - loss: 224.3995 - val_loss: 212.7972 - 75ms/epoch - 2ms/step\n",
            "Epoch 445/800\n",
            "40/40 - 0s - loss: 223.6039 - val_loss: 204.7474 - 74ms/epoch - 2ms/step\n",
            "Epoch 446/800\n",
            "40/40 - 0s - loss: 224.1597 - val_loss: 210.8081 - 67ms/epoch - 2ms/step\n",
            "Epoch 447/800\n",
            "40/40 - 0s - loss: 227.2897 - val_loss: 228.7937 - 65ms/epoch - 2ms/step\n",
            "Epoch 448/800\n",
            "40/40 - 0s - loss: 231.1502 - val_loss: 217.2679 - 65ms/epoch - 2ms/step\n",
            "Epoch 449/800\n",
            "40/40 - 0s - loss: 234.9136 - val_loss: 226.0388 - 66ms/epoch - 2ms/step\n",
            "Epoch 450/800\n",
            "40/40 - 0s - loss: 246.2841 - val_loss: 235.4400 - 65ms/epoch - 2ms/step\n",
            "Epoch 451/800\n",
            "40/40 - 0s - loss: 247.4450 - val_loss: 227.0560 - 66ms/epoch - 2ms/step\n",
            "Epoch 452/800\n",
            "40/40 - 0s - loss: 249.8537 - val_loss: 228.6296 - 66ms/epoch - 2ms/step\n",
            "Epoch 453/800\n",
            "40/40 - 0s - loss: 244.0307 - val_loss: 227.7042 - 68ms/epoch - 2ms/step\n",
            "Epoch 454/800\n",
            "40/40 - 0s - loss: 241.7120 - val_loss: 223.9449 - 64ms/epoch - 2ms/step\n",
            "Epoch 455/800\n",
            "40/40 - 0s - loss: 239.0962 - val_loss: 220.2173 - 65ms/epoch - 2ms/step\n",
            "Epoch 456/800\n",
            "40/40 - 0s - loss: 234.1323 - val_loss: 210.2345 - 68ms/epoch - 2ms/step\n",
            "Epoch 457/800\n",
            "40/40 - 0s - loss: 235.6820 - val_loss: 216.0248 - 64ms/epoch - 2ms/step\n",
            "Epoch 458/800\n",
            "40/40 - 0s - loss: 225.9248 - val_loss: 206.4370 - 66ms/epoch - 2ms/step\n",
            "Epoch 459/800\n",
            "40/40 - 0s - loss: 223.1074 - val_loss: 205.4729 - 64ms/epoch - 2ms/step\n",
            "Epoch 460/800\n",
            "40/40 - 0s - loss: 221.9898 - val_loss: 203.3024 - 65ms/epoch - 2ms/step\n",
            "Epoch 461/800\n",
            "40/40 - 0s - loss: 224.3685 - val_loss: 206.1395 - 66ms/epoch - 2ms/step\n",
            "Epoch 462/800\n",
            "40/40 - 0s - loss: 226.1936 - val_loss: 212.0343 - 66ms/epoch - 2ms/step\n",
            "Epoch 463/800\n",
            "40/40 - 0s - loss: 228.2154 - val_loss: 208.1244 - 67ms/epoch - 2ms/step\n",
            "Epoch 464/800\n",
            "40/40 - 0s - loss: 226.2962 - val_loss: 206.6431 - 68ms/epoch - 2ms/step\n",
            "Epoch 465/800\n",
            "40/40 - 0s - loss: 219.3117 - val_loss: 193.8899 - 66ms/epoch - 2ms/step\n",
            "Epoch 466/800\n",
            "40/40 - 0s - loss: 213.1362 - val_loss: 193.5916 - 66ms/epoch - 2ms/step\n",
            "Epoch 467/800\n",
            "40/40 - 0s - loss: 214.2130 - val_loss: 202.7864 - 67ms/epoch - 2ms/step\n",
            "Epoch 468/800\n",
            "40/40 - 0s - loss: 228.7437 - val_loss: 226.8550 - 65ms/epoch - 2ms/step\n",
            "Epoch 469/800\n",
            "40/40 - 0s - loss: 233.5915 - val_loss: 216.7365 - 66ms/epoch - 2ms/step\n",
            "Epoch 470/800\n",
            "40/40 - 0s - loss: 236.8735 - val_loss: 220.1880 - 65ms/epoch - 2ms/step\n",
            "Epoch 471/800\n",
            "40/40 - 0s - loss: 240.5462 - val_loss: 233.5037 - 65ms/epoch - 2ms/step\n",
            "Epoch 472/800\n",
            "40/40 - 0s - loss: 247.4932 - val_loss: 227.4077 - 65ms/epoch - 2ms/step\n",
            "Epoch 473/800\n",
            "40/40 - 0s - loss: 241.1709 - val_loss: 219.1626 - 65ms/epoch - 2ms/step\n",
            "Epoch 474/800\n",
            "40/40 - 0s - loss: 236.0628 - val_loss: 212.5901 - 67ms/epoch - 2ms/step\n",
            "Epoch 475/800\n",
            "40/40 - 0s - loss: 232.8543 - val_loss: 212.1486 - 66ms/epoch - 2ms/step\n",
            "Epoch 476/800\n",
            "40/40 - 0s - loss: 229.0384 - val_loss: 219.3156 - 66ms/epoch - 2ms/step\n",
            "Epoch 477/800\n",
            "40/40 - 0s - loss: 236.1990 - val_loss: 214.9152 - 67ms/epoch - 2ms/step\n",
            "Epoch 478/800\n",
            "40/40 - 0s - loss: 240.7882 - val_loss: 223.8714 - 68ms/epoch - 2ms/step\n",
            "Epoch 479/800\n",
            "40/40 - 0s - loss: 240.2392 - val_loss: 223.2521 - 68ms/epoch - 2ms/step\n",
            "Epoch 480/800\n",
            "40/40 - 0s - loss: 233.5876 - val_loss: 205.8825 - 70ms/epoch - 2ms/step\n",
            "Epoch 481/800\n",
            "40/40 - 0s - loss: 218.7774 - val_loss: 206.1867 - 69ms/epoch - 2ms/step\n",
            "Epoch 482/800\n",
            "40/40 - 0s - loss: 215.6188 - val_loss: 196.9376 - 66ms/epoch - 2ms/step\n",
            "Epoch 483/800\n",
            "40/40 - 0s - loss: 216.6693 - val_loss: 196.8746 - 69ms/epoch - 2ms/step\n",
            "Epoch 484/800\n",
            "40/40 - 0s - loss: 211.7721 - val_loss: 200.8279 - 67ms/epoch - 2ms/step\n",
            "Epoch 485/800\n",
            "40/40 - 0s - loss: 217.0630 - val_loss: 199.8528 - 66ms/epoch - 2ms/step\n",
            "Epoch 486/800\n",
            "40/40 - 0s - loss: 214.5347 - val_loss: 208.5592 - 76ms/epoch - 2ms/step\n",
            "Epoch 487/800\n",
            "40/40 - 0s - loss: 222.7470 - val_loss: 206.0761 - 69ms/epoch - 2ms/step\n",
            "Epoch 488/800\n",
            "40/40 - 0s - loss: 220.8362 - val_loss: 206.4303 - 64ms/epoch - 2ms/step\n",
            "Epoch 489/800\n",
            "40/40 - 0s - loss: 242.1592 - val_loss: 232.5603 - 66ms/epoch - 2ms/step\n",
            "Epoch 490/800\n",
            "40/40 - 0s - loss: 229.8360 - val_loss: 210.3072 - 68ms/epoch - 2ms/step\n",
            "Epoch 491/800\n",
            "40/40 - 0s - loss: 227.6261 - val_loss: 209.1751 - 65ms/epoch - 2ms/step\n",
            "Epoch 492/800\n",
            "40/40 - 0s - loss: 224.5889 - val_loss: 208.9527 - 68ms/epoch - 2ms/step\n",
            "Epoch 493/800\n",
            "40/40 - 0s - loss: 222.7003 - val_loss: 206.2945 - 65ms/epoch - 2ms/step\n",
            "Epoch 494/800\n",
            "40/40 - 0s - loss: 225.9876 - val_loss: 209.4603 - 66ms/epoch - 2ms/step\n",
            "Epoch 495/800\n",
            "40/40 - 0s - loss: 234.3187 - val_loss: 214.5773 - 66ms/epoch - 2ms/step\n",
            "Epoch 496/800\n",
            "40/40 - 0s - loss: 230.7609 - val_loss: 217.6239 - 74ms/epoch - 2ms/step\n",
            "Epoch 497/800\n",
            "40/40 - 0s - loss: 228.9847 - val_loss: 208.4751 - 66ms/epoch - 2ms/step\n",
            "Epoch 498/800\n",
            "40/40 - 0s - loss: 230.6597 - val_loss: 215.1220 - 66ms/epoch - 2ms/step\n",
            "Epoch 499/800\n",
            "40/40 - 0s - loss: 236.8112 - val_loss: 206.0167 - 67ms/epoch - 2ms/step\n",
            "Epoch 500/800\n",
            "40/40 - 0s - loss: 226.6611 - val_loss: 216.2659 - 67ms/epoch - 2ms/step\n",
            "Epoch 501/800\n",
            "40/40 - 0s - loss: 223.6477 - val_loss: 204.5785 - 68ms/epoch - 2ms/step\n",
            "Epoch 502/800\n",
            "40/40 - 0s - loss: 218.1969 - val_loss: 196.1970 - 70ms/epoch - 2ms/step\n",
            "Epoch 503/800\n",
            "40/40 - 0s - loss: 215.0598 - val_loss: 204.2509 - 70ms/epoch - 2ms/step\n",
            "Epoch 504/800\n",
            "40/40 - 0s - loss: 218.7691 - val_loss: 207.8073 - 68ms/epoch - 2ms/step\n",
            "Epoch 505/800\n",
            "40/40 - 0s - loss: 226.4212 - val_loss: 208.6504 - 67ms/epoch - 2ms/step\n",
            "Epoch 506/800\n",
            "40/40 - 0s - loss: 226.9828 - val_loss: 213.7567 - 67ms/epoch - 2ms/step\n",
            "Epoch 507/800\n",
            "40/40 - 0s - loss: 234.4073 - val_loss: 217.5565 - 65ms/epoch - 2ms/step\n",
            "Epoch 508/800\n",
            "40/40 - 0s - loss: 235.9330 - val_loss: 207.7243 - 65ms/epoch - 2ms/step\n",
            "Epoch 509/800\n",
            "40/40 - 0s - loss: 223.7939 - val_loss: 202.5271 - 66ms/epoch - 2ms/step\n",
            "Epoch 510/800\n",
            "40/40 - 0s - loss: 216.8856 - val_loss: 194.9397 - 66ms/epoch - 2ms/step\n",
            "Epoch 511/800\n",
            "40/40 - 0s - loss: 212.2749 - val_loss: 198.2195 - 66ms/epoch - 2ms/step\n",
            "Epoch 512/800\n",
            "40/40 - 0s - loss: 212.2047 - val_loss: 203.2238 - 67ms/epoch - 2ms/step\n",
            "Epoch 513/800\n",
            "40/40 - 0s - loss: 213.8123 - val_loss: 197.9486 - 67ms/epoch - 2ms/step\n",
            "Epoch 514/800\n",
            "40/40 - 0s - loss: 219.9072 - val_loss: 207.6352 - 67ms/epoch - 2ms/step\n",
            "Epoch 515/800\n",
            "40/40 - 0s - loss: 227.3655 - val_loss: 207.2129 - 66ms/epoch - 2ms/step\n",
            "Epoch 516/800\n",
            "40/40 - 0s - loss: 233.8241 - val_loss: 206.2525 - 67ms/epoch - 2ms/step\n",
            "Epoch 517/800\n",
            "40/40 - 0s - loss: 236.8291 - val_loss: 216.6562 - 67ms/epoch - 2ms/step\n",
            "Epoch 518/800\n",
            "40/40 - 0s - loss: 231.2671 - val_loss: 214.2543 - 69ms/epoch - 2ms/step\n",
            "Epoch 519/800\n",
            "40/40 - 0s - loss: 235.6559 - val_loss: 217.4532 - 64ms/epoch - 2ms/step\n",
            "Epoch 520/800\n",
            "40/40 - 0s - loss: 230.1871 - val_loss: 207.6844 - 67ms/epoch - 2ms/step\n",
            "Epoch 521/800\n",
            "40/40 - 0s - loss: 224.4886 - val_loss: 205.1419 - 66ms/epoch - 2ms/step\n",
            "Epoch 522/800\n",
            "40/40 - 0s - loss: 214.2809 - val_loss: 193.0595 - 65ms/epoch - 2ms/step\n",
            "Epoch 523/800\n",
            "40/40 - 0s - loss: 219.2089 - val_loss: 211.6817 - 67ms/epoch - 2ms/step\n",
            "Epoch 524/800\n",
            "40/40 - 0s - loss: 224.7740 - val_loss: 198.3744 - 69ms/epoch - 2ms/step\n",
            "Epoch 525/800\n",
            "40/40 - 0s - loss: 230.8058 - val_loss: 229.0206 - 68ms/epoch - 2ms/step\n",
            "Epoch 526/800\n",
            "40/40 - 0s - loss: 243.4794 - val_loss: 223.8298 - 68ms/epoch - 2ms/step\n",
            "Epoch 527/800\n",
            "40/40 - 0s - loss: 235.3445 - val_loss: 222.2103 - 67ms/epoch - 2ms/step\n",
            "Epoch 528/800\n",
            "40/40 - 0s - loss: 233.5620 - val_loss: 217.0780 - 66ms/epoch - 2ms/step\n",
            "Epoch 529/800\n",
            "40/40 - 0s - loss: 228.4742 - val_loss: 220.7338 - 66ms/epoch - 2ms/step\n",
            "Epoch 530/800\n",
            "40/40 - 0s - loss: 225.4005 - val_loss: 208.6624 - 68ms/epoch - 2ms/step\n",
            "Epoch 531/800\n",
            "40/40 - 0s - loss: 224.1686 - val_loss: 197.9941 - 65ms/epoch - 2ms/step\n",
            "Epoch 532/800\n",
            "40/40 - 0s - loss: 216.8140 - val_loss: 194.0516 - 68ms/epoch - 2ms/step\n",
            "Epoch 533/800\n",
            "40/40 - 0s - loss: 212.8065 - val_loss: 197.5070 - 64ms/epoch - 2ms/step\n",
            "Epoch 534/800\n",
            "40/40 - 0s - loss: 208.7011 - val_loss: 190.3272 - 66ms/epoch - 2ms/step\n",
            "Epoch 535/800\n",
            "40/40 - 0s - loss: 206.0988 - val_loss: 190.1587 - 65ms/epoch - 2ms/step\n",
            "Epoch 536/800\n",
            "40/40 - 0s - loss: 208.5032 - val_loss: 191.9298 - 66ms/epoch - 2ms/step\n",
            "Epoch 537/800\n",
            "40/40 - 0s - loss: 213.4558 - val_loss: 196.8010 - 67ms/epoch - 2ms/step\n",
            "Epoch 538/800\n",
            "40/40 - 0s - loss: 216.8353 - val_loss: 206.8134 - 66ms/epoch - 2ms/step\n",
            "Epoch 539/800\n",
            "40/40 - 0s - loss: 224.8404 - val_loss: 209.7551 - 66ms/epoch - 2ms/step\n",
            "Epoch 540/800\n",
            "40/40 - 0s - loss: 234.7333 - val_loss: 216.8575 - 68ms/epoch - 2ms/step\n",
            "Epoch 541/800\n",
            "40/40 - 0s - loss: 235.6721 - val_loss: 215.2605 - 65ms/epoch - 2ms/step\n",
            "Epoch 542/800\n",
            "40/40 - 0s - loss: 234.3259 - val_loss: 209.1694 - 65ms/epoch - 2ms/step\n",
            "Epoch 543/800\n",
            "40/40 - 0s - loss: 246.0300 - val_loss: 242.0749 - 66ms/epoch - 2ms/step\n",
            "Epoch 544/800\n",
            "40/40 - 0s - loss: 242.1600 - val_loss: 225.5865 - 66ms/epoch - 2ms/step\n",
            "Epoch 545/800\n",
            "40/40 - 0s - loss: 233.7562 - val_loss: 210.2551 - 64ms/epoch - 2ms/step\n",
            "Epoch 546/800\n",
            "40/40 - 0s - loss: 225.3198 - val_loss: 199.9167 - 66ms/epoch - 2ms/step\n",
            "Epoch 547/800\n",
            "40/40 - 0s - loss: 219.5523 - val_loss: 200.2139 - 67ms/epoch - 2ms/step\n",
            "Epoch 548/800\n",
            "40/40 - 0s - loss: 217.9187 - val_loss: 202.1568 - 67ms/epoch - 2ms/step\n",
            "Epoch 549/800\n",
            "40/40 - 0s - loss: 212.3308 - val_loss: 195.8729 - 66ms/epoch - 2ms/step\n",
            "Epoch 550/800\n",
            "40/40 - 0s - loss: 207.1843 - val_loss: 192.3269 - 65ms/epoch - 2ms/step\n",
            "Epoch 551/800\n",
            "40/40 - 0s - loss: 210.3271 - val_loss: 198.3067 - 66ms/epoch - 2ms/step\n",
            "Epoch 552/800\n",
            "40/40 - 0s - loss: 210.9444 - val_loss: 192.7499 - 67ms/epoch - 2ms/step\n",
            "Epoch 553/800\n",
            "40/40 - 0s - loss: 216.5590 - val_loss: 207.1070 - 65ms/epoch - 2ms/step\n",
            "Epoch 554/800\n",
            "40/40 - 0s - loss: 222.9818 - val_loss: 205.4305 - 67ms/epoch - 2ms/step\n",
            "Epoch 555/800\n",
            "40/40 - 0s - loss: 222.3617 - val_loss: 205.7870 - 65ms/epoch - 2ms/step\n",
            "Epoch 556/800\n",
            "40/40 - 0s - loss: 219.3367 - val_loss: 207.8462 - 66ms/epoch - 2ms/step\n",
            "Epoch 557/800\n",
            "40/40 - 0s - loss: 217.6613 - val_loss: 202.7881 - 66ms/epoch - 2ms/step\n",
            "Epoch 558/800\n",
            "40/40 - 0s - loss: 217.1716 - val_loss: 199.4500 - 66ms/epoch - 2ms/step\n",
            "Epoch 559/800\n",
            "40/40 - 0s - loss: 212.6468 - val_loss: 204.1096 - 65ms/epoch - 2ms/step\n",
            "Epoch 560/800\n",
            "40/40 - 0s - loss: 215.0794 - val_loss: 195.5424 - 66ms/epoch - 2ms/step\n",
            "Epoch 561/800\n",
            "40/40 - 0s - loss: 220.3007 - val_loss: 226.1925 - 68ms/epoch - 2ms/step\n",
            "Epoch 562/800\n",
            "40/40 - 0s - loss: 234.4583 - val_loss: 230.9189 - 64ms/epoch - 2ms/step\n",
            "Epoch 563/800\n",
            "40/40 - 0s - loss: 244.0389 - val_loss: 220.0400 - 66ms/epoch - 2ms/step\n",
            "Epoch 564/800\n",
            "40/40 - 0s - loss: 246.5565 - val_loss: 232.4995 - 67ms/epoch - 2ms/step\n",
            "Epoch 565/800\n",
            "40/40 - 0s - loss: 250.8514 - val_loss: 230.8153 - 67ms/epoch - 2ms/step\n",
            "Epoch 566/800\n",
            "40/40 - 0s - loss: 247.9847 - val_loss: 226.4593 - 66ms/epoch - 2ms/step\n",
            "Epoch 567/800\n",
            "40/40 - 0s - loss: 238.6052 - val_loss: 212.7459 - 66ms/epoch - 2ms/step\n",
            "Epoch 568/800\n",
            "40/40 - 0s - loss: 223.5134 - val_loss: 207.1730 - 70ms/epoch - 2ms/step\n",
            "Epoch 569/800\n",
            "40/40 - 0s - loss: 222.4619 - val_loss: 200.1308 - 67ms/epoch - 2ms/step\n",
            "Epoch 570/800\n",
            "40/40 - 0s - loss: 223.9513 - val_loss: 205.5804 - 63ms/epoch - 2ms/step\n",
            "Epoch 571/800\n",
            "40/40 - 0s - loss: 223.9508 - val_loss: 202.0935 - 68ms/epoch - 2ms/step\n",
            "Epoch 572/800\n",
            "40/40 - 0s - loss: 214.9666 - val_loss: 196.3065 - 64ms/epoch - 2ms/step\n",
            "Epoch 573/800\n",
            "40/40 - 0s - loss: 210.6439 - val_loss: 192.2584 - 64ms/epoch - 2ms/step\n",
            "Epoch 574/800\n",
            "40/40 - 0s - loss: 208.4455 - val_loss: 192.8971 - 66ms/epoch - 2ms/step\n",
            "Epoch 575/800\n",
            "40/40 - 0s - loss: 208.7689 - val_loss: 190.5484 - 71ms/epoch - 2ms/step\n",
            "Epoch 576/800\n",
            "40/40 - 0s - loss: 209.1684 - val_loss: 192.9497 - 67ms/epoch - 2ms/step\n",
            "Epoch 577/800\n",
            "40/40 - 0s - loss: 213.2899 - val_loss: 205.9838 - 66ms/epoch - 2ms/step\n",
            "Epoch 578/800\n",
            "40/40 - 0s - loss: 217.8070 - val_loss: 212.2791 - 70ms/epoch - 2ms/step\n",
            "Epoch 579/800\n",
            "40/40 - 0s - loss: 223.2827 - val_loss: 206.2098 - 65ms/epoch - 2ms/step\n",
            "Epoch 580/800\n",
            "40/40 - 0s - loss: 236.0643 - val_loss: 231.4383 - 66ms/epoch - 2ms/step\n",
            "Epoch 581/800\n",
            "40/40 - 0s - loss: 240.8381 - val_loss: 219.8569 - 65ms/epoch - 2ms/step\n",
            "Epoch 582/800\n",
            "40/40 - 0s - loss: 241.3443 - val_loss: 229.4353 - 66ms/epoch - 2ms/step\n",
            "Epoch 583/800\n",
            "40/40 - 0s - loss: 246.6241 - val_loss: 239.2036 - 66ms/epoch - 2ms/step\n",
            "Epoch 584/800\n",
            "40/40 - 0s - loss: 253.7500 - val_loss: 238.9920 - 69ms/epoch - 2ms/step\n",
            "Epoch 585/800\n",
            "40/40 - 0s - loss: 252.6317 - val_loss: 245.6290 - 68ms/epoch - 2ms/step\n",
            "Epoch 586/800\n",
            "40/40 - 0s - loss: 254.8954 - val_loss: 228.6431 - 68ms/epoch - 2ms/step\n",
            "Epoch 587/800\n",
            "40/40 - 0s - loss: 238.6649 - val_loss: 228.6087 - 71ms/epoch - 2ms/step\n",
            "Epoch 588/800\n",
            "40/40 - 0s - loss: 232.4721 - val_loss: 210.2506 - 69ms/epoch - 2ms/step\n",
            "Epoch 589/800\n",
            "40/40 - 0s - loss: 226.0613 - val_loss: 201.4231 - 67ms/epoch - 2ms/step\n",
            "Epoch 590/800\n",
            "40/40 - 0s - loss: 220.7226 - val_loss: 202.8414 - 69ms/epoch - 2ms/step\n",
            "Epoch 591/800\n",
            "40/40 - 0s - loss: 217.4784 - val_loss: 195.2113 - 67ms/epoch - 2ms/step\n",
            "Epoch 592/800\n",
            "40/40 - 0s - loss: 209.4180 - val_loss: 194.8503 - 67ms/epoch - 2ms/step\n",
            "Epoch 593/800\n",
            "40/40 - 0s - loss: 208.5203 - val_loss: 193.6189 - 67ms/epoch - 2ms/step\n",
            "Epoch 594/800\n",
            "40/40 - 0s - loss: 206.0639 - val_loss: 191.8334 - 76ms/epoch - 2ms/step\n",
            "Epoch 595/800\n",
            "40/40 - 0s - loss: 210.6970 - val_loss: 194.8727 - 67ms/epoch - 2ms/step\n",
            "Epoch 596/800\n",
            "40/40 - 0s - loss: 210.3448 - val_loss: 191.6794 - 67ms/epoch - 2ms/step\n",
            "Epoch 597/800\n",
            "40/40 - 0s - loss: 212.5695 - val_loss: 196.4767 - 68ms/epoch - 2ms/step\n",
            "Epoch 598/800\n",
            "40/40 - 0s - loss: 212.3138 - val_loss: 200.1900 - 67ms/epoch - 2ms/step\n",
            "Epoch 599/800\n",
            "40/40 - 0s - loss: 209.9748 - val_loss: 195.1516 - 65ms/epoch - 2ms/step\n",
            "Epoch 600/800\n",
            "40/40 - 0s - loss: 208.3891 - val_loss: 196.0916 - 68ms/epoch - 2ms/step\n",
            "Epoch 601/800\n",
            "40/40 - 0s - loss: 215.8704 - val_loss: 206.4817 - 70ms/epoch - 2ms/step\n",
            "Epoch 602/800\n",
            "40/40 - 0s - loss: 216.9232 - val_loss: 201.5794 - 70ms/epoch - 2ms/step\n",
            "Epoch 603/800\n",
            "40/40 - 0s - loss: 222.5664 - val_loss: 209.5658 - 67ms/epoch - 2ms/step\n",
            "Epoch 604/800\n",
            "40/40 - 0s - loss: 225.8762 - val_loss: 204.6060 - 70ms/epoch - 2ms/step\n",
            "Epoch 605/800\n",
            "40/40 - 0s - loss: 230.3138 - val_loss: 249.5416 - 69ms/epoch - 2ms/step\n",
            "Epoch 606/800\n",
            "40/40 - 0s - loss: 260.7389 - val_loss: 257.7471 - 67ms/epoch - 2ms/step\n",
            "Epoch 607/800\n",
            "40/40 - 0s - loss: 280.6053 - val_loss: 254.2954 - 71ms/epoch - 2ms/step\n",
            "Epoch 608/800\n",
            "40/40 - 0s - loss: 270.3564 - val_loss: 251.9495 - 70ms/epoch - 2ms/step\n",
            "Epoch 609/800\n",
            "40/40 - 0s - loss: 258.7718 - val_loss: 255.6681 - 68ms/epoch - 2ms/step\n",
            "Epoch 610/800\n",
            "40/40 - 0s - loss: 249.9445 - val_loss: 233.3783 - 128ms/epoch - 3ms/step\n",
            "Epoch 611/800\n",
            "40/40 - 0s - loss: 242.5455 - val_loss: 223.3497 - 76ms/epoch - 2ms/step\n",
            "Epoch 612/800\n",
            "40/40 - 0s - loss: 244.5933 - val_loss: 223.1190 - 70ms/epoch - 2ms/step\n",
            "Epoch 613/800\n",
            "40/40 - 0s - loss: 234.0888 - val_loss: 208.2346 - 68ms/epoch - 2ms/step\n",
            "Epoch 614/800\n",
            "40/40 - 0s - loss: 224.7193 - val_loss: 200.9235 - 73ms/epoch - 2ms/step\n",
            "Epoch 615/800\n",
            "40/40 - 0s - loss: 216.7116 - val_loss: 195.5292 - 65ms/epoch - 2ms/step\n",
            "Epoch 616/800\n",
            "40/40 - 0s - loss: 209.1720 - val_loss: 189.5471 - 64ms/epoch - 2ms/step\n",
            "Epoch 617/800\n",
            "40/40 - 0s - loss: 208.1850 - val_loss: 189.2616 - 67ms/epoch - 2ms/step\n",
            "Epoch 618/800\n",
            "40/40 - 0s - loss: 207.2458 - val_loss: 188.2520 - 66ms/epoch - 2ms/step\n",
            "Epoch 619/800\n",
            "40/40 - 0s - loss: 208.2826 - val_loss: 194.9217 - 65ms/epoch - 2ms/step\n",
            "Epoch 620/800\n",
            "40/40 - 0s - loss: 218.1916 - val_loss: 216.8023 - 66ms/epoch - 2ms/step\n",
            "Epoch 621/800\n",
            "40/40 - 0s - loss: 229.9465 - val_loss: 200.9509 - 67ms/epoch - 2ms/step\n",
            "Epoch 622/800\n",
            "40/40 - 0s - loss: 223.7978 - val_loss: 206.3906 - 65ms/epoch - 2ms/step\n",
            "Epoch 623/800\n",
            "40/40 - 0s - loss: 215.8266 - val_loss: 195.6884 - 65ms/epoch - 2ms/step\n",
            "Epoch 624/800\n",
            "40/40 - 0s - loss: 211.9990 - val_loss: 192.5656 - 65ms/epoch - 2ms/step\n",
            "Epoch 625/800\n",
            "40/40 - 0s - loss: 204.4069 - val_loss: 186.9834 - 67ms/epoch - 2ms/step\n",
            "Epoch 626/800\n",
            "40/40 - 0s - loss: 203.0259 - val_loss: 186.1827 - 64ms/epoch - 2ms/step\n",
            "Epoch 627/800\n",
            "40/40 - 0s - loss: 203.8899 - val_loss: 181.3916 - 64ms/epoch - 2ms/step\n",
            "Epoch 628/800\n",
            "40/40 - 0s - loss: 199.2343 - val_loss: 188.2571 - 66ms/epoch - 2ms/step\n",
            "Epoch 629/800\n",
            "40/40 - 0s - loss: 202.3249 - val_loss: 185.9982 - 67ms/epoch - 2ms/step\n",
            "Epoch 630/800\n",
            "40/40 - 0s - loss: 202.6162 - val_loss: 186.1281 - 66ms/epoch - 2ms/step\n",
            "Epoch 631/800\n",
            "40/40 - 0s - loss: 203.8532 - val_loss: 182.3676 - 67ms/epoch - 2ms/step\n",
            "Epoch 632/800\n",
            "40/40 - 0s - loss: 202.4004 - val_loss: 184.2064 - 67ms/epoch - 2ms/step\n",
            "Epoch 633/800\n",
            "40/40 - 0s - loss: 202.3290 - val_loss: 190.6527 - 67ms/epoch - 2ms/step\n",
            "Epoch 634/800\n",
            "40/40 - 0s - loss: 210.7769 - val_loss: 195.0402 - 67ms/epoch - 2ms/step\n",
            "Epoch 635/800\n",
            "40/40 - 0s - loss: 210.3211 - val_loss: 197.4628 - 66ms/epoch - 2ms/step\n",
            "Epoch 636/800\n",
            "40/40 - 0s - loss: 208.4961 - val_loss: 192.2383 - 70ms/epoch - 2ms/step\n",
            "Epoch 637/800\n",
            "40/40 - 0s - loss: 215.8019 - val_loss: 197.2960 - 69ms/epoch - 2ms/step\n",
            "Epoch 638/800\n",
            "40/40 - 0s - loss: 223.3487 - val_loss: 216.0240 - 65ms/epoch - 2ms/step\n",
            "Epoch 639/800\n",
            "40/40 - 0s - loss: 239.0363 - val_loss: 233.0658 - 65ms/epoch - 2ms/step\n",
            "Epoch 640/800\n",
            "40/40 - 0s - loss: 245.0551 - val_loss: 221.3994 - 67ms/epoch - 2ms/step\n",
            "Epoch 641/800\n",
            "40/40 - 0s - loss: 250.1457 - val_loss: 247.1241 - 75ms/epoch - 2ms/step\n",
            "Epoch 642/800\n",
            "40/40 - 0s - loss: 254.9897 - val_loss: 239.2507 - 66ms/epoch - 2ms/step\n",
            "Epoch 643/800\n",
            "40/40 - 0s - loss: 253.0326 - val_loss: 233.0223 - 70ms/epoch - 2ms/step\n",
            "Epoch 644/800\n",
            "40/40 - 0s - loss: 246.5541 - val_loss: 223.4119 - 70ms/epoch - 2ms/step\n",
            "Epoch 645/800\n",
            "40/40 - 0s - loss: 255.3638 - val_loss: 236.8891 - 65ms/epoch - 2ms/step\n",
            "Epoch 646/800\n",
            "40/40 - 0s - loss: 245.4031 - val_loss: 218.1405 - 67ms/epoch - 2ms/step\n",
            "Epoch 647/800\n",
            "40/40 - 0s - loss: 232.8746 - val_loss: 224.2575 - 66ms/epoch - 2ms/step\n",
            "Epoch 648/800\n",
            "40/40 - 0s - loss: 231.1019 - val_loss: 212.1507 - 68ms/epoch - 2ms/step\n",
            "Epoch 649/800\n",
            "40/40 - 0s - loss: 229.4857 - val_loss: 202.3945 - 67ms/epoch - 2ms/step\n",
            "Epoch 650/800\n",
            "40/40 - 0s - loss: 220.9781 - val_loss: 202.6108 - 65ms/epoch - 2ms/step\n",
            "Epoch 651/800\n",
            "40/40 - 0s - loss: 215.4765 - val_loss: 194.9867 - 67ms/epoch - 2ms/step\n",
            "Epoch 652/800\n",
            "40/40 - 0s - loss: 213.2833 - val_loss: 196.8536 - 70ms/epoch - 2ms/step\n",
            "Epoch 653/800\n",
            "40/40 - 0s - loss: 211.9970 - val_loss: 198.2291 - 63ms/epoch - 2ms/step\n",
            "Epoch 654/800\n",
            "40/40 - 0s - loss: 220.5302 - val_loss: 201.7800 - 65ms/epoch - 2ms/step\n",
            "Epoch 655/800\n",
            "40/40 - 0s - loss: 213.9120 - val_loss: 196.3276 - 67ms/epoch - 2ms/step\n",
            "Epoch 656/800\n",
            "40/40 - 0s - loss: 213.7962 - val_loss: 197.2010 - 65ms/epoch - 2ms/step\n",
            "Epoch 657/800\n",
            "40/40 - 0s - loss: 210.2488 - val_loss: 189.1741 - 64ms/epoch - 2ms/step\n",
            "Epoch 658/800\n",
            "40/40 - 0s - loss: 209.2071 - val_loss: 197.3916 - 64ms/epoch - 2ms/step\n",
            "Epoch 659/800\n",
            "40/40 - 0s - loss: 218.5617 - val_loss: 198.3928 - 67ms/epoch - 2ms/step\n",
            "Epoch 660/800\n",
            "40/40 - 0s - loss: 214.2696 - val_loss: 194.0013 - 64ms/epoch - 2ms/step\n",
            "Epoch 661/800\n",
            "40/40 - 0s - loss: 210.0554 - val_loss: 195.8535 - 66ms/epoch - 2ms/step\n",
            "Epoch 662/800\n",
            "40/40 - 0s - loss: 212.5657 - val_loss: 193.9679 - 65ms/epoch - 2ms/step\n",
            "Epoch 663/800\n",
            "40/40 - 0s - loss: 213.1186 - val_loss: 192.4908 - 67ms/epoch - 2ms/step\n",
            "Epoch 664/800\n",
            "40/40 - 0s - loss: 218.4244 - val_loss: 209.0676 - 68ms/epoch - 2ms/step\n",
            "Epoch 665/800\n",
            "40/40 - 0s - loss: 219.3433 - val_loss: 203.9982 - 65ms/epoch - 2ms/step\n",
            "Epoch 666/800\n",
            "40/40 - 0s - loss: 223.4934 - val_loss: 199.6754 - 66ms/epoch - 2ms/step\n",
            "Epoch 667/800\n",
            "40/40 - 0s - loss: 217.8652 - val_loss: 205.9240 - 68ms/epoch - 2ms/step\n",
            "Epoch 668/800\n",
            "40/40 - 0s - loss: 225.1209 - val_loss: 208.7005 - 64ms/epoch - 2ms/step\n",
            "Epoch 669/800\n",
            "40/40 - 0s - loss: 231.4692 - val_loss: 229.8071 - 66ms/epoch - 2ms/step\n",
            "Epoch 670/800\n",
            "40/40 - 0s - loss: 241.2610 - val_loss: 213.2744 - 67ms/epoch - 2ms/step\n",
            "Epoch 671/800\n",
            "40/40 - 0s - loss: 232.2165 - val_loss: 218.2165 - 69ms/epoch - 2ms/step\n",
            "Epoch 672/800\n",
            "40/40 - 0s - loss: 227.6467 - val_loss: 218.7439 - 70ms/epoch - 2ms/step\n",
            "Epoch 673/800\n",
            "40/40 - 0s - loss: 228.5921 - val_loss: 209.6745 - 71ms/epoch - 2ms/step\n",
            "Epoch 674/800\n",
            "40/40 - 0s - loss: 228.2577 - val_loss: 201.8788 - 70ms/epoch - 2ms/step\n",
            "Epoch 675/800\n",
            "40/40 - 0s - loss: 220.8327 - val_loss: 207.5225 - 65ms/epoch - 2ms/step\n",
            "Epoch 676/800\n",
            "40/40 - 0s - loss: 234.2137 - val_loss: 230.6679 - 65ms/epoch - 2ms/step\n",
            "Epoch 677/800\n",
            "40/40 - 0s - loss: 238.7980 - val_loss: 219.7677 - 66ms/epoch - 2ms/step\n",
            "Epoch 678/800\n",
            "40/40 - 0s - loss: 238.6290 - val_loss: 212.3170 - 62ms/epoch - 2ms/step\n",
            "Epoch 679/800\n",
            "40/40 - 0s - loss: 228.5207 - val_loss: 212.3054 - 71ms/epoch - 2ms/step\n",
            "Epoch 680/800\n",
            "40/40 - 0s - loss: 219.2535 - val_loss: 196.9436 - 65ms/epoch - 2ms/step\n",
            "Epoch 681/800\n",
            "40/40 - 0s - loss: 225.0736 - val_loss: 202.8322 - 66ms/epoch - 2ms/step\n",
            "Epoch 682/800\n",
            "40/40 - 0s - loss: 218.8266 - val_loss: 200.2451 - 66ms/epoch - 2ms/step\n",
            "Epoch 683/800\n",
            "40/40 - 0s - loss: 218.7900 - val_loss: 199.9953 - 66ms/epoch - 2ms/step\n",
            "Epoch 684/800\n",
            "40/40 - 0s - loss: 221.3021 - val_loss: 203.5600 - 64ms/epoch - 2ms/step\n",
            "Epoch 685/800\n",
            "40/40 - 0s - loss: 218.5553 - val_loss: 207.0514 - 68ms/epoch - 2ms/step\n",
            "Epoch 686/800\n",
            "40/40 - 0s - loss: 231.0434 - val_loss: 209.9447 - 68ms/epoch - 2ms/step\n",
            "Epoch 687/800\n",
            "40/40 - 0s - loss: 227.4262 - val_loss: 224.3584 - 68ms/epoch - 2ms/step\n",
            "Epoch 688/800\n",
            "40/40 - 0s - loss: 229.2253 - val_loss: 202.2722 - 64ms/epoch - 2ms/step\n",
            "Epoch 689/800\n",
            "40/40 - 0s - loss: 220.8172 - val_loss: 196.6845 - 65ms/epoch - 2ms/step\n",
            "Epoch 690/800\n",
            "40/40 - 0s - loss: 213.9167 - val_loss: 196.4145 - 78ms/epoch - 2ms/step\n",
            "Epoch 691/800\n",
            "40/40 - 0s - loss: 214.9724 - val_loss: 196.7655 - 85ms/epoch - 2ms/step\n",
            "Epoch 692/800\n",
            "40/40 - 0s - loss: 215.7389 - val_loss: 197.6489 - 69ms/epoch - 2ms/step\n",
            "Epoch 693/800\n",
            "40/40 - 0s - loss: 214.7278 - val_loss: 197.7515 - 72ms/epoch - 2ms/step\n",
            "Epoch 694/800\n",
            "40/40 - 0s - loss: 216.8265 - val_loss: 203.8062 - 69ms/epoch - 2ms/step\n",
            "Epoch 695/800\n",
            "40/40 - 0s - loss: 225.6755 - val_loss: 205.3537 - 66ms/epoch - 2ms/step\n",
            "Epoch 696/800\n",
            "40/40 - 0s - loss: 222.1321 - val_loss: 198.3350 - 67ms/epoch - 2ms/step\n",
            "Epoch 697/800\n",
            "40/40 - 0s - loss: 219.9449 - val_loss: 201.2618 - 69ms/epoch - 2ms/step\n",
            "Epoch 698/800\n",
            "40/40 - 0s - loss: 222.4127 - val_loss: 205.6217 - 98ms/epoch - 2ms/step\n",
            "Epoch 699/800\n",
            "40/40 - 0s - loss: 222.4248 - val_loss: 202.7438 - 65ms/epoch - 2ms/step\n",
            "Epoch 700/800\n",
            "40/40 - 0s - loss: 218.4928 - val_loss: 200.4368 - 64ms/epoch - 2ms/step\n",
            "Epoch 701/800\n",
            "40/40 - 0s - loss: 220.3001 - val_loss: 207.8731 - 87ms/epoch - 2ms/step\n",
            "Epoch 702/800\n",
            "40/40 - 0s - loss: 223.1550 - val_loss: 202.0032 - 81ms/epoch - 2ms/step\n",
            "Epoch 703/800\n",
            "40/40 - 0s - loss: 222.3852 - val_loss: 198.4324 - 96ms/epoch - 2ms/step\n",
            "Epoch 704/800\n",
            "40/40 - 0s - loss: 216.3349 - val_loss: 196.8903 - 80ms/epoch - 2ms/step\n",
            "Epoch 705/800\n",
            "40/40 - 0s - loss: 219.2466 - val_loss: 201.3380 - 66ms/epoch - 2ms/step\n",
            "Epoch 706/800\n",
            "40/40 - 0s - loss: 221.8741 - val_loss: 195.3972 - 67ms/epoch - 2ms/step\n",
            "Epoch 707/800\n",
            "40/40 - 0s - loss: 221.4391 - val_loss: 212.4404 - 68ms/epoch - 2ms/step\n",
            "Epoch 708/800\n",
            "40/40 - 0s - loss: 227.4683 - val_loss: 208.7282 - 67ms/epoch - 2ms/step\n",
            "Epoch 709/800\n",
            "40/40 - 0s - loss: 228.9790 - val_loss: 215.5085 - 65ms/epoch - 2ms/step\n",
            "Epoch 710/800\n",
            "40/40 - 0s - loss: 232.8308 - val_loss: 214.2091 - 67ms/epoch - 2ms/step\n",
            "Epoch 711/800\n",
            "40/40 - 0s - loss: 229.4568 - val_loss: 217.7074 - 68ms/epoch - 2ms/step\n",
            "Epoch 712/800\n",
            "40/40 - 0s - loss: 226.0363 - val_loss: 209.1312 - 65ms/epoch - 2ms/step\n",
            "Epoch 713/800\n",
            "40/40 - 0s - loss: 219.7443 - val_loss: 201.1083 - 65ms/epoch - 2ms/step\n",
            "Epoch 714/800\n",
            "40/40 - 0s - loss: 212.9851 - val_loss: 198.2274 - 67ms/epoch - 2ms/step\n",
            "Epoch 715/800\n",
            "40/40 - 0s - loss: 209.6153 - val_loss: 192.8553 - 73ms/epoch - 2ms/step\n",
            "Epoch 716/800\n",
            "40/40 - 0s - loss: 209.1758 - val_loss: 188.8787 - 68ms/epoch - 2ms/step\n",
            "Epoch 717/800\n",
            "40/40 - 0s - loss: 206.7666 - val_loss: 188.1057 - 65ms/epoch - 2ms/step\n",
            "Epoch 718/800\n",
            "40/40 - 0s - loss: 203.9817 - val_loss: 189.0426 - 66ms/epoch - 2ms/step\n",
            "Epoch 719/800\n",
            "40/40 - 0s - loss: 212.3258 - val_loss: 195.9456 - 64ms/epoch - 2ms/step\n",
            "Epoch 720/800\n",
            "40/40 - 0s - loss: 209.4467 - val_loss: 190.1340 - 67ms/epoch - 2ms/step\n",
            "Epoch 721/800\n",
            "40/40 - 0s - loss: 208.3324 - val_loss: 188.9238 - 64ms/epoch - 2ms/step\n",
            "Epoch 722/800\n",
            "40/40 - 0s - loss: 204.7590 - val_loss: 184.0519 - 68ms/epoch - 2ms/step\n",
            "Epoch 723/800\n",
            "40/40 - 0s - loss: 207.0851 - val_loss: 192.0140 - 65ms/epoch - 2ms/step\n",
            "Epoch 724/800\n",
            "40/40 - 0s - loss: 213.6995 - val_loss: 196.6586 - 68ms/epoch - 2ms/step\n",
            "Epoch 725/800\n",
            "40/40 - 0s - loss: 212.3861 - val_loss: 193.1369 - 70ms/epoch - 2ms/step\n",
            "Epoch 726/800\n",
            "40/40 - 0s - loss: 214.8365 - val_loss: 208.4306 - 67ms/epoch - 2ms/step\n",
            "Epoch 727/800\n",
            "40/40 - 0s - loss: 222.0869 - val_loss: 208.1208 - 67ms/epoch - 2ms/step\n",
            "Epoch 728/800\n",
            "40/40 - 0s - loss: 222.2470 - val_loss: 212.6278 - 74ms/epoch - 2ms/step\n",
            "Epoch 729/800\n",
            "40/40 - 0s - loss: 226.8673 - val_loss: 218.6085 - 66ms/epoch - 2ms/step\n",
            "Epoch 730/800\n",
            "40/40 - 0s - loss: 232.3652 - val_loss: 214.0820 - 65ms/epoch - 2ms/step\n",
            "Epoch 731/800\n",
            "40/40 - 0s - loss: 239.0119 - val_loss: 218.6527 - 66ms/epoch - 2ms/step\n",
            "Epoch 732/800\n",
            "40/40 - 0s - loss: 253.9201 - val_loss: 234.3997 - 73ms/epoch - 2ms/step\n",
            "Epoch 733/800\n",
            "40/40 - 0s - loss: 248.0573 - val_loss: 245.2215 - 68ms/epoch - 2ms/step\n",
            "Epoch 734/800\n",
            "40/40 - 0s - loss: 260.4474 - val_loss: 235.9154 - 66ms/epoch - 2ms/step\n",
            "Epoch 735/800\n",
            "40/40 - 0s - loss: 242.4678 - val_loss: 218.6993 - 66ms/epoch - 2ms/step\n",
            "Epoch 736/800\n",
            "40/40 - 0s - loss: 232.9798 - val_loss: 215.8056 - 71ms/epoch - 2ms/step\n",
            "Epoch 737/800\n",
            "40/40 - 0s - loss: 228.0430 - val_loss: 209.6647 - 65ms/epoch - 2ms/step\n",
            "Epoch 738/800\n",
            "40/40 - 0s - loss: 227.7524 - val_loss: 205.6550 - 65ms/epoch - 2ms/step\n",
            "Epoch 739/800\n",
            "40/40 - 0s - loss: 218.4341 - val_loss: 196.8829 - 67ms/epoch - 2ms/step\n",
            "Epoch 740/800\n",
            "40/40 - 0s - loss: 213.4559 - val_loss: 195.3658 - 66ms/epoch - 2ms/step\n",
            "Epoch 741/800\n",
            "40/40 - 0s - loss: 212.1712 - val_loss: 194.3599 - 65ms/epoch - 2ms/step\n",
            "Epoch 742/800\n",
            "40/40 - 0s - loss: 211.4250 - val_loss: 198.5229 - 63ms/epoch - 2ms/step\n",
            "Epoch 743/800\n",
            "40/40 - 0s - loss: 223.1787 - val_loss: 201.4785 - 68ms/epoch - 2ms/step\n",
            "Epoch 744/800\n",
            "40/40 - 0s - loss: 213.2181 - val_loss: 190.6873 - 66ms/epoch - 2ms/step\n",
            "Epoch 745/800\n",
            "40/40 - 0s - loss: 211.9380 - val_loss: 198.9064 - 65ms/epoch - 2ms/step\n",
            "Epoch 746/800\n",
            "40/40 - 0s - loss: 215.3814 - val_loss: 200.1774 - 64ms/epoch - 2ms/step\n",
            "Epoch 747/800\n",
            "40/40 - 0s - loss: 211.3415 - val_loss: 189.9364 - 66ms/epoch - 2ms/step\n",
            "Epoch 748/800\n",
            "40/40 - 0s - loss: 211.0178 - val_loss: 192.5378 - 67ms/epoch - 2ms/step\n",
            "Epoch 749/800\n",
            "40/40 - 0s - loss: 213.8641 - val_loss: 193.7691 - 66ms/epoch - 2ms/step\n",
            "Epoch 750/800\n",
            "40/40 - 0s - loss: 210.8182 - val_loss: 194.0056 - 63ms/epoch - 2ms/step\n",
            "Epoch 751/800\n",
            "40/40 - 0s - loss: 207.8646 - val_loss: 190.2098 - 65ms/epoch - 2ms/step\n",
            "Epoch 752/800\n",
            "40/40 - 0s - loss: 204.9694 - val_loss: 186.4616 - 66ms/epoch - 2ms/step\n",
            "Epoch 753/800\n",
            "40/40 - 0s - loss: 204.1135 - val_loss: 190.7384 - 67ms/epoch - 2ms/step\n",
            "Epoch 754/800\n",
            "40/40 - 0s - loss: 204.4291 - val_loss: 186.9393 - 67ms/epoch - 2ms/step\n",
            "Epoch 755/800\n",
            "40/40 - 0s - loss: 208.3376 - val_loss: 191.4830 - 65ms/epoch - 2ms/step\n",
            "Epoch 756/800\n",
            "40/40 - 0s - loss: 206.8532 - val_loss: 193.6689 - 69ms/epoch - 2ms/step\n",
            "Epoch 757/800\n",
            "40/40 - 0s - loss: 212.3898 - val_loss: 209.5329 - 67ms/epoch - 2ms/step\n",
            "Epoch 758/800\n",
            "40/40 - 0s - loss: 221.2982 - val_loss: 199.2976 - 65ms/epoch - 2ms/step\n",
            "Epoch 759/800\n",
            "40/40 - 0s - loss: 223.8195 - val_loss: 215.8505 - 71ms/epoch - 2ms/step\n",
            "Epoch 760/800\n",
            "40/40 - 0s - loss: 232.2155 - val_loss: 216.9294 - 66ms/epoch - 2ms/step\n",
            "Epoch 761/800\n",
            "40/40 - 0s - loss: 226.0126 - val_loss: 204.6084 - 65ms/epoch - 2ms/step\n",
            "Epoch 762/800\n",
            "40/40 - 0s - loss: 232.4529 - val_loss: 225.4278 - 67ms/epoch - 2ms/step\n",
            "Epoch 763/800\n",
            "40/40 - 0s - loss: 242.5689 - val_loss: 251.7477 - 67ms/epoch - 2ms/step\n",
            "Epoch 764/800\n",
            "40/40 - 0s - loss: 245.8398 - val_loss: 217.1388 - 67ms/epoch - 2ms/step\n",
            "Epoch 765/800\n",
            "40/40 - 0s - loss: 233.8444 - val_loss: 214.6743 - 64ms/epoch - 2ms/step\n",
            "Epoch 766/800\n",
            "40/40 - 0s - loss: 233.7265 - val_loss: 223.0408 - 65ms/epoch - 2ms/step\n",
            "Epoch 767/800\n",
            "40/40 - 0s - loss: 234.1299 - val_loss: 204.5699 - 66ms/epoch - 2ms/step\n",
            "Epoch 768/800\n",
            "40/40 - 0s - loss: 227.0089 - val_loss: 207.3937 - 66ms/epoch - 2ms/step\n",
            "Epoch 769/800\n",
            "40/40 - 0s - loss: 226.0790 - val_loss: 216.3207 - 65ms/epoch - 2ms/step\n",
            "Epoch 770/800\n",
            "40/40 - 0s - loss: 225.4658 - val_loss: 200.7443 - 66ms/epoch - 2ms/step\n",
            "Epoch 771/800\n",
            "40/40 - 0s - loss: 216.0783 - val_loss: 193.7670 - 66ms/epoch - 2ms/step\n",
            "Epoch 772/800\n",
            "40/40 - 0s - loss: 210.1732 - val_loss: 190.5815 - 67ms/epoch - 2ms/step\n",
            "Epoch 773/800\n",
            "40/40 - 0s - loss: 210.6719 - val_loss: 190.1928 - 66ms/epoch - 2ms/step\n",
            "Epoch 774/800\n",
            "40/40 - 0s - loss: 217.4470 - val_loss: 200.2780 - 65ms/epoch - 2ms/step\n",
            "Epoch 775/800\n",
            "40/40 - 0s - loss: 212.2986 - val_loss: 190.4667 - 64ms/epoch - 2ms/step\n",
            "Epoch 776/800\n",
            "40/40 - 0s - loss: 208.9361 - val_loss: 194.0369 - 68ms/epoch - 2ms/step\n",
            "Epoch 777/800\n",
            "40/40 - 0s - loss: 207.9945 - val_loss: 191.7227 - 68ms/epoch - 2ms/step\n",
            "Epoch 778/800\n",
            "40/40 - 0s - loss: 217.8279 - val_loss: 201.3909 - 66ms/epoch - 2ms/step\n",
            "Epoch 779/800\n",
            "40/40 - 0s - loss: 223.8428 - val_loss: 218.5719 - 68ms/epoch - 2ms/step\n",
            "Epoch 780/800\n",
            "40/40 - 0s - loss: 232.3642 - val_loss: 211.5051 - 65ms/epoch - 2ms/step\n",
            "Epoch 781/800\n",
            "40/40 - 0s - loss: 243.0566 - val_loss: 218.1860 - 67ms/epoch - 2ms/step\n",
            "Epoch 782/800\n",
            "40/40 - 0s - loss: 233.5588 - val_loss: 203.7192 - 67ms/epoch - 2ms/step\n",
            "Epoch 783/800\n",
            "40/40 - 0s - loss: 219.6535 - val_loss: 196.2819 - 66ms/epoch - 2ms/step\n",
            "Epoch 784/800\n",
            "40/40 - 0s - loss: 212.4747 - val_loss: 193.0269 - 67ms/epoch - 2ms/step\n",
            "Epoch 785/800\n",
            "40/40 - 0s - loss: 213.0663 - val_loss: 196.4933 - 67ms/epoch - 2ms/step\n",
            "Epoch 786/800\n",
            "40/40 - 0s - loss: 213.8087 - val_loss: 197.3893 - 66ms/epoch - 2ms/step\n",
            "Epoch 787/800\n",
            "40/40 - 0s - loss: 214.2175 - val_loss: 194.9538 - 65ms/epoch - 2ms/step\n",
            "Epoch 788/800\n",
            "40/40 - 0s - loss: 213.8444 - val_loss: 202.5932 - 66ms/epoch - 2ms/step\n",
            "Epoch 789/800\n",
            "40/40 - 0s - loss: 223.8660 - val_loss: 203.5313 - 66ms/epoch - 2ms/step\n",
            "Epoch 790/800\n",
            "40/40 - 0s - loss: 222.3229 - val_loss: 206.4455 - 67ms/epoch - 2ms/step\n",
            "Epoch 791/800\n",
            "40/40 - 0s - loss: 221.8593 - val_loss: 197.3124 - 66ms/epoch - 2ms/step\n",
            "Epoch 792/800\n",
            "40/40 - 0s - loss: 215.3295 - val_loss: 195.7379 - 64ms/epoch - 2ms/step\n",
            "Epoch 793/800\n",
            "40/40 - 0s - loss: 221.2142 - val_loss: 207.3165 - 64ms/epoch - 2ms/step\n",
            "Epoch 794/800\n",
            "40/40 - 0s - loss: 216.1186 - val_loss: 198.3014 - 65ms/epoch - 2ms/step\n",
            "Epoch 795/800\n",
            "40/40 - 0s - loss: 212.9637 - val_loss: 194.7617 - 66ms/epoch - 2ms/step\n",
            "Epoch 796/800\n",
            "40/40 - 0s - loss: 216.8994 - val_loss: 200.0572 - 64ms/epoch - 2ms/step\n",
            "Epoch 797/800\n",
            "40/40 - 0s - loss: 220.8904 - val_loss: 202.1908 - 65ms/epoch - 2ms/step\n",
            "Epoch 798/800\n",
            "40/40 - 0s - loss: 220.4446 - val_loss: 208.8174 - 66ms/epoch - 2ms/step\n",
            "Epoch 799/800\n",
            "40/40 - 0s - loss: 218.6172 - val_loss: 203.6216 - 67ms/epoch - 2ms/step\n",
            "Epoch 800/800\n",
            "40/40 - 0s - loss: 221.8958 - val_loss: 214.2098 - 67ms/epoch - 2ms/step\n"
          ]
        }
      ],
      "source": [
        "# fit the autoencoder model to reconstruct input\n",
        "history = model_1.fit(x, x, epochs=800, batch_size=16, verbose=2, validation_data=(x,x))\n",
        "# plot loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "G7pE5XyPTIPs"
      },
      "outputs": [],
      "source": [
        "# define encoder\n",
        "def get_model_2(n_inputs=324):\n",
        "  visible = Input(shape=(n_inputs,))\n",
        "  # encoder level 1\n",
        "  e = Dense(n_inputs)(visible)\n",
        "  # e = BatchNormalization()(e)\n",
        "  e = ReLU()(e)\n",
        "\n",
        "  e = Dense(97)(e)\n",
        "  # e = BatchNormalization()(e)\n",
        "  e = ReLU()(e)\n",
        "\n",
        "  # bottleneck\n",
        "  # n_bottleneck = round(float(n_inputs) / 2.0)\n",
        "  bottleneck = Dense(29)(e)\n",
        "  # e = BatchNormalization()(bottleneck)\n",
        "\n",
        "  e = Dense(97)(bottleneck)\n",
        "  e = ReLU()(e)\n",
        "  # e = BatchNormalization()(e)\n",
        "\n",
        "  # decoder level 1\n",
        "  # d = Dense(n_inputs*2)(bottleneck)\n",
        "  # d = BatchNormalization()(d)\n",
        "  # d = LeakyReLU()(d)\n",
        "  # output layer\n",
        "  output = Dense(n_inputs, activation='linear')(e)\n",
        "  # define autoencoder model\n",
        "  model = Model(inputs=visible, outputs=output)\n",
        "  # compile autoencoder model\n",
        "  model.compile(optimizer='adam', loss='mse')\n",
        "  # plot the autoencoder\n",
        "  # plot_model(model, 'autoencoder_compress.png', show_shapes=True)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGUt6VcmTLtn",
        "outputId": "bcdfddae-8b83-456f-eb11-213a190807cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 324)]             0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 324)               105300    \n",
            "                                                                 \n",
            " re_lu_10 (ReLU)             (None, 324)               0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 97)                31525     \n",
            "                                                                 \n",
            " re_lu_11 (ReLU)             (None, 97)                0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 29)                2842      \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 97)                2910      \n",
            "                                                                 \n",
            " re_lu_12 (ReLU)             (None, 97)                0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 324)               31752     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 174,329\n",
            "Trainable params: 174,329\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_2 = get_model_2()\n",
        "model_2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "ykVYe5KTTOTJ"
      },
      "outputs": [],
      "source": [
        "weight_transfer_layer_model_2 = [1,2,3,8]\n",
        "weight_transfer_from_layer_model_1 = [1,2,3,4]\n",
        "\n",
        "for i in range(len(weight_transfer_layer_model_2)):\n",
        "  model_2_index = weight_transfer_layer_model_2[i]\n",
        "  model_1_index = weight_transfer_from_layer_model_1[i]\n",
        "  model_2.layers[model_2_index] = model_1.layers[model_1_index]\n",
        "  model_2.layers[model_2_index].trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlAKdMiKTSyV",
        "outputId": "d1ae8112-498e-4031-ff29-ef8d86029972"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/800\n",
            "40/40 - 0s - loss: 12539.8838 - val_loss: 8598.7422 - 392ms/epoch - 10ms/step\n",
            "Epoch 2/800\n",
            "40/40 - 0s - loss: 7777.9731 - val_loss: 7026.1582 - 72ms/epoch - 2ms/step\n",
            "Epoch 3/800\n",
            "40/40 - 0s - loss: 6639.1729 - val_loss: 5994.4521 - 78ms/epoch - 2ms/step\n",
            "Epoch 4/800\n",
            "40/40 - 0s - loss: 5669.8916 - val_loss: 5164.0410 - 72ms/epoch - 2ms/step\n",
            "Epoch 5/800\n",
            "40/40 - 0s - loss: 4871.8555 - val_loss: 4367.6743 - 69ms/epoch - 2ms/step\n",
            "Epoch 6/800\n",
            "40/40 - 0s - loss: 4164.6328 - val_loss: 3820.8047 - 75ms/epoch - 2ms/step\n",
            "Epoch 7/800\n",
            "40/40 - 0s - loss: 3697.7861 - val_loss: 3375.1577 - 74ms/epoch - 2ms/step\n",
            "Epoch 8/800\n",
            "40/40 - 0s - loss: 3307.9309 - val_loss: 3067.5925 - 72ms/epoch - 2ms/step\n",
            "Epoch 9/800\n",
            "40/40 - 0s - loss: 3025.2678 - val_loss: 2843.9976 - 77ms/epoch - 2ms/step\n",
            "Epoch 10/800\n",
            "40/40 - 0s - loss: 2795.3508 - val_loss: 2649.4209 - 72ms/epoch - 2ms/step\n",
            "Epoch 11/800\n",
            "40/40 - 0s - loss: 2622.9546 - val_loss: 2505.1858 - 84ms/epoch - 2ms/step\n",
            "Epoch 12/800\n",
            "40/40 - 0s - loss: 2501.4053 - val_loss: 2394.7620 - 81ms/epoch - 2ms/step\n",
            "Epoch 13/800\n",
            "40/40 - 0s - loss: 2365.4939 - val_loss: 2250.2476 - 70ms/epoch - 2ms/step\n",
            "Epoch 14/800\n",
            "40/40 - 0s - loss: 2277.9583 - val_loss: 2172.6648 - 79ms/epoch - 2ms/step\n",
            "Epoch 15/800\n",
            "40/40 - 0s - loss: 2195.3472 - val_loss: 2110.1450 - 77ms/epoch - 2ms/step\n",
            "Epoch 16/800\n",
            "40/40 - 0s - loss: 2128.4431 - val_loss: 2051.6853 - 73ms/epoch - 2ms/step\n",
            "Epoch 17/800\n",
            "40/40 - 0s - loss: 2070.1890 - val_loss: 2015.8711 - 73ms/epoch - 2ms/step\n",
            "Epoch 18/800\n",
            "40/40 - 0s - loss: 2013.1318 - val_loss: 1905.4659 - 70ms/epoch - 2ms/step\n",
            "Epoch 19/800\n",
            "40/40 - 0s - loss: 1964.1859 - val_loss: 1908.4839 - 69ms/epoch - 2ms/step\n",
            "Epoch 20/800\n",
            "40/40 - 0s - loss: 1922.0116 - val_loss: 1870.4208 - 75ms/epoch - 2ms/step\n",
            "Epoch 21/800\n",
            "40/40 - 0s - loss: 1879.5992 - val_loss: 1824.6592 - 71ms/epoch - 2ms/step\n",
            "Epoch 22/800\n",
            "40/40 - 0s - loss: 1854.3612 - val_loss: 1808.8843 - 74ms/epoch - 2ms/step\n",
            "Epoch 23/800\n",
            "40/40 - 0s - loss: 1821.1743 - val_loss: 1815.0798 - 69ms/epoch - 2ms/step\n",
            "Epoch 24/800\n",
            "40/40 - 0s - loss: 1804.7946 - val_loss: 1735.8593 - 72ms/epoch - 2ms/step\n",
            "Epoch 25/800\n",
            "40/40 - 0s - loss: 1758.0216 - val_loss: 1688.5541 - 69ms/epoch - 2ms/step\n",
            "Epoch 26/800\n",
            "40/40 - 0s - loss: 1735.2694 - val_loss: 1709.7107 - 72ms/epoch - 2ms/step\n",
            "Epoch 27/800\n",
            "40/40 - 0s - loss: 1723.9846 - val_loss: 1632.9587 - 75ms/epoch - 2ms/step\n",
            "Epoch 28/800\n",
            "40/40 - 0s - loss: 1692.0599 - val_loss: 1632.2188 - 72ms/epoch - 2ms/step\n",
            "Epoch 29/800\n",
            "40/40 - 0s - loss: 1674.9929 - val_loss: 1620.1672 - 70ms/epoch - 2ms/step\n",
            "Epoch 30/800\n",
            "40/40 - 0s - loss: 1646.0947 - val_loss: 1629.6178 - 79ms/epoch - 2ms/step\n",
            "Epoch 31/800\n",
            "40/40 - 0s - loss: 1638.1101 - val_loss: 1590.6321 - 80ms/epoch - 2ms/step\n",
            "Epoch 32/800\n",
            "40/40 - 0s - loss: 1629.9579 - val_loss: 1576.9987 - 70ms/epoch - 2ms/step\n",
            "Epoch 33/800\n",
            "40/40 - 0s - loss: 1632.3279 - val_loss: 1589.1510 - 74ms/epoch - 2ms/step\n",
            "Epoch 34/800\n",
            "40/40 - 0s - loss: 1627.0731 - val_loss: 1591.3767 - 72ms/epoch - 2ms/step\n",
            "Epoch 35/800\n",
            "40/40 - 0s - loss: 1621.2568 - val_loss: 1593.3208 - 78ms/epoch - 2ms/step\n",
            "Epoch 36/800\n",
            "40/40 - 0s - loss: 1608.0348 - val_loss: 1565.0322 - 70ms/epoch - 2ms/step\n",
            "Epoch 37/800\n",
            "40/40 - 0s - loss: 1583.4799 - val_loss: 1558.8309 - 76ms/epoch - 2ms/step\n",
            "Epoch 38/800\n",
            "40/40 - 0s - loss: 1571.2814 - val_loss: 1538.8041 - 70ms/epoch - 2ms/step\n",
            "Epoch 39/800\n",
            "40/40 - 0s - loss: 1559.1423 - val_loss: 1510.4781 - 87ms/epoch - 2ms/step\n",
            "Epoch 40/800\n",
            "40/40 - 0s - loss: 1544.3922 - val_loss: 1518.9167 - 74ms/epoch - 2ms/step\n",
            "Epoch 41/800\n",
            "40/40 - 0s - loss: 1558.2596 - val_loss: 1522.4186 - 68ms/epoch - 2ms/step\n",
            "Epoch 42/800\n",
            "40/40 - 0s - loss: 1544.0502 - val_loss: 1536.6783 - 77ms/epoch - 2ms/step\n",
            "Epoch 43/800\n",
            "40/40 - 0s - loss: 1563.3624 - val_loss: 1523.1702 - 68ms/epoch - 2ms/step\n",
            "Epoch 44/800\n",
            "40/40 - 0s - loss: 1557.2850 - val_loss: 1529.8427 - 72ms/epoch - 2ms/step\n",
            "Epoch 45/800\n",
            "40/40 - 0s - loss: 1556.9496 - val_loss: 1515.8860 - 79ms/epoch - 2ms/step\n",
            "Epoch 46/800\n",
            "40/40 - 0s - loss: 1554.3115 - val_loss: 1540.0642 - 74ms/epoch - 2ms/step\n",
            "Epoch 47/800\n",
            "40/40 - 0s - loss: 1552.5483 - val_loss: 1523.9441 - 77ms/epoch - 2ms/step\n",
            "Epoch 48/800\n",
            "40/40 - 0s - loss: 1563.4596 - val_loss: 1525.1566 - 80ms/epoch - 2ms/step\n",
            "Epoch 49/800\n",
            "40/40 - 0s - loss: 1558.9292 - val_loss: 1537.7616 - 77ms/epoch - 2ms/step\n",
            "Epoch 50/800\n",
            "40/40 - 0s - loss: 1553.1510 - val_loss: 1524.1317 - 72ms/epoch - 2ms/step\n",
            "Epoch 51/800\n",
            "40/40 - 0s - loss: 1546.1797 - val_loss: 1514.0341 - 83ms/epoch - 2ms/step\n",
            "Epoch 52/800\n",
            "40/40 - 0s - loss: 1524.0466 - val_loss: 1488.1027 - 80ms/epoch - 2ms/step\n",
            "Epoch 53/800\n",
            "40/40 - 0s - loss: 1526.9484 - val_loss: 1480.7467 - 74ms/epoch - 2ms/step\n",
            "Epoch 54/800\n",
            "40/40 - 0s - loss: 1520.1251 - val_loss: 1484.0437 - 73ms/epoch - 2ms/step\n",
            "Epoch 55/800\n",
            "40/40 - 0s - loss: 1517.0625 - val_loss: 1490.8220 - 69ms/epoch - 2ms/step\n",
            "Epoch 56/800\n",
            "40/40 - 0s - loss: 1518.1356 - val_loss: 1475.5116 - 76ms/epoch - 2ms/step\n",
            "Epoch 57/800\n",
            "40/40 - 0s - loss: 1530.9983 - val_loss: 1477.1838 - 76ms/epoch - 2ms/step\n",
            "Epoch 58/800\n",
            "40/40 - 0s - loss: 1532.4877 - val_loss: 1491.4127 - 75ms/epoch - 2ms/step\n",
            "Epoch 59/800\n",
            "40/40 - 0s - loss: 1519.8763 - val_loss: 1491.0405 - 74ms/epoch - 2ms/step\n",
            "Epoch 60/800\n",
            "40/40 - 0s - loss: 1518.3027 - val_loss: 1501.3951 - 70ms/epoch - 2ms/step\n",
            "Epoch 61/800\n",
            "40/40 - 0s - loss: 1530.3403 - val_loss: 1494.3508 - 76ms/epoch - 2ms/step\n",
            "Epoch 62/800\n",
            "40/40 - 0s - loss: 1504.0331 - val_loss: 1462.7423 - 74ms/epoch - 2ms/step\n",
            "Epoch 63/800\n",
            "40/40 - 0s - loss: 1490.5504 - val_loss: 1451.7882 - 73ms/epoch - 2ms/step\n",
            "Epoch 64/800\n",
            "40/40 - 0s - loss: 1475.3892 - val_loss: 1433.8693 - 77ms/epoch - 2ms/step\n",
            "Epoch 65/800\n",
            "40/40 - 0s - loss: 1463.6284 - val_loss: 1424.8856 - 75ms/epoch - 2ms/step\n",
            "Epoch 66/800\n",
            "40/40 - 0s - loss: 1463.7599 - val_loss: 1448.2972 - 74ms/epoch - 2ms/step\n",
            "Epoch 67/800\n",
            "40/40 - 0s - loss: 1469.1436 - val_loss: 1445.4818 - 79ms/epoch - 2ms/step\n",
            "Epoch 68/800\n",
            "40/40 - 0s - loss: 1462.4602 - val_loss: 1435.7412 - 96ms/epoch - 2ms/step\n",
            "Epoch 69/800\n",
            "40/40 - 0s - loss: 1471.9221 - val_loss: 1420.6794 - 78ms/epoch - 2ms/step\n",
            "Epoch 70/800\n",
            "40/40 - 0s - loss: 1464.4645 - val_loss: 1439.0671 - 82ms/epoch - 2ms/step\n",
            "Epoch 71/800\n",
            "40/40 - 0s - loss: 1484.4600 - val_loss: 1461.9530 - 82ms/epoch - 2ms/step\n",
            "Epoch 72/800\n",
            "40/40 - 0s - loss: 1493.3594 - val_loss: 1456.9463 - 76ms/epoch - 2ms/step\n",
            "Epoch 73/800\n",
            "40/40 - 0s - loss: 1500.7427 - val_loss: 1449.0905 - 74ms/epoch - 2ms/step\n",
            "Epoch 74/800\n",
            "40/40 - 0s - loss: 1492.0841 - val_loss: 1454.3907 - 78ms/epoch - 2ms/step\n",
            "Epoch 75/800\n",
            "40/40 - 0s - loss: 1484.5734 - val_loss: 1456.6455 - 76ms/epoch - 2ms/step\n",
            "Epoch 76/800\n",
            "40/40 - 0s - loss: 1460.9207 - val_loss: 1434.2084 - 71ms/epoch - 2ms/step\n",
            "Epoch 77/800\n",
            "40/40 - 0s - loss: 1462.3667 - val_loss: 1442.0598 - 74ms/epoch - 2ms/step\n",
            "Epoch 78/800\n",
            "40/40 - 0s - loss: 1489.9539 - val_loss: 1450.9817 - 71ms/epoch - 2ms/step\n",
            "Epoch 79/800\n",
            "40/40 - 0s - loss: 1467.8406 - val_loss: 1420.9855 - 71ms/epoch - 2ms/step\n",
            "Epoch 80/800\n",
            "40/40 - 0s - loss: 1459.6150 - val_loss: 1439.3126 - 73ms/epoch - 2ms/step\n",
            "Epoch 81/800\n",
            "40/40 - 0s - loss: 1457.9862 - val_loss: 1415.6312 - 73ms/epoch - 2ms/step\n",
            "Epoch 82/800\n",
            "40/40 - 0s - loss: 1440.6968 - val_loss: 1420.5060 - 75ms/epoch - 2ms/step\n",
            "Epoch 83/800\n",
            "40/40 - 0s - loss: 1427.6307 - val_loss: 1397.2222 - 83ms/epoch - 2ms/step\n",
            "Epoch 84/800\n",
            "40/40 - 0s - loss: 1411.5409 - val_loss: 1385.6879 - 71ms/epoch - 2ms/step\n",
            "Epoch 85/800\n",
            "40/40 - 0s - loss: 1416.2852 - val_loss: 1393.9728 - 74ms/epoch - 2ms/step\n",
            "Epoch 86/800\n",
            "40/40 - 0s - loss: 1413.2865 - val_loss: 1381.7968 - 87ms/epoch - 2ms/step\n",
            "Epoch 87/800\n",
            "40/40 - 0s - loss: 1419.7341 - val_loss: 1413.3545 - 72ms/epoch - 2ms/step\n",
            "Epoch 88/800\n",
            "40/40 - 0s - loss: 1439.5792 - val_loss: 1393.7550 - 77ms/epoch - 2ms/step\n",
            "Epoch 89/800\n",
            "40/40 - 0s - loss: 1434.2450 - val_loss: 1395.7222 - 80ms/epoch - 2ms/step\n",
            "Epoch 90/800\n",
            "40/40 - 0s - loss: 1443.1611 - val_loss: 1394.3375 - 76ms/epoch - 2ms/step\n",
            "Epoch 91/800\n",
            "40/40 - 0s - loss: 1448.6451 - val_loss: 1409.6750 - 71ms/epoch - 2ms/step\n",
            "Epoch 92/800\n",
            "40/40 - 0s - loss: 1454.4010 - val_loss: 1449.4504 - 68ms/epoch - 2ms/step\n",
            "Epoch 93/800\n",
            "40/40 - 0s - loss: 1507.2089 - val_loss: 1437.3002 - 75ms/epoch - 2ms/step\n",
            "Epoch 94/800\n",
            "40/40 - 0s - loss: 1457.7239 - val_loss: 1414.3043 - 69ms/epoch - 2ms/step\n",
            "Epoch 95/800\n",
            "40/40 - 0s - loss: 1414.7336 - val_loss: 1390.3345 - 80ms/epoch - 2ms/step\n",
            "Epoch 96/800\n",
            "40/40 - 0s - loss: 1402.9816 - val_loss: 1362.5691 - 78ms/epoch - 2ms/step\n",
            "Epoch 97/800\n",
            "40/40 - 0s - loss: 1402.1134 - val_loss: 1355.5029 - 73ms/epoch - 2ms/step\n",
            "Epoch 98/800\n",
            "40/40 - 0s - loss: 1393.3309 - val_loss: 1377.1154 - 83ms/epoch - 2ms/step\n",
            "Epoch 99/800\n",
            "40/40 - 0s - loss: 1393.6621 - val_loss: 1351.7087 - 73ms/epoch - 2ms/step\n",
            "Epoch 100/800\n",
            "40/40 - 0s - loss: 1381.1531 - val_loss: 1345.6399 - 75ms/epoch - 2ms/step\n",
            "Epoch 101/800\n",
            "40/40 - 0s - loss: 1371.8187 - val_loss: 1330.1622 - 78ms/epoch - 2ms/step\n",
            "Epoch 102/800\n",
            "40/40 - 0s - loss: 1369.2167 - val_loss: 1320.3934 - 72ms/epoch - 2ms/step\n",
            "Epoch 103/800\n",
            "40/40 - 0s - loss: 1374.0348 - val_loss: 1399.3361 - 79ms/epoch - 2ms/step\n",
            "Epoch 104/800\n",
            "40/40 - 0s - loss: 1400.1376 - val_loss: 1354.8251 - 75ms/epoch - 2ms/step\n",
            "Epoch 105/800\n",
            "40/40 - 0s - loss: 1388.1722 - val_loss: 1372.7213 - 75ms/epoch - 2ms/step\n",
            "Epoch 106/800\n",
            "40/40 - 0s - loss: 1379.3722 - val_loss: 1340.6973 - 86ms/epoch - 2ms/step\n",
            "Epoch 107/800\n",
            "40/40 - 0s - loss: 1364.2264 - val_loss: 1341.0179 - 75ms/epoch - 2ms/step\n",
            "Epoch 108/800\n",
            "40/40 - 0s - loss: 1366.4746 - val_loss: 1340.3420 - 115ms/epoch - 3ms/step\n",
            "Epoch 109/800\n",
            "40/40 - 0s - loss: 1381.1396 - val_loss: 1340.1824 - 82ms/epoch - 2ms/step\n",
            "Epoch 110/800\n",
            "40/40 - 0s - loss: 1373.0446 - val_loss: 1338.6736 - 97ms/epoch - 2ms/step\n",
            "Epoch 111/800\n",
            "40/40 - 0s - loss: 1359.3145 - val_loss: 1312.0753 - 77ms/epoch - 2ms/step\n",
            "Epoch 112/800\n",
            "40/40 - 0s - loss: 1342.8743 - val_loss: 1308.9342 - 73ms/epoch - 2ms/step\n",
            "Epoch 113/800\n",
            "40/40 - 0s - loss: 1347.7454 - val_loss: 1344.3577 - 78ms/epoch - 2ms/step\n",
            "Epoch 114/800\n",
            "40/40 - 0s - loss: 1396.1750 - val_loss: 1393.0635 - 76ms/epoch - 2ms/step\n",
            "Epoch 115/800\n",
            "40/40 - 0s - loss: 1403.2485 - val_loss: 1348.3518 - 72ms/epoch - 2ms/step\n",
            "Epoch 116/800\n",
            "40/40 - 0s - loss: 1423.9639 - val_loss: 1394.7930 - 75ms/epoch - 2ms/step\n",
            "Epoch 117/800\n",
            "40/40 - 0s - loss: 1417.2043 - val_loss: 1387.8899 - 73ms/epoch - 2ms/step\n",
            "Epoch 118/800\n",
            "40/40 - 0s - loss: 1382.9342 - val_loss: 1334.2538 - 80ms/epoch - 2ms/step\n",
            "Epoch 119/800\n",
            "40/40 - 0s - loss: 1354.1843 - val_loss: 1309.9867 - 74ms/epoch - 2ms/step\n",
            "Epoch 120/800\n",
            "40/40 - 0s - loss: 1356.8927 - val_loss: 1304.5793 - 77ms/epoch - 2ms/step\n",
            "Epoch 121/800\n",
            "40/40 - 0s - loss: 1331.5824 - val_loss: 1300.8002 - 78ms/epoch - 2ms/step\n",
            "Epoch 122/800\n",
            "40/40 - 0s - loss: 1334.3680 - val_loss: 1290.2870 - 79ms/epoch - 2ms/step\n",
            "Epoch 123/800\n",
            "40/40 - 0s - loss: 1326.1294 - val_loss: 1305.6119 - 69ms/epoch - 2ms/step\n",
            "Epoch 124/800\n",
            "40/40 - 0s - loss: 1327.6165 - val_loss: 1292.1661 - 77ms/epoch - 2ms/step\n",
            "Epoch 125/800\n",
            "40/40 - 0s - loss: 1312.7499 - val_loss: 1262.9021 - 75ms/epoch - 2ms/step\n",
            "Epoch 126/800\n",
            "40/40 - 0s - loss: 1294.4177 - val_loss: 1254.8151 - 78ms/epoch - 2ms/step\n",
            "Epoch 127/800\n",
            "40/40 - 0s - loss: 1288.1858 - val_loss: 1255.0809 - 75ms/epoch - 2ms/step\n",
            "Epoch 128/800\n",
            "40/40 - 0s - loss: 1282.2563 - val_loss: 1255.3691 - 84ms/epoch - 2ms/step\n",
            "Epoch 129/800\n",
            "40/40 - 0s - loss: 1283.4191 - val_loss: 1235.9917 - 74ms/epoch - 2ms/step\n",
            "Epoch 130/800\n",
            "40/40 - 0s - loss: 1280.9524 - val_loss: 1242.6034 - 79ms/epoch - 2ms/step\n",
            "Epoch 131/800\n",
            "40/40 - 0s - loss: 1282.2737 - val_loss: 1246.7563 - 81ms/epoch - 2ms/step\n",
            "Epoch 132/800\n",
            "40/40 - 0s - loss: 1277.5073 - val_loss: 1240.4125 - 84ms/epoch - 2ms/step\n",
            "Epoch 133/800\n",
            "40/40 - 0s - loss: 1283.0068 - val_loss: 1267.8698 - 75ms/epoch - 2ms/step\n",
            "Epoch 134/800\n",
            "40/40 - 0s - loss: 1297.4463 - val_loss: 1272.2424 - 71ms/epoch - 2ms/step\n",
            "Epoch 135/800\n",
            "40/40 - 0s - loss: 1302.5734 - val_loss: 1252.7301 - 75ms/epoch - 2ms/step\n",
            "Epoch 136/800\n",
            "40/40 - 0s - loss: 1302.3690 - val_loss: 1273.8606 - 77ms/epoch - 2ms/step\n",
            "Epoch 137/800\n",
            "40/40 - 0s - loss: 1299.7543 - val_loss: 1266.5702 - 74ms/epoch - 2ms/step\n",
            "Epoch 138/800\n",
            "40/40 - 0s - loss: 1288.3712 - val_loss: 1250.0718 - 78ms/epoch - 2ms/step\n",
            "Epoch 139/800\n",
            "40/40 - 0s - loss: 1283.0436 - val_loss: 1245.2778 - 74ms/epoch - 2ms/step\n",
            "Epoch 140/800\n",
            "40/40 - 0s - loss: 1285.9202 - val_loss: 1278.6475 - 81ms/epoch - 2ms/step\n",
            "Epoch 141/800\n",
            "40/40 - 0s - loss: 1332.0305 - val_loss: 1321.1285 - 81ms/epoch - 2ms/step\n",
            "Epoch 142/800\n",
            "40/40 - 0s - loss: 1361.5139 - val_loss: 1303.0845 - 74ms/epoch - 2ms/step\n",
            "Epoch 143/800\n",
            "40/40 - 0s - loss: 1338.0966 - val_loss: 1301.0621 - 79ms/epoch - 2ms/step\n",
            "Epoch 144/800\n",
            "40/40 - 0s - loss: 1317.0394 - val_loss: 1285.1990 - 85ms/epoch - 2ms/step\n",
            "Epoch 145/800\n",
            "40/40 - 0s - loss: 1299.3243 - val_loss: 1252.8113 - 71ms/epoch - 2ms/step\n",
            "Epoch 146/800\n",
            "40/40 - 0s - loss: 1276.9586 - val_loss: 1240.5210 - 78ms/epoch - 2ms/step\n",
            "Epoch 147/800\n",
            "40/40 - 0s - loss: 1272.5819 - val_loss: 1216.0247 - 77ms/epoch - 2ms/step\n",
            "Epoch 148/800\n",
            "40/40 - 0s - loss: 1266.6086 - val_loss: 1221.0411 - 74ms/epoch - 2ms/step\n",
            "Epoch 149/800\n",
            "40/40 - 0s - loss: 1252.7679 - val_loss: 1216.0767 - 78ms/epoch - 2ms/step\n",
            "Epoch 150/800\n",
            "40/40 - 0s - loss: 1257.1323 - val_loss: 1220.8229 - 73ms/epoch - 2ms/step\n",
            "Epoch 151/800\n",
            "40/40 - 0s - loss: 1250.1326 - val_loss: 1212.5793 - 83ms/epoch - 2ms/step\n",
            "Epoch 152/800\n",
            "40/40 - 0s - loss: 1246.1068 - val_loss: 1224.9543 - 79ms/epoch - 2ms/step\n",
            "Epoch 153/800\n",
            "40/40 - 0s - loss: 1257.8132 - val_loss: 1222.1178 - 75ms/epoch - 2ms/step\n",
            "Epoch 154/800\n",
            "40/40 - 0s - loss: 1254.6196 - val_loss: 1229.3608 - 70ms/epoch - 2ms/step\n",
            "Epoch 155/800\n",
            "40/40 - 0s - loss: 1257.9529 - val_loss: 1204.1088 - 72ms/epoch - 2ms/step\n",
            "Epoch 156/800\n",
            "40/40 - 0s - loss: 1253.1274 - val_loss: 1213.7898 - 77ms/epoch - 2ms/step\n",
            "Epoch 157/800\n",
            "40/40 - 0s - loss: 1254.5640 - val_loss: 1191.2765 - 74ms/epoch - 2ms/step\n",
            "Epoch 158/800\n",
            "40/40 - 0s - loss: 1237.9984 - val_loss: 1211.2502 - 72ms/epoch - 2ms/step\n",
            "Epoch 159/800\n",
            "40/40 - 0s - loss: 1241.9609 - val_loss: 1203.8778 - 75ms/epoch - 2ms/step\n",
            "Epoch 160/800\n",
            "40/40 - 0s - loss: 1258.3334 - val_loss: 1226.0220 - 86ms/epoch - 2ms/step\n",
            "Epoch 161/800\n",
            "40/40 - 0s - loss: 1258.0677 - val_loss: 1210.6606 - 81ms/epoch - 2ms/step\n",
            "Epoch 162/800\n",
            "40/40 - 0s - loss: 1247.6589 - val_loss: 1192.5365 - 77ms/epoch - 2ms/step\n",
            "Epoch 163/800\n",
            "40/40 - 0s - loss: 1233.9222 - val_loss: 1194.0839 - 78ms/epoch - 2ms/step\n",
            "Epoch 164/800\n",
            "40/40 - 0s - loss: 1231.1736 - val_loss: 1194.0105 - 72ms/epoch - 2ms/step\n",
            "Epoch 165/800\n",
            "40/40 - 0s - loss: 1226.3322 - val_loss: 1187.1401 - 86ms/epoch - 2ms/step\n",
            "Epoch 166/800\n",
            "40/40 - 0s - loss: 1221.4841 - val_loss: 1167.1932 - 77ms/epoch - 2ms/step\n",
            "Epoch 167/800\n",
            "40/40 - 0s - loss: 1210.3906 - val_loss: 1171.9100 - 85ms/epoch - 2ms/step\n",
            "Epoch 168/800\n",
            "40/40 - 0s - loss: 1209.8445 - val_loss: 1166.3005 - 79ms/epoch - 2ms/step\n",
            "Epoch 169/800\n",
            "40/40 - 0s - loss: 1194.0154 - val_loss: 1155.6610 - 77ms/epoch - 2ms/step\n",
            "Epoch 170/800\n",
            "40/40 - 0s - loss: 1197.3510 - val_loss: 1162.4751 - 70ms/epoch - 2ms/step\n",
            "Epoch 171/800\n",
            "40/40 - 0s - loss: 1196.2979 - val_loss: 1181.5200 - 77ms/epoch - 2ms/step\n",
            "Epoch 172/800\n",
            "40/40 - 0s - loss: 1206.8875 - val_loss: 1170.3289 - 72ms/epoch - 2ms/step\n",
            "Epoch 173/800\n",
            "40/40 - 0s - loss: 1204.5310 - val_loss: 1180.4313 - 73ms/epoch - 2ms/step\n",
            "Epoch 174/800\n",
            "40/40 - 0s - loss: 1198.3983 - val_loss: 1159.5143 - 72ms/epoch - 2ms/step\n",
            "Epoch 175/800\n",
            "40/40 - 0s - loss: 1211.2556 - val_loss: 1176.9640 - 72ms/epoch - 2ms/step\n",
            "Epoch 176/800\n",
            "40/40 - 0s - loss: 1215.6852 - val_loss: 1203.5374 - 80ms/epoch - 2ms/step\n",
            "Epoch 177/800\n",
            "40/40 - 0s - loss: 1220.1311 - val_loss: 1180.2494 - 71ms/epoch - 2ms/step\n",
            "Epoch 178/800\n",
            "40/40 - 0s - loss: 1221.9294 - val_loss: 1178.5033 - 73ms/epoch - 2ms/step\n",
            "Epoch 179/800\n",
            "40/40 - 0s - loss: 1199.5396 - val_loss: 1175.4543 - 77ms/epoch - 2ms/step\n",
            "Epoch 180/800\n",
            "40/40 - 0s - loss: 1188.3760 - val_loss: 1159.8647 - 78ms/epoch - 2ms/step\n",
            "Epoch 181/800\n",
            "40/40 - 0s - loss: 1183.8077 - val_loss: 1150.3844 - 74ms/epoch - 2ms/step\n",
            "Epoch 182/800\n",
            "40/40 - 0s - loss: 1183.8131 - val_loss: 1155.4551 - 71ms/epoch - 2ms/step\n",
            "Epoch 183/800\n",
            "40/40 - 0s - loss: 1190.6793 - val_loss: 1148.6648 - 70ms/epoch - 2ms/step\n",
            "Epoch 184/800\n",
            "40/40 - 0s - loss: 1199.3572 - val_loss: 1160.7316 - 78ms/epoch - 2ms/step\n",
            "Epoch 185/800\n",
            "40/40 - 0s - loss: 1194.3109 - val_loss: 1142.5599 - 80ms/epoch - 2ms/step\n",
            "Epoch 186/800\n",
            "40/40 - 0s - loss: 1183.0839 - val_loss: 1136.2411 - 75ms/epoch - 2ms/step\n",
            "Epoch 187/800\n",
            "40/40 - 0s - loss: 1185.3809 - val_loss: 1160.3485 - 80ms/epoch - 2ms/step\n",
            "Epoch 188/800\n",
            "40/40 - 0s - loss: 1199.3154 - val_loss: 1180.0726 - 81ms/epoch - 2ms/step\n",
            "Epoch 189/800\n",
            "40/40 - 0s - loss: 1194.8333 - val_loss: 1137.8011 - 72ms/epoch - 2ms/step\n",
            "Epoch 190/800\n",
            "40/40 - 0s - loss: 1176.2322 - val_loss: 1179.7842 - 76ms/epoch - 2ms/step\n",
            "Epoch 191/800\n",
            "40/40 - 0s - loss: 1195.8877 - val_loss: 1142.7468 - 74ms/epoch - 2ms/step\n",
            "Epoch 192/800\n",
            "40/40 - 0s - loss: 1193.8090 - val_loss: 1164.6173 - 70ms/epoch - 2ms/step\n",
            "Epoch 193/800\n",
            "40/40 - 0s - loss: 1199.2906 - val_loss: 1156.1061 - 73ms/epoch - 2ms/step\n",
            "Epoch 194/800\n",
            "40/40 - 0s - loss: 1175.7404 - val_loss: 1121.6859 - 74ms/epoch - 2ms/step\n",
            "Epoch 195/800\n",
            "40/40 - 0s - loss: 1155.3253 - val_loss: 1116.5557 - 69ms/epoch - 2ms/step\n",
            "Epoch 196/800\n",
            "40/40 - 0s - loss: 1152.9600 - val_loss: 1110.0280 - 69ms/epoch - 2ms/step\n",
            "Epoch 197/800\n",
            "40/40 - 0s - loss: 1145.9501 - val_loss: 1110.2084 - 73ms/epoch - 2ms/step\n",
            "Epoch 198/800\n",
            "40/40 - 0s - loss: 1145.9937 - val_loss: 1115.4602 - 77ms/epoch - 2ms/step\n",
            "Epoch 199/800\n",
            "40/40 - 0s - loss: 1170.5627 - val_loss: 1144.0980 - 74ms/epoch - 2ms/step\n",
            "Epoch 200/800\n",
            "40/40 - 0s - loss: 1172.8029 - val_loss: 1112.4008 - 72ms/epoch - 2ms/step\n",
            "Epoch 201/800\n",
            "40/40 - 0s - loss: 1162.0725 - val_loss: 1129.4766 - 75ms/epoch - 2ms/step\n",
            "Epoch 202/800\n",
            "40/40 - 0s - loss: 1151.4966 - val_loss: 1111.3854 - 71ms/epoch - 2ms/step\n",
            "Epoch 203/800\n",
            "40/40 - 0s - loss: 1160.0527 - val_loss: 1135.8568 - 79ms/epoch - 2ms/step\n",
            "Epoch 204/800\n",
            "40/40 - 0s - loss: 1163.3536 - val_loss: 1140.4453 - 70ms/epoch - 2ms/step\n",
            "Epoch 205/800\n",
            "40/40 - 0s - loss: 1164.1230 - val_loss: 1155.1725 - 77ms/epoch - 2ms/step\n",
            "Epoch 206/800\n",
            "40/40 - 0s - loss: 1192.8341 - val_loss: 1131.2356 - 73ms/epoch - 2ms/step\n",
            "Epoch 207/800\n",
            "40/40 - 0s - loss: 1175.3209 - val_loss: 1115.6573 - 77ms/epoch - 2ms/step\n",
            "Epoch 208/800\n",
            "40/40 - 0s - loss: 1196.6730 - val_loss: 1184.0315 - 79ms/epoch - 2ms/step\n",
            "Epoch 209/800\n",
            "40/40 - 0s - loss: 1198.7183 - val_loss: 1141.2230 - 75ms/epoch - 2ms/step\n",
            "Epoch 210/800\n",
            "40/40 - 0s - loss: 1174.0194 - val_loss: 1119.9438 - 80ms/epoch - 2ms/step\n",
            "Epoch 211/800\n",
            "40/40 - 0s - loss: 1167.5352 - val_loss: 1102.6912 - 81ms/epoch - 2ms/step\n",
            "Epoch 212/800\n",
            "40/40 - 0s - loss: 1149.2474 - val_loss: 1107.2283 - 73ms/epoch - 2ms/step\n",
            "Epoch 213/800\n",
            "40/40 - 0s - loss: 1140.2631 - val_loss: 1083.8635 - 68ms/epoch - 2ms/step\n",
            "Epoch 214/800\n",
            "40/40 - 0s - loss: 1118.6193 - val_loss: 1086.6378 - 82ms/epoch - 2ms/step\n",
            "Epoch 215/800\n",
            "40/40 - 0s - loss: 1113.3495 - val_loss: 1070.1948 - 68ms/epoch - 2ms/step\n",
            "Epoch 216/800\n",
            "40/40 - 0s - loss: 1105.4408 - val_loss: 1069.3516 - 71ms/epoch - 2ms/step\n",
            "Epoch 217/800\n",
            "40/40 - 0s - loss: 1100.9662 - val_loss: 1066.0824 - 68ms/epoch - 2ms/step\n",
            "Epoch 218/800\n",
            "40/40 - 0s - loss: 1101.1594 - val_loss: 1071.1753 - 75ms/epoch - 2ms/step\n",
            "Epoch 219/800\n",
            "40/40 - 0s - loss: 1099.4104 - val_loss: 1064.0632 - 73ms/epoch - 2ms/step\n",
            "Epoch 220/800\n",
            "40/40 - 0s - loss: 1106.9449 - val_loss: 1069.4758 - 69ms/epoch - 2ms/step\n",
            "Epoch 221/800\n",
            "40/40 - 0s - loss: 1121.1199 - val_loss: 1086.6742 - 78ms/epoch - 2ms/step\n",
            "Epoch 222/800\n",
            "40/40 - 0s - loss: 1144.1321 - val_loss: 1102.3032 - 73ms/epoch - 2ms/step\n",
            "Epoch 223/800\n",
            "40/40 - 0s - loss: 1152.6833 - val_loss: 1121.3225 - 70ms/epoch - 2ms/step\n",
            "Epoch 224/800\n",
            "40/40 - 0s - loss: 1158.4142 - val_loss: 1115.7505 - 77ms/epoch - 2ms/step\n",
            "Epoch 225/800\n",
            "40/40 - 0s - loss: 1141.1379 - val_loss: 1091.6404 - 75ms/epoch - 2ms/step\n",
            "Epoch 226/800\n",
            "40/40 - 0s - loss: 1124.3114 - val_loss: 1089.5028 - 87ms/epoch - 2ms/step\n",
            "Epoch 227/800\n",
            "40/40 - 0s - loss: 1130.7268 - val_loss: 1077.8583 - 81ms/epoch - 2ms/step\n",
            "Epoch 228/800\n",
            "40/40 - 0s - loss: 1111.8185 - val_loss: 1087.8591 - 74ms/epoch - 2ms/step\n",
            "Epoch 229/800\n",
            "40/40 - 0s - loss: 1126.2687 - val_loss: 1079.6669 - 76ms/epoch - 2ms/step\n",
            "Epoch 230/800\n",
            "40/40 - 0s - loss: 1121.5599 - val_loss: 1084.3466 - 70ms/epoch - 2ms/step\n",
            "Epoch 231/800\n",
            "40/40 - 0s - loss: 1126.2659 - val_loss: 1103.8191 - 79ms/epoch - 2ms/step\n",
            "Epoch 232/800\n",
            "40/40 - 0s - loss: 1120.0461 - val_loss: 1091.6666 - 69ms/epoch - 2ms/step\n",
            "Epoch 233/800\n",
            "40/40 - 0s - loss: 1127.4020 - val_loss: 1073.7069 - 70ms/epoch - 2ms/step\n",
            "Epoch 234/800\n",
            "40/40 - 0s - loss: 1100.1086 - val_loss: 1072.9508 - 80ms/epoch - 2ms/step\n",
            "Epoch 235/800\n",
            "40/40 - 0s - loss: 1129.9203 - val_loss: 1131.0865 - 71ms/epoch - 2ms/step\n",
            "Epoch 236/800\n",
            "40/40 - 0s - loss: 1178.2179 - val_loss: 1122.8057 - 70ms/epoch - 2ms/step\n",
            "Epoch 237/800\n",
            "40/40 - 0s - loss: 1146.7782 - val_loss: 1079.1711 - 70ms/epoch - 2ms/step\n",
            "Epoch 238/800\n",
            "40/40 - 0s - loss: 1112.2886 - val_loss: 1092.8993 - 77ms/epoch - 2ms/step\n",
            "Epoch 239/800\n",
            "40/40 - 0s - loss: 1101.6232 - val_loss: 1052.5819 - 70ms/epoch - 2ms/step\n",
            "Epoch 240/800\n",
            "40/40 - 0s - loss: 1083.0793 - val_loss: 1041.9805 - 73ms/epoch - 2ms/step\n",
            "Epoch 241/800\n",
            "40/40 - 0s - loss: 1074.9164 - val_loss: 1031.9619 - 72ms/epoch - 2ms/step\n",
            "Epoch 242/800\n",
            "40/40 - 0s - loss: 1078.9412 - val_loss: 1050.5042 - 68ms/epoch - 2ms/step\n",
            "Epoch 243/800\n",
            "40/40 - 0s - loss: 1078.4462 - val_loss: 1042.3444 - 81ms/epoch - 2ms/step\n",
            "Epoch 244/800\n",
            "40/40 - 0s - loss: 1073.9484 - val_loss: 1045.7772 - 76ms/epoch - 2ms/step\n",
            "Epoch 245/800\n",
            "40/40 - 0s - loss: 1077.1346 - val_loss: 1045.5599 - 74ms/epoch - 2ms/step\n",
            "Epoch 246/800\n",
            "40/40 - 0s - loss: 1090.0396 - val_loss: 1046.2262 - 74ms/epoch - 2ms/step\n",
            "Epoch 247/800\n",
            "40/40 - 0s - loss: 1077.2073 - val_loss: 1045.7318 - 74ms/epoch - 2ms/step\n",
            "Epoch 248/800\n",
            "40/40 - 0s - loss: 1077.2256 - val_loss: 1050.3656 - 75ms/epoch - 2ms/step\n",
            "Epoch 249/800\n",
            "40/40 - 0s - loss: 1103.6674 - val_loss: 1064.3711 - 70ms/epoch - 2ms/step\n",
            "Epoch 250/800\n",
            "40/40 - 0s - loss: 1104.2766 - val_loss: 1071.7183 - 82ms/epoch - 2ms/step\n",
            "Epoch 251/800\n",
            "40/40 - 0s - loss: 1092.6305 - val_loss: 1038.6705 - 84ms/epoch - 2ms/step\n",
            "Epoch 252/800\n",
            "40/40 - 0s - loss: 1077.0973 - val_loss: 1026.8656 - 70ms/epoch - 2ms/step\n",
            "Epoch 253/800\n",
            "40/40 - 0s - loss: 1079.1554 - val_loss: 1040.8883 - 70ms/epoch - 2ms/step\n",
            "Epoch 254/800\n",
            "40/40 - 0s - loss: 1079.3019 - val_loss: 1045.4233 - 85ms/epoch - 2ms/step\n",
            "Epoch 255/800\n",
            "40/40 - 0s - loss: 1081.2427 - val_loss: 1042.8541 - 73ms/epoch - 2ms/step\n",
            "Epoch 256/800\n",
            "40/40 - 0s - loss: 1077.4377 - val_loss: 1037.9258 - 71ms/epoch - 2ms/step\n",
            "Epoch 257/800\n",
            "40/40 - 0s - loss: 1081.5393 - val_loss: 1033.7130 - 71ms/epoch - 2ms/step\n",
            "Epoch 258/800\n",
            "40/40 - 0s - loss: 1076.8160 - val_loss: 1063.4691 - 81ms/epoch - 2ms/step\n",
            "Epoch 259/800\n",
            "40/40 - 0s - loss: 1092.2512 - val_loss: 1055.7979 - 72ms/epoch - 2ms/step\n",
            "Epoch 260/800\n",
            "40/40 - 0s - loss: 1105.5103 - val_loss: 1050.8748 - 69ms/epoch - 2ms/step\n",
            "Epoch 261/800\n",
            "40/40 - 0s - loss: 1090.6993 - val_loss: 1056.0853 - 73ms/epoch - 2ms/step\n",
            "Epoch 262/800\n",
            "40/40 - 0s - loss: 1083.8120 - val_loss: 1030.3198 - 74ms/epoch - 2ms/step\n",
            "Epoch 263/800\n",
            "40/40 - 0s - loss: 1075.7039 - val_loss: 1047.0846 - 69ms/epoch - 2ms/step\n",
            "Epoch 264/800\n",
            "40/40 - 0s - loss: 1071.1989 - val_loss: 1026.2303 - 79ms/epoch - 2ms/step\n",
            "Epoch 265/800\n",
            "40/40 - 0s - loss: 1066.7128 - val_loss: 1048.5839 - 75ms/epoch - 2ms/step\n",
            "Epoch 266/800\n",
            "40/40 - 0s - loss: 1064.1062 - val_loss: 1040.3809 - 75ms/epoch - 2ms/step\n",
            "Epoch 267/800\n",
            "40/40 - 0s - loss: 1105.0171 - val_loss: 1069.1804 - 71ms/epoch - 2ms/step\n",
            "Epoch 268/800\n",
            "40/40 - 0s - loss: 1089.1205 - val_loss: 1041.4323 - 73ms/epoch - 2ms/step\n",
            "Epoch 269/800\n",
            "40/40 - 0s - loss: 1076.2625 - val_loss: 1020.1664 - 77ms/epoch - 2ms/step\n",
            "Epoch 270/800\n",
            "40/40 - 0s - loss: 1060.6470 - val_loss: 1010.0150 - 74ms/epoch - 2ms/step\n",
            "Epoch 271/800\n",
            "40/40 - 0s - loss: 1059.9750 - val_loss: 1043.9427 - 73ms/epoch - 2ms/step\n",
            "Epoch 272/800\n",
            "40/40 - 0s - loss: 1062.0265 - val_loss: 1013.7948 - 74ms/epoch - 2ms/step\n",
            "Epoch 273/800\n",
            "40/40 - 0s - loss: 1047.6082 - val_loss: 1006.8657 - 75ms/epoch - 2ms/step\n",
            "Epoch 274/800\n",
            "40/40 - 0s - loss: 1043.6687 - val_loss: 1017.2184 - 76ms/epoch - 2ms/step\n",
            "Epoch 275/800\n",
            "40/40 - 0s - loss: 1042.1638 - val_loss: 997.8371 - 69ms/epoch - 2ms/step\n",
            "Epoch 276/800\n",
            "40/40 - 0s - loss: 1034.3236 - val_loss: 990.8388 - 77ms/epoch - 2ms/step\n",
            "Epoch 277/800\n",
            "40/40 - 0s - loss: 1039.3336 - val_loss: 1009.6688 - 74ms/epoch - 2ms/step\n",
            "Epoch 278/800\n",
            "40/40 - 0s - loss: 1050.6335 - val_loss: 1013.9787 - 74ms/epoch - 2ms/step\n",
            "Epoch 279/800\n",
            "40/40 - 0s - loss: 1070.6041 - val_loss: 1046.3490 - 70ms/epoch - 2ms/step\n",
            "Epoch 280/800\n",
            "40/40 - 0s - loss: 1066.7126 - val_loss: 1021.2255 - 70ms/epoch - 2ms/step\n",
            "Epoch 281/800\n",
            "40/40 - 0s - loss: 1055.6006 - val_loss: 1024.8983 - 75ms/epoch - 2ms/step\n",
            "Epoch 282/800\n",
            "40/40 - 0s - loss: 1040.9343 - val_loss: 996.2843 - 70ms/epoch - 2ms/step\n",
            "Epoch 283/800\n",
            "40/40 - 0s - loss: 1044.4161 - val_loss: 1019.4578 - 72ms/epoch - 2ms/step\n",
            "Epoch 284/800\n",
            "40/40 - 0s - loss: 1047.8088 - val_loss: 1040.9744 - 80ms/epoch - 2ms/step\n",
            "Epoch 285/800\n",
            "40/40 - 0s - loss: 1081.6188 - val_loss: 1071.4607 - 74ms/epoch - 2ms/step\n",
            "Epoch 286/800\n",
            "40/40 - 0s - loss: 1094.2004 - val_loss: 1044.3159 - 69ms/epoch - 2ms/step\n",
            "Epoch 287/800\n",
            "40/40 - 0s - loss: 1081.4624 - val_loss: 1048.0868 - 72ms/epoch - 2ms/step\n",
            "Epoch 288/800\n",
            "40/40 - 0s - loss: 1067.8750 - val_loss: 1035.1696 - 80ms/epoch - 2ms/step\n",
            "Epoch 289/800\n",
            "40/40 - 0s - loss: 1073.3009 - val_loss: 1019.4218 - 72ms/epoch - 2ms/step\n",
            "Epoch 290/800\n",
            "40/40 - 0s - loss: 1084.0000 - val_loss: 1055.4335 - 78ms/epoch - 2ms/step\n",
            "Epoch 291/800\n",
            "40/40 - 0s - loss: 1078.9799 - val_loss: 1021.6719 - 75ms/epoch - 2ms/step\n",
            "Epoch 292/800\n",
            "40/40 - 0s - loss: 1064.1814 - val_loss: 1005.3021 - 71ms/epoch - 2ms/step\n",
            "Epoch 293/800\n",
            "40/40 - 0s - loss: 1048.6605 - val_loss: 994.9966 - 78ms/epoch - 2ms/step\n",
            "Epoch 294/800\n",
            "40/40 - 0s - loss: 1029.6998 - val_loss: 988.6863 - 68ms/epoch - 2ms/step\n",
            "Epoch 295/800\n",
            "40/40 - 0s - loss: 1032.0328 - val_loss: 983.5366 - 74ms/epoch - 2ms/step\n",
            "Epoch 296/800\n",
            "40/40 - 0s - loss: 1017.0898 - val_loss: 986.5267 - 71ms/epoch - 2ms/step\n",
            "Epoch 297/800\n",
            "40/40 - 0s - loss: 1016.9645 - val_loss: 988.9106 - 80ms/epoch - 2ms/step\n",
            "Epoch 298/800\n",
            "40/40 - 0s - loss: 1014.1767 - val_loss: 980.7377 - 72ms/epoch - 2ms/step\n",
            "Epoch 299/800\n",
            "40/40 - 0s - loss: 1017.1738 - val_loss: 988.9575 - 71ms/epoch - 2ms/step\n",
            "Epoch 300/800\n",
            "40/40 - 0s - loss: 1012.9722 - val_loss: 979.2573 - 78ms/epoch - 2ms/step\n",
            "Epoch 301/800\n",
            "40/40 - 0s - loss: 1013.2706 - val_loss: 989.3402 - 72ms/epoch - 2ms/step\n",
            "Epoch 302/800\n",
            "40/40 - 0s - loss: 1011.8992 - val_loss: 977.4897 - 70ms/epoch - 2ms/step\n",
            "Epoch 303/800\n",
            "40/40 - 0s - loss: 1004.4119 - val_loss: 972.6796 - 74ms/epoch - 2ms/step\n",
            "Epoch 304/800\n",
            "40/40 - 0s - loss: 1012.1602 - val_loss: 967.2772 - 69ms/epoch - 2ms/step\n",
            "Epoch 305/800\n",
            "40/40 - 0s - loss: 1025.0665 - val_loss: 997.8474 - 72ms/epoch - 2ms/step\n",
            "Epoch 306/800\n",
            "40/40 - 0s - loss: 1044.6075 - val_loss: 1024.8431 - 77ms/epoch - 2ms/step\n",
            "Epoch 307/800\n",
            "40/40 - 0s - loss: 1070.1528 - val_loss: 1028.8959 - 72ms/epoch - 2ms/step\n",
            "Epoch 308/800\n",
            "40/40 - 0s - loss: 1058.1146 - val_loss: 1024.0709 - 78ms/epoch - 2ms/step\n",
            "Epoch 309/800\n",
            "40/40 - 0s - loss: 1055.8248 - val_loss: 1032.8694 - 71ms/epoch - 2ms/step\n",
            "Epoch 310/800\n",
            "40/40 - 0s - loss: 1088.2250 - val_loss: 1157.4191 - 74ms/epoch - 2ms/step\n",
            "Epoch 311/800\n",
            "40/40 - 0s - loss: 1127.6704 - val_loss: 1048.7699 - 70ms/epoch - 2ms/step\n",
            "Epoch 312/800\n",
            "40/40 - 0s - loss: 1095.8838 - val_loss: 1019.1638 - 76ms/epoch - 2ms/step\n",
            "Epoch 313/800\n",
            "40/40 - 0s - loss: 1053.1779 - val_loss: 1002.6517 - 71ms/epoch - 2ms/step\n",
            "Epoch 314/800\n",
            "40/40 - 0s - loss: 1029.6982 - val_loss: 986.9754 - 70ms/epoch - 2ms/step\n",
            "Epoch 315/800\n",
            "40/40 - 0s - loss: 1028.6521 - val_loss: 1028.5295 - 74ms/epoch - 2ms/step\n",
            "Epoch 316/800\n",
            "40/40 - 0s - loss: 1034.4805 - val_loss: 999.5590 - 71ms/epoch - 2ms/step\n",
            "Epoch 317/800\n",
            "40/40 - 0s - loss: 1022.8575 - val_loss: 967.3820 - 117ms/epoch - 3ms/step\n",
            "Epoch 318/800\n",
            "40/40 - 0s - loss: 1004.9905 - val_loss: 972.0266 - 65ms/epoch - 2ms/step\n",
            "Epoch 319/800\n",
            "40/40 - 0s - loss: 993.3472 - val_loss: 961.4520 - 92ms/epoch - 2ms/step\n",
            "Epoch 320/800\n",
            "40/40 - 0s - loss: 998.1198 - val_loss: 965.3845 - 75ms/epoch - 2ms/step\n",
            "Epoch 321/800\n",
            "40/40 - 0s - loss: 1001.0712 - val_loss: 967.1547 - 70ms/epoch - 2ms/step\n",
            "Epoch 322/800\n",
            "40/40 - 0s - loss: 998.7294 - val_loss: 964.8781 - 72ms/epoch - 2ms/step\n",
            "Epoch 323/800\n",
            "40/40 - 0s - loss: 1002.0358 - val_loss: 960.2682 - 77ms/epoch - 2ms/step\n",
            "Epoch 324/800\n",
            "40/40 - 0s - loss: 993.1260 - val_loss: 958.2615 - 72ms/epoch - 2ms/step\n",
            "Epoch 325/800\n",
            "40/40 - 0s - loss: 1005.5569 - val_loss: 970.8626 - 80ms/epoch - 2ms/step\n",
            "Epoch 326/800\n",
            "40/40 - 0s - loss: 1013.2502 - val_loss: 980.7604 - 81ms/epoch - 2ms/step\n",
            "Epoch 327/800\n",
            "40/40 - 0s - loss: 1009.2678 - val_loss: 961.6553 - 75ms/epoch - 2ms/step\n",
            "Epoch 328/800\n",
            "40/40 - 0s - loss: 1018.1930 - val_loss: 974.3771 - 73ms/epoch - 2ms/step\n",
            "Epoch 329/800\n",
            "40/40 - 0s - loss: 1020.1536 - val_loss: 1006.2454 - 73ms/epoch - 2ms/step\n",
            "Epoch 330/800\n",
            "40/40 - 0s - loss: 1019.6556 - val_loss: 966.9264 - 73ms/epoch - 2ms/step\n",
            "Epoch 331/800\n",
            "40/40 - 0s - loss: 1014.4549 - val_loss: 973.1026 - 73ms/epoch - 2ms/step\n",
            "Epoch 332/800\n",
            "40/40 - 0s - loss: 1005.2983 - val_loss: 968.5001 - 77ms/epoch - 2ms/step\n",
            "Epoch 333/800\n",
            "40/40 - 0s - loss: 1008.2577 - val_loss: 982.3348 - 71ms/epoch - 2ms/step\n",
            "Epoch 334/800\n",
            "40/40 - 0s - loss: 1022.0302 - val_loss: 987.8359 - 70ms/epoch - 2ms/step\n",
            "Epoch 335/800\n",
            "40/40 - 0s - loss: 1013.7158 - val_loss: 965.4760 - 78ms/epoch - 2ms/step\n",
            "Epoch 336/800\n",
            "40/40 - 0s - loss: 1006.5182 - val_loss: 958.7017 - 69ms/epoch - 2ms/step\n",
            "Epoch 337/800\n",
            "40/40 - 0s - loss: 1002.0868 - val_loss: 978.4180 - 79ms/epoch - 2ms/step\n",
            "Epoch 338/800\n",
            "40/40 - 0s - loss: 998.9537 - val_loss: 960.6226 - 76ms/epoch - 2ms/step\n",
            "Epoch 339/800\n",
            "40/40 - 0s - loss: 991.0381 - val_loss: 967.8134 - 71ms/epoch - 2ms/step\n",
            "Epoch 340/800\n",
            "40/40 - 0s - loss: 997.3064 - val_loss: 958.6700 - 69ms/epoch - 2ms/step\n",
            "Epoch 341/800\n",
            "40/40 - 0s - loss: 995.7230 - val_loss: 961.4878 - 81ms/epoch - 2ms/step\n",
            "Epoch 342/800\n",
            "40/40 - 0s - loss: 1016.7603 - val_loss: 975.4694 - 74ms/epoch - 2ms/step\n",
            "Epoch 343/800\n",
            "40/40 - 0s - loss: 1013.9615 - val_loss: 986.0436 - 74ms/epoch - 2ms/step\n",
            "Epoch 344/800\n",
            "40/40 - 0s - loss: 1015.1340 - val_loss: 979.3803 - 78ms/epoch - 2ms/step\n",
            "Epoch 345/800\n",
            "40/40 - 0s - loss: 1023.5385 - val_loss: 1021.8391 - 73ms/epoch - 2ms/step\n",
            "Epoch 346/800\n",
            "40/40 - 0s - loss: 1081.8096 - val_loss: 1033.7383 - 81ms/epoch - 2ms/step\n",
            "Epoch 347/800\n",
            "40/40 - 0s - loss: 1057.5804 - val_loss: 1002.8126 - 83ms/epoch - 2ms/step\n",
            "Epoch 348/800\n",
            "40/40 - 0s - loss: 1015.6185 - val_loss: 959.8506 - 75ms/epoch - 2ms/step\n",
            "Epoch 349/800\n",
            "40/40 - 0s - loss: 1001.5410 - val_loss: 967.4528 - 81ms/epoch - 2ms/step\n",
            "Epoch 350/800\n",
            "40/40 - 0s - loss: 991.0229 - val_loss: 937.3903 - 71ms/epoch - 2ms/step\n",
            "Epoch 351/800\n",
            "40/40 - 0s - loss: 983.1015 - val_loss: 948.9575 - 70ms/epoch - 2ms/step\n",
            "Epoch 352/800\n",
            "40/40 - 0s - loss: 988.8895 - val_loss: 952.7054 - 79ms/epoch - 2ms/step\n",
            "Epoch 353/800\n",
            "40/40 - 0s - loss: 984.5280 - val_loss: 942.8016 - 74ms/epoch - 2ms/step\n",
            "Epoch 354/800\n",
            "40/40 - 0s - loss: 973.6641 - val_loss: 944.0928 - 68ms/epoch - 2ms/step\n",
            "Epoch 355/800\n",
            "40/40 - 0s - loss: 976.1773 - val_loss: 933.3458 - 72ms/epoch - 2ms/step\n",
            "Epoch 356/800\n",
            "40/40 - 0s - loss: 975.0609 - val_loss: 936.6189 - 74ms/epoch - 2ms/step\n",
            "Epoch 357/800\n",
            "40/40 - 0s - loss: 969.3966 - val_loss: 950.0377 - 73ms/epoch - 2ms/step\n",
            "Epoch 358/800\n",
            "40/40 - 0s - loss: 978.5757 - val_loss: 960.9946 - 81ms/epoch - 2ms/step\n",
            "Epoch 359/800\n",
            "40/40 - 0s - loss: 991.8702 - val_loss: 973.3681 - 73ms/epoch - 2ms/step\n",
            "Epoch 360/800\n",
            "40/40 - 0s - loss: 1013.3587 - val_loss: 967.1176 - 79ms/epoch - 2ms/step\n",
            "Epoch 361/800\n",
            "40/40 - 0s - loss: 1001.2542 - val_loss: 955.5707 - 70ms/epoch - 2ms/step\n",
            "Epoch 362/800\n",
            "40/40 - 0s - loss: 991.2951 - val_loss: 953.3278 - 74ms/epoch - 2ms/step\n",
            "Epoch 363/800\n",
            "40/40 - 0s - loss: 987.7646 - val_loss: 947.1962 - 75ms/epoch - 2ms/step\n",
            "Epoch 364/800\n",
            "40/40 - 0s - loss: 990.4792 - val_loss: 975.7449 - 74ms/epoch - 2ms/step\n",
            "Epoch 365/800\n",
            "40/40 - 0s - loss: 1006.9830 - val_loss: 970.6363 - 72ms/epoch - 2ms/step\n",
            "Epoch 366/800\n",
            "40/40 - 0s - loss: 996.4047 - val_loss: 950.4122 - 82ms/epoch - 2ms/step\n",
            "Epoch 367/800\n",
            "40/40 - 0s - loss: 991.3843 - val_loss: 955.9754 - 76ms/epoch - 2ms/step\n",
            "Epoch 368/800\n",
            "40/40 - 0s - loss: 1011.0563 - val_loss: 1025.3926 - 74ms/epoch - 2ms/step\n",
            "Epoch 369/800\n",
            "40/40 - 0s - loss: 1041.0023 - val_loss: 998.3439 - 73ms/epoch - 2ms/step\n",
            "Epoch 370/800\n",
            "40/40 - 0s - loss: 1027.4299 - val_loss: 966.2648 - 70ms/epoch - 2ms/step\n",
            "Epoch 371/800\n",
            "40/40 - 0s - loss: 1012.9855 - val_loss: 996.3913 - 75ms/epoch - 2ms/step\n",
            "Epoch 372/800\n",
            "40/40 - 0s - loss: 1007.9366 - val_loss: 972.4720 - 68ms/epoch - 2ms/step\n",
            "Epoch 373/800\n",
            "40/40 - 0s - loss: 1001.0272 - val_loss: 955.8751 - 74ms/epoch - 2ms/step\n",
            "Epoch 374/800\n",
            "40/40 - 0s - loss: 995.0372 - val_loss: 970.2466 - 81ms/epoch - 2ms/step\n",
            "Epoch 375/800\n",
            "40/40 - 0s - loss: 984.4811 - val_loss: 936.1135 - 71ms/epoch - 2ms/step\n",
            "Epoch 376/800\n",
            "40/40 - 0s - loss: 975.9213 - val_loss: 937.6637 - 75ms/epoch - 2ms/step\n",
            "Epoch 377/800\n",
            "40/40 - 0s - loss: 972.4780 - val_loss: 927.9194 - 71ms/epoch - 2ms/step\n",
            "Epoch 378/800\n",
            "40/40 - 0s - loss: 965.4026 - val_loss: 931.3580 - 77ms/epoch - 2ms/step\n",
            "Epoch 379/800\n",
            "40/40 - 0s - loss: 962.3371 - val_loss: 921.6350 - 67ms/epoch - 2ms/step\n",
            "Epoch 380/800\n",
            "40/40 - 0s - loss: 964.5364 - val_loss: 922.2393 - 78ms/epoch - 2ms/step\n",
            "Epoch 381/800\n",
            "40/40 - 0s - loss: 974.7461 - val_loss: 944.2454 - 72ms/epoch - 2ms/step\n",
            "Epoch 382/800\n",
            "40/40 - 0s - loss: 975.6600 - val_loss: 938.4965 - 74ms/epoch - 2ms/step\n",
            "Epoch 383/800\n",
            "40/40 - 0s - loss: 980.7801 - val_loss: 938.9557 - 74ms/epoch - 2ms/step\n",
            "Epoch 384/800\n",
            "40/40 - 0s - loss: 973.1843 - val_loss: 930.6793 - 72ms/epoch - 2ms/step\n",
            "Epoch 385/800\n",
            "40/40 - 0s - loss: 965.8053 - val_loss: 938.5370 - 71ms/epoch - 2ms/step\n",
            "Epoch 386/800\n",
            "40/40 - 0s - loss: 958.4581 - val_loss: 935.5725 - 77ms/epoch - 2ms/step\n",
            "Epoch 387/800\n",
            "40/40 - 0s - loss: 974.4172 - val_loss: 929.9698 - 82ms/epoch - 2ms/step\n",
            "Epoch 388/800\n",
            "40/40 - 0s - loss: 969.2736 - val_loss: 946.2391 - 76ms/epoch - 2ms/step\n",
            "Epoch 389/800\n",
            "40/40 - 0s - loss: 971.1604 - val_loss: 949.0294 - 78ms/epoch - 2ms/step\n",
            "Epoch 390/800\n",
            "40/40 - 0s - loss: 988.5767 - val_loss: 953.1182 - 74ms/epoch - 2ms/step\n",
            "Epoch 391/800\n",
            "40/40 - 0s - loss: 988.9016 - val_loss: 948.7738 - 69ms/epoch - 2ms/step\n",
            "Epoch 392/800\n",
            "40/40 - 0s - loss: 975.9779 - val_loss: 939.2276 - 81ms/epoch - 2ms/step\n",
            "Epoch 393/800\n",
            "40/40 - 0s - loss: 980.8808 - val_loss: 929.1970 - 74ms/epoch - 2ms/step\n",
            "Epoch 394/800\n",
            "40/40 - 0s - loss: 973.6564 - val_loss: 943.8038 - 76ms/epoch - 2ms/step\n",
            "Epoch 395/800\n",
            "40/40 - 0s - loss: 972.2959 - val_loss: 929.7363 - 75ms/epoch - 2ms/step\n",
            "Epoch 396/800\n",
            "40/40 - 0s - loss: 965.4291 - val_loss: 927.0385 - 69ms/epoch - 2ms/step\n",
            "Epoch 397/800\n",
            "40/40 - 0s - loss: 963.4081 - val_loss: 929.3732 - 70ms/epoch - 2ms/step\n",
            "Epoch 398/800\n",
            "40/40 - 0s - loss: 956.1309 - val_loss: 925.1656 - 72ms/epoch - 2ms/step\n",
            "Epoch 399/800\n",
            "40/40 - 0s - loss: 956.9830 - val_loss: 925.1467 - 74ms/epoch - 2ms/step\n",
            "Epoch 400/800\n",
            "40/40 - 0s - loss: 953.7052 - val_loss: 916.7723 - 70ms/epoch - 2ms/step\n",
            "Epoch 401/800\n",
            "40/40 - 0s - loss: 968.3721 - val_loss: 937.6886 - 78ms/epoch - 2ms/step\n",
            "Epoch 402/800\n",
            "40/40 - 0s - loss: 962.2267 - val_loss: 922.1313 - 74ms/epoch - 2ms/step\n",
            "Epoch 403/800\n",
            "40/40 - 0s - loss: 957.9222 - val_loss: 933.0364 - 70ms/epoch - 2ms/step\n",
            "Epoch 404/800\n",
            "40/40 - 0s - loss: 962.8514 - val_loss: 929.8401 - 75ms/epoch - 2ms/step\n",
            "Epoch 405/800\n",
            "40/40 - 0s - loss: 961.8935 - val_loss: 936.3456 - 79ms/epoch - 2ms/step\n",
            "Epoch 406/800\n",
            "40/40 - 0s - loss: 966.3842 - val_loss: 933.6863 - 83ms/epoch - 2ms/step\n",
            "Epoch 407/800\n",
            "40/40 - 0s - loss: 957.3439 - val_loss: 912.2761 - 78ms/epoch - 2ms/step\n",
            "Epoch 408/800\n",
            "40/40 - 0s - loss: 946.1312 - val_loss: 920.8512 - 68ms/epoch - 2ms/step\n",
            "Epoch 409/800\n",
            "40/40 - 0s - loss: 960.6605 - val_loss: 928.0297 - 71ms/epoch - 2ms/step\n",
            "Epoch 410/800\n",
            "40/40 - 0s - loss: 961.0704 - val_loss: 931.3646 - 71ms/epoch - 2ms/step\n",
            "Epoch 411/800\n",
            "40/40 - 0s - loss: 961.6562 - val_loss: 927.6354 - 78ms/epoch - 2ms/step\n",
            "Epoch 412/800\n",
            "40/40 - 0s - loss: 967.5195 - val_loss: 925.5219 - 68ms/epoch - 2ms/step\n",
            "Epoch 413/800\n",
            "40/40 - 0s - loss: 967.9280 - val_loss: 937.4318 - 76ms/epoch - 2ms/step\n",
            "Epoch 414/800\n",
            "40/40 - 0s - loss: 959.4318 - val_loss: 935.1685 - 72ms/epoch - 2ms/step\n",
            "Epoch 415/800\n",
            "40/40 - 0s - loss: 957.9995 - val_loss: 922.6306 - 75ms/epoch - 2ms/step\n",
            "Epoch 416/800\n",
            "40/40 - 0s - loss: 969.1395 - val_loss: 931.1520 - 68ms/epoch - 2ms/step\n",
            "Epoch 417/800\n",
            "40/40 - 0s - loss: 983.8235 - val_loss: 956.9504 - 74ms/epoch - 2ms/step\n",
            "Epoch 418/800\n",
            "40/40 - 0s - loss: 985.9048 - val_loss: 929.6808 - 75ms/epoch - 2ms/step\n",
            "Epoch 419/800\n",
            "40/40 - 0s - loss: 961.8876 - val_loss: 922.7354 - 70ms/epoch - 2ms/step\n",
            "Epoch 420/800\n",
            "40/40 - 0s - loss: 960.1006 - val_loss: 932.3336 - 78ms/epoch - 2ms/step\n",
            "Epoch 421/800\n",
            "40/40 - 0s - loss: 973.5419 - val_loss: 953.7930 - 69ms/epoch - 2ms/step\n",
            "Epoch 422/800\n",
            "40/40 - 0s - loss: 1003.1274 - val_loss: 966.1211 - 80ms/epoch - 2ms/step\n",
            "Epoch 423/800\n",
            "40/40 - 0s - loss: 1017.9586 - val_loss: 963.5574 - 75ms/epoch - 2ms/step\n",
            "Epoch 424/800\n",
            "40/40 - 0s - loss: 1006.8411 - val_loss: 970.1944 - 76ms/epoch - 2ms/step\n",
            "Epoch 425/800\n",
            "40/40 - 0s - loss: 1000.2742 - val_loss: 954.9074 - 82ms/epoch - 2ms/step\n",
            "Epoch 426/800\n",
            "40/40 - 0s - loss: 982.0314 - val_loss: 937.2545 - 76ms/epoch - 2ms/step\n",
            "Epoch 427/800\n",
            "40/40 - 0s - loss: 981.6537 - val_loss: 929.8607 - 75ms/epoch - 2ms/step\n",
            "Epoch 428/800\n",
            "40/40 - 0s - loss: 969.2415 - val_loss: 924.7816 - 78ms/epoch - 2ms/step\n",
            "Epoch 429/800\n",
            "40/40 - 0s - loss: 960.1224 - val_loss: 906.7369 - 71ms/epoch - 2ms/step\n",
            "Epoch 430/800\n",
            "40/40 - 0s - loss: 951.5390 - val_loss: 913.5823 - 70ms/epoch - 2ms/step\n",
            "Epoch 431/800\n",
            "40/40 - 0s - loss: 958.4028 - val_loss: 940.7220 - 77ms/epoch - 2ms/step\n",
            "Epoch 432/800\n",
            "40/40 - 0s - loss: 981.1213 - val_loss: 920.8341 - 73ms/epoch - 2ms/step\n",
            "Epoch 433/800\n",
            "40/40 - 0s - loss: 959.1959 - val_loss: 919.7817 - 70ms/epoch - 2ms/step\n",
            "Epoch 434/800\n",
            "40/40 - 0s - loss: 956.2234 - val_loss: 902.2774 - 74ms/epoch - 2ms/step\n",
            "Epoch 435/800\n",
            "40/40 - 0s - loss: 945.9892 - val_loss: 912.2851 - 70ms/epoch - 2ms/step\n",
            "Epoch 436/800\n",
            "40/40 - 0s - loss: 935.0383 - val_loss: 887.9424 - 76ms/epoch - 2ms/step\n",
            "Epoch 437/800\n",
            "40/40 - 0s - loss: 936.7488 - val_loss: 910.0970 - 71ms/epoch - 2ms/step\n",
            "Epoch 438/800\n",
            "40/40 - 0s - loss: 941.0062 - val_loss: 926.6485 - 77ms/epoch - 2ms/step\n",
            "Epoch 439/800\n",
            "40/40 - 0s - loss: 950.5596 - val_loss: 910.3992 - 74ms/epoch - 2ms/step\n",
            "Epoch 440/800\n",
            "40/40 - 0s - loss: 955.4122 - val_loss: 930.3093 - 70ms/epoch - 2ms/step\n",
            "Epoch 441/800\n",
            "40/40 - 0s - loss: 965.2914 - val_loss: 917.6835 - 69ms/epoch - 2ms/step\n",
            "Epoch 442/800\n",
            "40/40 - 0s - loss: 948.9684 - val_loss: 911.8992 - 73ms/epoch - 2ms/step\n",
            "Epoch 443/800\n",
            "40/40 - 0s - loss: 961.3822 - val_loss: 929.5444 - 73ms/epoch - 2ms/step\n",
            "Epoch 444/800\n",
            "40/40 - 0s - loss: 959.1126 - val_loss: 918.4306 - 74ms/epoch - 2ms/step\n",
            "Epoch 445/800\n",
            "40/40 - 0s - loss: 950.3852 - val_loss: 922.9572 - 85ms/epoch - 2ms/step\n",
            "Epoch 446/800\n",
            "40/40 - 0s - loss: 952.7441 - val_loss: 912.1830 - 77ms/epoch - 2ms/step\n",
            "Epoch 447/800\n",
            "40/40 - 0s - loss: 945.6675 - val_loss: 924.9313 - 75ms/epoch - 2ms/step\n",
            "Epoch 448/800\n",
            "40/40 - 0s - loss: 951.5401 - val_loss: 910.3619 - 73ms/epoch - 2ms/step\n",
            "Epoch 449/800\n",
            "40/40 - 0s - loss: 951.0216 - val_loss: 911.3950 - 83ms/epoch - 2ms/step\n",
            "Epoch 450/800\n",
            "40/40 - 0s - loss: 946.7958 - val_loss: 920.9615 - 75ms/epoch - 2ms/step\n",
            "Epoch 451/800\n",
            "40/40 - 0s - loss: 942.6471 - val_loss: 900.0381 - 71ms/epoch - 2ms/step\n",
            "Epoch 452/800\n",
            "40/40 - 0s - loss: 937.6374 - val_loss: 912.3337 - 77ms/epoch - 2ms/step\n",
            "Epoch 453/800\n",
            "40/40 - 0s - loss: 950.6895 - val_loss: 933.2408 - 72ms/epoch - 2ms/step\n",
            "Epoch 454/800\n",
            "40/40 - 0s - loss: 960.9106 - val_loss: 925.6063 - 71ms/epoch - 2ms/step\n",
            "Epoch 455/800\n",
            "40/40 - 0s - loss: 954.5860 - val_loss: 900.8615 - 78ms/epoch - 2ms/step\n",
            "Epoch 456/800\n",
            "40/40 - 0s - loss: 938.4222 - val_loss: 896.9622 - 85ms/epoch - 2ms/step\n",
            "Epoch 457/800\n",
            "40/40 - 0s - loss: 934.8851 - val_loss: 894.1105 - 76ms/epoch - 2ms/step\n",
            "Epoch 458/800\n",
            "40/40 - 0s - loss: 930.8186 - val_loss: 890.0955 - 70ms/epoch - 2ms/step\n",
            "Epoch 459/800\n",
            "40/40 - 0s - loss: 928.1483 - val_loss: 892.6276 - 72ms/epoch - 2ms/step\n",
            "Epoch 460/800\n",
            "40/40 - 0s - loss: 932.7932 - val_loss: 896.4954 - 69ms/epoch - 2ms/step\n",
            "Epoch 461/800\n",
            "40/40 - 0s - loss: 946.0688 - val_loss: 905.1993 - 72ms/epoch - 2ms/step\n",
            "Epoch 462/800\n",
            "40/40 - 0s - loss: 952.8671 - val_loss: 925.1118 - 75ms/epoch - 2ms/step\n",
            "Epoch 463/800\n",
            "40/40 - 0s - loss: 948.6243 - val_loss: 917.6192 - 71ms/epoch - 2ms/step\n",
            "Epoch 464/800\n",
            "40/40 - 0s - loss: 949.9667 - val_loss: 900.5503 - 69ms/epoch - 2ms/step\n",
            "Epoch 465/800\n",
            "40/40 - 0s - loss: 957.6334 - val_loss: 914.2231 - 77ms/epoch - 2ms/step\n",
            "Epoch 466/800\n",
            "40/40 - 0s - loss: 957.6008 - val_loss: 920.7663 - 84ms/epoch - 2ms/step\n",
            "Epoch 467/800\n",
            "40/40 - 0s - loss: 944.1548 - val_loss: 908.4227 - 71ms/epoch - 2ms/step\n",
            "Epoch 468/800\n",
            "40/40 - 0s - loss: 940.5236 - val_loss: 910.6063 - 79ms/epoch - 2ms/step\n",
            "Epoch 469/800\n",
            "40/40 - 0s - loss: 956.6896 - val_loss: 917.0328 - 72ms/epoch - 2ms/step\n",
            "Epoch 470/800\n",
            "40/40 - 0s - loss: 957.8823 - val_loss: 929.5709 - 74ms/epoch - 2ms/step\n",
            "Epoch 471/800\n",
            "40/40 - 0s - loss: 944.0346 - val_loss: 892.6415 - 71ms/epoch - 2ms/step\n",
            "Epoch 472/800\n",
            "40/40 - 0s - loss: 952.8568 - val_loss: 925.9761 - 74ms/epoch - 2ms/step\n",
            "Epoch 473/800\n",
            "40/40 - 0s - loss: 958.7829 - val_loss: 909.3996 - 67ms/epoch - 2ms/step\n",
            "Epoch 474/800\n",
            "40/40 - 0s - loss: 946.9356 - val_loss: 915.3233 - 78ms/epoch - 2ms/step\n",
            "Epoch 475/800\n",
            "40/40 - 0s - loss: 961.8466 - val_loss: 916.0336 - 72ms/epoch - 2ms/step\n",
            "Epoch 476/800\n",
            "40/40 - 0s - loss: 952.3671 - val_loss: 928.2885 - 73ms/epoch - 2ms/step\n",
            "Epoch 477/800\n",
            "40/40 - 0s - loss: 946.9704 - val_loss: 904.4323 - 76ms/epoch - 2ms/step\n",
            "Epoch 478/800\n",
            "40/40 - 0s - loss: 941.6116 - val_loss: 893.2020 - 72ms/epoch - 2ms/step\n",
            "Epoch 479/800\n",
            "40/40 - 0s - loss: 946.6730 - val_loss: 914.1463 - 70ms/epoch - 2ms/step\n",
            "Epoch 480/800\n",
            "40/40 - 0s - loss: 983.9437 - val_loss: 962.8428 - 74ms/epoch - 2ms/step\n",
            "Epoch 481/800\n",
            "40/40 - 0s - loss: 981.2200 - val_loss: 946.0810 - 71ms/epoch - 2ms/step\n",
            "Epoch 482/800\n",
            "40/40 - 0s - loss: 971.5200 - val_loss: 917.8453 - 78ms/epoch - 2ms/step\n",
            "Epoch 483/800\n",
            "40/40 - 0s - loss: 950.9946 - val_loss: 904.4512 - 74ms/epoch - 2ms/step\n",
            "Epoch 484/800\n",
            "40/40 - 0s - loss: 956.8566 - val_loss: 908.4330 - 71ms/epoch - 2ms/step\n",
            "Epoch 485/800\n",
            "40/40 - 0s - loss: 945.4059 - val_loss: 918.7466 - 76ms/epoch - 2ms/step\n",
            "Epoch 486/800\n",
            "40/40 - 0s - loss: 941.8503 - val_loss: 899.9491 - 82ms/epoch - 2ms/step\n",
            "Epoch 487/800\n",
            "40/40 - 0s - loss: 934.9222 - val_loss: 910.6284 - 77ms/epoch - 2ms/step\n",
            "Epoch 488/800\n",
            "40/40 - 0s - loss: 940.8003 - val_loss: 892.9824 - 75ms/epoch - 2ms/step\n",
            "Epoch 489/800\n",
            "40/40 - 0s - loss: 928.4515 - val_loss: 893.5676 - 69ms/epoch - 2ms/step\n",
            "Epoch 490/800\n",
            "40/40 - 0s - loss: 921.3448 - val_loss: 877.7521 - 78ms/epoch - 2ms/step\n",
            "Epoch 491/800\n",
            "40/40 - 0s - loss: 912.7957 - val_loss: 885.3376 - 72ms/epoch - 2ms/step\n",
            "Epoch 492/800\n",
            "40/40 - 0s - loss: 915.6168 - val_loss: 881.6629 - 73ms/epoch - 2ms/step\n",
            "Epoch 493/800\n",
            "40/40 - 0s - loss: 916.2146 - val_loss: 887.1031 - 73ms/epoch - 2ms/step\n",
            "Epoch 494/800\n",
            "40/40 - 0s - loss: 915.3203 - val_loss: 884.9477 - 82ms/epoch - 2ms/step\n",
            "Epoch 495/800\n",
            "40/40 - 0s - loss: 923.8535 - val_loss: 913.0709 - 72ms/epoch - 2ms/step\n",
            "Epoch 496/800\n",
            "40/40 - 0s - loss: 938.2047 - val_loss: 900.8278 - 72ms/epoch - 2ms/step\n",
            "Epoch 497/800\n",
            "40/40 - 0s - loss: 937.9210 - val_loss: 909.3093 - 89ms/epoch - 2ms/step\n",
            "Epoch 498/800\n",
            "40/40 - 0s - loss: 929.8452 - val_loss: 898.8918 - 69ms/epoch - 2ms/step\n",
            "Epoch 499/800\n",
            "40/40 - 0s - loss: 927.3199 - val_loss: 876.8729 - 73ms/epoch - 2ms/step\n",
            "Epoch 500/800\n",
            "40/40 - 0s - loss: 913.6042 - val_loss: 877.2642 - 81ms/epoch - 2ms/step\n",
            "Epoch 501/800\n",
            "40/40 - 0s - loss: 917.4818 - val_loss: 894.0657 - 76ms/epoch - 2ms/step\n",
            "Epoch 502/800\n",
            "40/40 - 0s - loss: 923.0508 - val_loss: 903.8310 - 75ms/epoch - 2ms/step\n",
            "Epoch 503/800\n",
            "40/40 - 0s - loss: 929.9303 - val_loss: 884.3371 - 78ms/epoch - 2ms/step\n",
            "Epoch 504/800\n",
            "40/40 - 0s - loss: 928.2034 - val_loss: 886.3428 - 74ms/epoch - 2ms/step\n",
            "Epoch 505/800\n",
            "40/40 - 0s - loss: 948.9337 - val_loss: 907.9761 - 71ms/epoch - 2ms/step\n",
            "Epoch 506/800\n",
            "40/40 - 0s - loss: 942.7803 - val_loss: 897.0997 - 74ms/epoch - 2ms/step\n",
            "Epoch 507/800\n",
            "40/40 - 0s - loss: 945.1169 - val_loss: 911.0323 - 78ms/epoch - 2ms/step\n",
            "Epoch 508/800\n",
            "40/40 - 0s - loss: 936.6578 - val_loss: 884.9575 - 76ms/epoch - 2ms/step\n",
            "Epoch 509/800\n",
            "40/40 - 0s - loss: 919.4618 - val_loss: 890.2097 - 71ms/epoch - 2ms/step\n",
            "Epoch 510/800\n",
            "40/40 - 0s - loss: 937.4578 - val_loss: 901.8524 - 78ms/epoch - 2ms/step\n",
            "Epoch 511/800\n",
            "40/40 - 0s - loss: 957.3137 - val_loss: 910.6473 - 76ms/epoch - 2ms/step\n",
            "Epoch 512/800\n",
            "40/40 - 0s - loss: 957.0002 - val_loss: 907.9764 - 72ms/epoch - 2ms/step\n",
            "Epoch 513/800\n",
            "40/40 - 0s - loss: 948.3748 - val_loss: 944.0556 - 75ms/epoch - 2ms/step\n",
            "Epoch 514/800\n",
            "40/40 - 0s - loss: 959.9454 - val_loss: 899.1891 - 73ms/epoch - 2ms/step\n",
            "Epoch 515/800\n",
            "40/40 - 0s - loss: 934.1934 - val_loss: 886.1489 - 74ms/epoch - 2ms/step\n",
            "Epoch 516/800\n",
            "40/40 - 0s - loss: 924.1767 - val_loss: 904.1962 - 72ms/epoch - 2ms/step\n",
            "Epoch 517/800\n",
            "40/40 - 0s - loss: 922.7782 - val_loss: 872.1697 - 72ms/epoch - 2ms/step\n",
            "Epoch 518/800\n",
            "40/40 - 0s - loss: 920.3353 - val_loss: 885.5084 - 74ms/epoch - 2ms/step\n",
            "Epoch 519/800\n",
            "40/40 - 0s - loss: 919.6663 - val_loss: 882.0351 - 75ms/epoch - 2ms/step\n",
            "Epoch 520/800\n",
            "40/40 - 0s - loss: 926.5961 - val_loss: 896.4510 - 76ms/epoch - 2ms/step\n",
            "Epoch 521/800\n",
            "40/40 - 0s - loss: 933.9889 - val_loss: 949.3887 - 75ms/epoch - 2ms/step\n",
            "Epoch 522/800\n",
            "40/40 - 0s - loss: 1007.1572 - val_loss: 972.8059 - 80ms/epoch - 2ms/step\n",
            "Epoch 523/800\n",
            "40/40 - 0s - loss: 1008.1838 - val_loss: 937.5397 - 73ms/epoch - 2ms/step\n",
            "Epoch 524/800\n",
            "40/40 - 0s - loss: 974.0322 - val_loss: 925.7759 - 78ms/epoch - 2ms/step\n",
            "Epoch 525/800\n",
            "40/40 - 0s - loss: 955.3691 - val_loss: 935.4554 - 71ms/epoch - 2ms/step\n",
            "Epoch 526/800\n",
            "40/40 - 0s - loss: 957.8091 - val_loss: 898.4215 - 76ms/epoch - 2ms/step\n",
            "Epoch 527/800\n",
            "40/40 - 0s - loss: 920.8492 - val_loss: 884.0206 - 87ms/epoch - 2ms/step\n",
            "Epoch 528/800\n",
            "40/40 - 0s - loss: 917.2814 - val_loss: 883.5789 - 72ms/epoch - 2ms/step\n",
            "Epoch 529/800\n",
            "40/40 - 0s - loss: 913.0042 - val_loss: 871.9470 - 77ms/epoch - 2ms/step\n",
            "Epoch 530/800\n",
            "40/40 - 0s - loss: 912.3137 - val_loss: 869.7099 - 70ms/epoch - 2ms/step\n",
            "Epoch 531/800\n",
            "40/40 - 0s - loss: 911.6090 - val_loss: 879.7659 - 74ms/epoch - 2ms/step\n",
            "Epoch 532/800\n",
            "40/40 - 0s - loss: 903.3452 - val_loss: 869.5406 - 74ms/epoch - 2ms/step\n",
            "Epoch 533/800\n",
            "40/40 - 0s - loss: 911.1520 - val_loss: 878.2033 - 77ms/epoch - 2ms/step\n",
            "Epoch 534/800\n",
            "40/40 - 0s - loss: 904.0811 - val_loss: 873.2557 - 90ms/epoch - 2ms/step\n",
            "Epoch 535/800\n",
            "40/40 - 0s - loss: 908.9636 - val_loss: 871.4283 - 74ms/epoch - 2ms/step\n",
            "Epoch 536/800\n",
            "40/40 - 0s - loss: 894.9282 - val_loss: 853.1793 - 75ms/epoch - 2ms/step\n",
            "Epoch 537/800\n",
            "40/40 - 0s - loss: 891.9825 - val_loss: 853.5662 - 80ms/epoch - 2ms/step\n",
            "Epoch 538/800\n",
            "40/40 - 0s - loss: 887.1483 - val_loss: 863.2555 - 72ms/epoch - 2ms/step\n",
            "Epoch 539/800\n",
            "40/40 - 0s - loss: 898.1160 - val_loss: 863.2265 - 76ms/epoch - 2ms/step\n",
            "Epoch 540/800\n",
            "40/40 - 0s - loss: 905.0024 - val_loss: 868.7460 - 102ms/epoch - 3ms/step\n",
            "Epoch 541/800\n",
            "40/40 - 0s - loss: 909.9668 - val_loss: 880.7744 - 90ms/epoch - 2ms/step\n",
            "Epoch 542/800\n",
            "40/40 - 0s - loss: 904.7579 - val_loss: 864.3702 - 82ms/epoch - 2ms/step\n",
            "Epoch 543/800\n",
            "40/40 - 0s - loss: 903.2234 - val_loss: 877.6024 - 74ms/epoch - 2ms/step\n",
            "Epoch 544/800\n",
            "40/40 - 0s - loss: 923.0063 - val_loss: 896.7375 - 77ms/epoch - 2ms/step\n",
            "Epoch 545/800\n",
            "40/40 - 0s - loss: 926.3643 - val_loss: 881.0261 - 76ms/epoch - 2ms/step\n",
            "Epoch 546/800\n",
            "40/40 - 0s - loss: 932.2703 - val_loss: 896.3369 - 74ms/epoch - 2ms/step\n",
            "Epoch 547/800\n",
            "40/40 - 0s - loss: 935.9525 - val_loss: 917.6702 - 75ms/epoch - 2ms/step\n",
            "Epoch 548/800\n",
            "40/40 - 0s - loss: 977.2535 - val_loss: 947.2524 - 70ms/epoch - 2ms/step\n",
            "Epoch 549/800\n",
            "40/40 - 0s - loss: 1005.9996 - val_loss: 990.0456 - 80ms/epoch - 2ms/step\n",
            "Epoch 550/800\n",
            "40/40 - 0s - loss: 977.6753 - val_loss: 924.6437 - 70ms/epoch - 2ms/step\n",
            "Epoch 551/800\n",
            "40/40 - 0s - loss: 941.0562 - val_loss: 906.0599 - 72ms/epoch - 2ms/step\n",
            "Epoch 552/800\n",
            "40/40 - 0s - loss: 942.4215 - val_loss: 905.0981 - 71ms/epoch - 2ms/step\n",
            "Epoch 553/800\n",
            "40/40 - 0s - loss: 925.6249 - val_loss: 883.5409 - 74ms/epoch - 2ms/step\n",
            "Epoch 554/800\n",
            "40/40 - 0s - loss: 918.9155 - val_loss: 891.4517 - 71ms/epoch - 2ms/step\n",
            "Epoch 555/800\n",
            "40/40 - 0s - loss: 926.3834 - val_loss: 884.6049 - 77ms/epoch - 2ms/step\n",
            "Epoch 556/800\n",
            "40/40 - 0s - loss: 923.4023 - val_loss: 887.1672 - 68ms/epoch - 2ms/step\n",
            "Epoch 557/800\n",
            "40/40 - 0s - loss: 905.3300 - val_loss: 868.0206 - 74ms/epoch - 2ms/step\n",
            "Epoch 558/800\n",
            "40/40 - 0s - loss: 907.9059 - val_loss: 876.4409 - 78ms/epoch - 2ms/step\n",
            "Epoch 559/800\n",
            "40/40 - 0s - loss: 901.1896 - val_loss: 860.1639 - 70ms/epoch - 2ms/step\n",
            "Epoch 560/800\n",
            "40/40 - 0s - loss: 906.7499 - val_loss: 870.5590 - 74ms/epoch - 2ms/step\n",
            "Epoch 561/800\n",
            "40/40 - 0s - loss: 907.2895 - val_loss: 878.9559 - 81ms/epoch - 2ms/step\n",
            "Epoch 562/800\n",
            "40/40 - 0s - loss: 913.3729 - val_loss: 873.4963 - 80ms/epoch - 2ms/step\n",
            "Epoch 563/800\n",
            "40/40 - 0s - loss: 897.9449 - val_loss: 871.7590 - 79ms/epoch - 2ms/step\n",
            "Epoch 564/800\n",
            "40/40 - 0s - loss: 883.6401 - val_loss: 843.6776 - 72ms/epoch - 2ms/step\n",
            "Epoch 565/800\n",
            "40/40 - 0s - loss: 891.1070 - val_loss: 865.7685 - 82ms/epoch - 2ms/step\n",
            "Epoch 566/800\n",
            "40/40 - 0s - loss: 890.8267 - val_loss: 854.5251 - 72ms/epoch - 2ms/step\n",
            "Epoch 567/800\n",
            "40/40 - 0s - loss: 900.3641 - val_loss: 875.3051 - 69ms/epoch - 2ms/step\n",
            "Epoch 568/800\n",
            "40/40 - 0s - loss: 917.8128 - val_loss: 908.9140 - 73ms/epoch - 2ms/step\n",
            "Epoch 569/800\n",
            "40/40 - 0s - loss: 949.7797 - val_loss: 924.8934 - 79ms/epoch - 2ms/step\n",
            "Epoch 570/800\n",
            "40/40 - 0s - loss: 956.3519 - val_loss: 924.5333 - 77ms/epoch - 2ms/step\n",
            "Epoch 571/800\n",
            "40/40 - 0s - loss: 942.7141 - val_loss: 888.4818 - 73ms/epoch - 2ms/step\n",
            "Epoch 572/800\n",
            "40/40 - 0s - loss: 924.2453 - val_loss: 884.3188 - 86ms/epoch - 2ms/step\n",
            "Epoch 573/800\n",
            "40/40 - 0s - loss: 912.8446 - val_loss: 878.3953 - 72ms/epoch - 2ms/step\n",
            "Epoch 574/800\n",
            "40/40 - 0s - loss: 912.7126 - val_loss: 891.6998 - 74ms/epoch - 2ms/step\n",
            "Epoch 575/800\n",
            "40/40 - 0s - loss: 912.1130 - val_loss: 872.1037 - 79ms/epoch - 2ms/step\n",
            "Epoch 576/800\n",
            "40/40 - 0s - loss: 900.3247 - val_loss: 863.4401 - 80ms/epoch - 2ms/step\n",
            "Epoch 577/800\n",
            "40/40 - 0s - loss: 907.7450 - val_loss: 865.2551 - 72ms/epoch - 2ms/step\n",
            "Epoch 578/800\n",
            "40/40 - 0s - loss: 899.6775 - val_loss: 873.1755 - 78ms/epoch - 2ms/step\n",
            "Epoch 579/800\n",
            "40/40 - 0s - loss: 895.8743 - val_loss: 861.9380 - 70ms/epoch - 2ms/step\n",
            "Epoch 580/800\n",
            "40/40 - 0s - loss: 898.8210 - val_loss: 859.3651 - 80ms/epoch - 2ms/step\n",
            "Epoch 581/800\n",
            "40/40 - 0s - loss: 897.3642 - val_loss: 864.6490 - 74ms/epoch - 2ms/step\n",
            "Epoch 582/800\n",
            "40/40 - 0s - loss: 900.9750 - val_loss: 876.9182 - 75ms/epoch - 2ms/step\n",
            "Epoch 583/800\n",
            "40/40 - 0s - loss: 906.3381 - val_loss: 871.3197 - 89ms/epoch - 2ms/step\n",
            "Epoch 584/800\n",
            "40/40 - 0s - loss: 901.3961 - val_loss: 868.7628 - 74ms/epoch - 2ms/step\n",
            "Epoch 585/800\n",
            "40/40 - 0s - loss: 905.3429 - val_loss: 880.7458 - 80ms/epoch - 2ms/step\n",
            "Epoch 586/800\n",
            "40/40 - 0s - loss: 918.5927 - val_loss: 906.1511 - 70ms/epoch - 2ms/step\n",
            "Epoch 587/800\n",
            "40/40 - 0s - loss: 935.8143 - val_loss: 913.5479 - 80ms/epoch - 2ms/step\n",
            "Epoch 588/800\n",
            "40/40 - 0s - loss: 923.8799 - val_loss: 885.6943 - 73ms/epoch - 2ms/step\n",
            "Epoch 589/800\n",
            "40/40 - 0s - loss: 921.8621 - val_loss: 878.1450 - 73ms/epoch - 2ms/step\n",
            "Epoch 590/800\n",
            "40/40 - 0s - loss: 933.2181 - val_loss: 922.7273 - 73ms/epoch - 2ms/step\n",
            "Epoch 591/800\n",
            "40/40 - 0s - loss: 935.7957 - val_loss: 887.6571 - 80ms/epoch - 2ms/step\n",
            "Epoch 592/800\n",
            "40/40 - 0s - loss: 926.0435 - val_loss: 884.2573 - 77ms/epoch - 2ms/step\n",
            "Epoch 593/800\n",
            "40/40 - 0s - loss: 910.8503 - val_loss: 879.1535 - 77ms/epoch - 2ms/step\n",
            "Epoch 594/800\n",
            "40/40 - 0s - loss: 906.2179 - val_loss: 859.0074 - 76ms/epoch - 2ms/step\n",
            "Epoch 595/800\n",
            "40/40 - 0s - loss: 896.3729 - val_loss: 863.7954 - 76ms/epoch - 2ms/step\n",
            "Epoch 596/800\n",
            "40/40 - 0s - loss: 898.7450 - val_loss: 863.8188 - 70ms/epoch - 2ms/step\n",
            "Epoch 597/800\n",
            "40/40 - 0s - loss: 890.5639 - val_loss: 869.7315 - 82ms/epoch - 2ms/step\n",
            "Epoch 598/800\n",
            "40/40 - 0s - loss: 892.5160 - val_loss: 860.4636 - 79ms/epoch - 2ms/step\n",
            "Epoch 599/800\n",
            "40/40 - 0s - loss: 896.3980 - val_loss: 852.7834 - 71ms/epoch - 2ms/step\n",
            "Epoch 600/800\n",
            "40/40 - 0s - loss: 889.1564 - val_loss: 851.7213 - 84ms/epoch - 2ms/step\n",
            "Epoch 601/800\n",
            "40/40 - 0s - loss: 894.2227 - val_loss: 867.3011 - 76ms/epoch - 2ms/step\n",
            "Epoch 602/800\n",
            "40/40 - 0s - loss: 899.2334 - val_loss: 871.1281 - 73ms/epoch - 2ms/step\n",
            "Epoch 603/800\n",
            "40/40 - 0s - loss: 901.1046 - val_loss: 868.9994 - 79ms/epoch - 2ms/step\n",
            "Epoch 604/800\n",
            "40/40 - 0s - loss: 906.7570 - val_loss: 888.0908 - 72ms/epoch - 2ms/step\n",
            "Epoch 605/800\n",
            "40/40 - 0s - loss: 903.9298 - val_loss: 895.5803 - 89ms/epoch - 2ms/step\n",
            "Epoch 606/800\n",
            "40/40 - 0s - loss: 911.7044 - val_loss: 877.8099 - 79ms/epoch - 2ms/step\n",
            "Epoch 607/800\n",
            "40/40 - 0s - loss: 902.5883 - val_loss: 881.2197 - 71ms/epoch - 2ms/step\n",
            "Epoch 608/800\n",
            "40/40 - 0s - loss: 910.0049 - val_loss: 867.6517 - 81ms/epoch - 2ms/step\n",
            "Epoch 609/800\n",
            "40/40 - 0s - loss: 907.6609 - val_loss: 886.1699 - 74ms/epoch - 2ms/step\n",
            "Epoch 610/800\n",
            "40/40 - 0s - loss: 914.8197 - val_loss: 885.7632 - 76ms/epoch - 2ms/step\n",
            "Epoch 611/800\n",
            "40/40 - 0s - loss: 938.0637 - val_loss: 936.8448 - 76ms/epoch - 2ms/step\n",
            "Epoch 612/800\n",
            "40/40 - 0s - loss: 946.8872 - val_loss: 917.3201 - 71ms/epoch - 2ms/step\n",
            "Epoch 613/800\n",
            "40/40 - 0s - loss: 937.7186 - val_loss: 883.5742 - 68ms/epoch - 2ms/step\n",
            "Epoch 614/800\n",
            "40/40 - 0s - loss: 910.2628 - val_loss: 876.1793 - 82ms/epoch - 2ms/step\n",
            "Epoch 615/800\n",
            "40/40 - 0s - loss: 904.0617 - val_loss: 904.0038 - 78ms/epoch - 2ms/step\n",
            "Epoch 616/800\n",
            "40/40 - 0s - loss: 921.4650 - val_loss: 900.2297 - 71ms/epoch - 2ms/step\n",
            "Epoch 617/800\n",
            "40/40 - 0s - loss: 920.5583 - val_loss: 895.4872 - 69ms/epoch - 2ms/step\n",
            "Epoch 618/800\n",
            "40/40 - 0s - loss: 906.7237 - val_loss: 869.3546 - 78ms/epoch - 2ms/step\n",
            "Epoch 619/800\n",
            "40/40 - 0s - loss: 905.8190 - val_loss: 866.9623 - 74ms/epoch - 2ms/step\n",
            "Epoch 620/800\n",
            "40/40 - 0s - loss: 897.3683 - val_loss: 859.5918 - 70ms/epoch - 2ms/step\n",
            "Epoch 621/800\n",
            "40/40 - 0s - loss: 888.3595 - val_loss: 843.8835 - 73ms/epoch - 2ms/step\n",
            "Epoch 622/800\n",
            "40/40 - 0s - loss: 874.0714 - val_loss: 837.2094 - 76ms/epoch - 2ms/step\n",
            "Epoch 623/800\n",
            "40/40 - 0s - loss: 870.8692 - val_loss: 843.6068 - 71ms/epoch - 2ms/step\n",
            "Epoch 624/800\n",
            "40/40 - 0s - loss: 874.1526 - val_loss: 832.4337 - 81ms/epoch - 2ms/step\n",
            "Epoch 625/800\n",
            "40/40 - 0s - loss: 875.0204 - val_loss: 834.3132 - 74ms/epoch - 2ms/step\n",
            "Epoch 626/800\n",
            "40/40 - 0s - loss: 870.7745 - val_loss: 856.4636 - 75ms/epoch - 2ms/step\n",
            "Epoch 627/800\n",
            "40/40 - 0s - loss: 882.5952 - val_loss: 849.9825 - 72ms/epoch - 2ms/step\n",
            "Epoch 628/800\n",
            "40/40 - 0s - loss: 887.0419 - val_loss: 860.7166 - 73ms/epoch - 2ms/step\n",
            "Epoch 629/800\n",
            "40/40 - 0s - loss: 909.1547 - val_loss: 864.6539 - 78ms/epoch - 2ms/step\n",
            "Epoch 630/800\n",
            "40/40 - 0s - loss: 907.4794 - val_loss: 872.4008 - 70ms/epoch - 2ms/step\n",
            "Epoch 631/800\n",
            "40/40 - 0s - loss: 901.7234 - val_loss: 860.4738 - 77ms/epoch - 2ms/step\n",
            "Epoch 632/800\n",
            "40/40 - 0s - loss: 902.9163 - val_loss: 870.5261 - 73ms/epoch - 2ms/step\n",
            "Epoch 633/800\n",
            "40/40 - 0s - loss: 919.5324 - val_loss: 887.1785 - 69ms/epoch - 2ms/step\n",
            "Epoch 634/800\n",
            "40/40 - 0s - loss: 930.5069 - val_loss: 879.8314 - 77ms/epoch - 2ms/step\n",
            "Epoch 635/800\n",
            "40/40 - 0s - loss: 905.1440 - val_loss: 861.1144 - 71ms/epoch - 2ms/step\n",
            "Epoch 636/800\n",
            "40/40 - 0s - loss: 896.3711 - val_loss: 866.3574 - 71ms/epoch - 2ms/step\n",
            "Epoch 637/800\n",
            "40/40 - 0s - loss: 892.4017 - val_loss: 856.2508 - 80ms/epoch - 2ms/step\n",
            "Epoch 638/800\n",
            "40/40 - 0s - loss: 893.7375 - val_loss: 847.1115 - 79ms/epoch - 2ms/step\n",
            "Epoch 639/800\n",
            "40/40 - 0s - loss: 906.1749 - val_loss: 858.9814 - 75ms/epoch - 2ms/step\n",
            "Epoch 640/800\n",
            "40/40 - 0s - loss: 904.1224 - val_loss: 890.4270 - 72ms/epoch - 2ms/step\n",
            "Epoch 641/800\n",
            "40/40 - 0s - loss: 913.2231 - val_loss: 864.4335 - 77ms/epoch - 2ms/step\n",
            "Epoch 642/800\n",
            "40/40 - 0s - loss: 897.6536 - val_loss: 857.4410 - 73ms/epoch - 2ms/step\n",
            "Epoch 643/800\n",
            "40/40 - 0s - loss: 893.8030 - val_loss: 866.7830 - 80ms/epoch - 2ms/step\n",
            "Epoch 644/800\n",
            "40/40 - 0s - loss: 886.5654 - val_loss: 830.5161 - 75ms/epoch - 2ms/step\n",
            "Epoch 645/800\n",
            "40/40 - 0s - loss: 882.9316 - val_loss: 848.5637 - 73ms/epoch - 2ms/step\n",
            "Epoch 646/800\n",
            "40/40 - 0s - loss: 881.3703 - val_loss: 854.8128 - 76ms/epoch - 2ms/step\n",
            "Epoch 647/800\n",
            "40/40 - 0s - loss: 883.0594 - val_loss: 852.2477 - 81ms/epoch - 2ms/step\n",
            "Epoch 648/800\n",
            "40/40 - 0s - loss: 894.2380 - val_loss: 866.6484 - 77ms/epoch - 2ms/step\n",
            "Epoch 649/800\n",
            "40/40 - 0s - loss: 911.4957 - val_loss: 906.8768 - 73ms/epoch - 2ms/step\n",
            "Epoch 650/800\n",
            "40/40 - 0s - loss: 916.8279 - val_loss: 885.2500 - 84ms/epoch - 2ms/step\n",
            "Epoch 651/800\n",
            "40/40 - 0s - loss: 918.6095 - val_loss: 889.1697 - 76ms/epoch - 2ms/step\n",
            "Epoch 652/800\n",
            "40/40 - 0s - loss: 907.4958 - val_loss: 853.7678 - 99ms/epoch - 2ms/step\n",
            "Epoch 653/800\n",
            "40/40 - 0s - loss: 899.6513 - val_loss: 869.2307 - 92ms/epoch - 2ms/step\n",
            "Epoch 654/800\n",
            "40/40 - 0s - loss: 898.0129 - val_loss: 843.4636 - 84ms/epoch - 2ms/step\n",
            "Epoch 655/800\n",
            "40/40 - 0s - loss: 885.3040 - val_loss: 849.9149 - 82ms/epoch - 2ms/step\n",
            "Epoch 656/800\n",
            "40/40 - 0s - loss: 886.0167 - val_loss: 858.9499 - 80ms/epoch - 2ms/step\n",
            "Epoch 657/800\n",
            "40/40 - 0s - loss: 888.1447 - val_loss: 847.0452 - 73ms/epoch - 2ms/step\n",
            "Epoch 658/800\n",
            "40/40 - 0s - loss: 873.9379 - val_loss: 843.1004 - 75ms/epoch - 2ms/step\n",
            "Epoch 659/800\n",
            "40/40 - 0s - loss: 884.9554 - val_loss: 853.2083 - 71ms/epoch - 2ms/step\n",
            "Epoch 660/800\n",
            "40/40 - 0s - loss: 899.0069 - val_loss: 882.5067 - 78ms/epoch - 2ms/step\n",
            "Epoch 661/800\n",
            "40/40 - 0s - loss: 920.7759 - val_loss: 884.0419 - 80ms/epoch - 2ms/step\n",
            "Epoch 662/800\n",
            "40/40 - 0s - loss: 915.8030 - val_loss: 882.7429 - 75ms/epoch - 2ms/step\n",
            "Epoch 663/800\n",
            "40/40 - 0s - loss: 908.0931 - val_loss: 873.4187 - 88ms/epoch - 2ms/step\n",
            "Epoch 664/800\n",
            "40/40 - 0s - loss: 900.3575 - val_loss: 867.2751 - 74ms/epoch - 2ms/step\n",
            "Epoch 665/800\n",
            "40/40 - 0s - loss: 899.3671 - val_loss: 887.3458 - 77ms/epoch - 2ms/step\n",
            "Epoch 666/800\n",
            "40/40 - 0s - loss: 912.6492 - val_loss: 903.0304 - 76ms/epoch - 2ms/step\n",
            "Epoch 667/800\n",
            "40/40 - 0s - loss: 914.2119 - val_loss: 873.3499 - 74ms/epoch - 2ms/step\n",
            "Epoch 668/800\n",
            "40/40 - 0s - loss: 920.2421 - val_loss: 875.0162 - 72ms/epoch - 2ms/step\n",
            "Epoch 669/800\n",
            "40/40 - 0s - loss: 899.3184 - val_loss: 855.2811 - 72ms/epoch - 2ms/step\n",
            "Epoch 670/800\n",
            "40/40 - 0s - loss: 888.6229 - val_loss: 868.3953 - 75ms/epoch - 2ms/step\n",
            "Epoch 671/800\n",
            "40/40 - 0s - loss: 885.8653 - val_loss: 842.3738 - 72ms/epoch - 2ms/step\n",
            "Epoch 672/800\n",
            "40/40 - 0s - loss: 888.4722 - val_loss: 871.8529 - 75ms/epoch - 2ms/step\n",
            "Epoch 673/800\n",
            "40/40 - 0s - loss: 878.1083 - val_loss: 840.5197 - 71ms/epoch - 2ms/step\n",
            "Epoch 674/800\n",
            "40/40 - 0s - loss: 881.4064 - val_loss: 846.8027 - 69ms/epoch - 2ms/step\n",
            "Epoch 675/800\n",
            "40/40 - 0s - loss: 878.3993 - val_loss: 848.4900 - 83ms/epoch - 2ms/step\n",
            "Epoch 676/800\n",
            "40/40 - 0s - loss: 880.1641 - val_loss: 881.1885 - 69ms/epoch - 2ms/step\n",
            "Epoch 677/800\n",
            "40/40 - 0s - loss: 898.0822 - val_loss: 853.0851 - 88ms/epoch - 2ms/step\n",
            "Epoch 678/800\n",
            "40/40 - 0s - loss: 895.5838 - val_loss: 861.6140 - 76ms/epoch - 2ms/step\n",
            "Epoch 679/800\n",
            "40/40 - 0s - loss: 896.2837 - val_loss: 866.4336 - 76ms/epoch - 2ms/step\n",
            "Epoch 680/800\n",
            "40/40 - 0s - loss: 890.2650 - val_loss: 858.3284 - 71ms/epoch - 2ms/step\n",
            "Epoch 681/800\n",
            "40/40 - 0s - loss: 891.1976 - val_loss: 873.7078 - 79ms/epoch - 2ms/step\n",
            "Epoch 682/800\n",
            "40/40 - 0s - loss: 887.4704 - val_loss: 859.2424 - 76ms/epoch - 2ms/step\n",
            "Epoch 683/800\n",
            "40/40 - 0s - loss: 884.4137 - val_loss: 846.3311 - 75ms/epoch - 2ms/step\n",
            "Epoch 684/800\n",
            "40/40 - 0s - loss: 875.8494 - val_loss: 840.8823 - 79ms/epoch - 2ms/step\n",
            "Epoch 685/800\n",
            "40/40 - 0s - loss: 872.0298 - val_loss: 858.4419 - 75ms/epoch - 2ms/step\n",
            "Epoch 686/800\n",
            "40/40 - 0s - loss: 875.7932 - val_loss: 841.1616 - 80ms/epoch - 2ms/step\n",
            "Epoch 687/800\n",
            "40/40 - 0s - loss: 886.1319 - val_loss: 862.1907 - 70ms/epoch - 2ms/step\n",
            "Epoch 688/800\n",
            "40/40 - 0s - loss: 881.2395 - val_loss: 841.9402 - 73ms/epoch - 2ms/step\n",
            "Epoch 689/800\n",
            "40/40 - 0s - loss: 879.2456 - val_loss: 848.1115 - 81ms/epoch - 2ms/step\n",
            "Epoch 690/800\n",
            "40/40 - 0s - loss: 894.1566 - val_loss: 882.6730 - 76ms/epoch - 2ms/step\n",
            "Epoch 691/800\n",
            "40/40 - 0s - loss: 900.0667 - val_loss: 874.3923 - 81ms/epoch - 2ms/step\n",
            "Epoch 692/800\n",
            "40/40 - 0s - loss: 905.4628 - val_loss: 868.1714 - 74ms/epoch - 2ms/step\n",
            "Epoch 693/800\n",
            "40/40 - 0s - loss: 900.5488 - val_loss: 862.3119 - 74ms/epoch - 2ms/step\n",
            "Epoch 694/800\n",
            "40/40 - 0s - loss: 890.8673 - val_loss: 871.4652 - 73ms/epoch - 2ms/step\n",
            "Epoch 695/800\n",
            "40/40 - 0s - loss: 905.5321 - val_loss: 880.6896 - 72ms/epoch - 2ms/step\n",
            "Epoch 696/800\n",
            "40/40 - 0s - loss: 926.3013 - val_loss: 867.9296 - 78ms/epoch - 2ms/step\n",
            "Epoch 697/800\n",
            "40/40 - 0s - loss: 907.6879 - val_loss: 858.4619 - 75ms/epoch - 2ms/step\n",
            "Epoch 698/800\n",
            "40/40 - 0s - loss: 888.5676 - val_loss: 848.2520 - 76ms/epoch - 2ms/step\n",
            "Epoch 699/800\n",
            "40/40 - 0s - loss: 891.0464 - val_loss: 858.6533 - 81ms/epoch - 2ms/step\n",
            "Epoch 700/800\n",
            "40/40 - 0s - loss: 900.2324 - val_loss: 868.8570 - 73ms/epoch - 2ms/step\n",
            "Epoch 701/800\n",
            "40/40 - 0s - loss: 892.2668 - val_loss: 862.5103 - 75ms/epoch - 2ms/step\n",
            "Epoch 702/800\n",
            "40/40 - 0s - loss: 908.8006 - val_loss: 887.0126 - 79ms/epoch - 2ms/step\n",
            "Epoch 703/800\n",
            "40/40 - 0s - loss: 904.1160 - val_loss: 860.4229 - 86ms/epoch - 2ms/step\n",
            "Epoch 704/800\n",
            "40/40 - 0s - loss: 894.3196 - val_loss: 849.6533 - 77ms/epoch - 2ms/step\n",
            "Epoch 705/800\n",
            "40/40 - 0s - loss: 884.8370 - val_loss: 851.1883 - 82ms/epoch - 2ms/step\n",
            "Epoch 706/800\n",
            "40/40 - 0s - loss: 886.9471 - val_loss: 856.0778 - 75ms/epoch - 2ms/step\n",
            "Epoch 707/800\n",
            "40/40 - 0s - loss: 890.7550 - val_loss: 849.1803 - 82ms/epoch - 2ms/step\n",
            "Epoch 708/800\n",
            "40/40 - 0s - loss: 888.3167 - val_loss: 850.1965 - 81ms/epoch - 2ms/step\n",
            "Epoch 709/800\n",
            "40/40 - 0s - loss: 880.2105 - val_loss: 849.9301 - 74ms/epoch - 2ms/step\n",
            "Epoch 710/800\n",
            "40/40 - 0s - loss: 875.6506 - val_loss: 842.0554 - 81ms/epoch - 2ms/step\n",
            "Epoch 711/800\n",
            "40/40 - 0s - loss: 870.9186 - val_loss: 835.9866 - 85ms/epoch - 2ms/step\n",
            "Epoch 712/800\n",
            "40/40 - 0s - loss: 868.6061 - val_loss: 823.9503 - 73ms/epoch - 2ms/step\n",
            "Epoch 713/800\n",
            "40/40 - 0s - loss: 867.5261 - val_loss: 831.0229 - 82ms/epoch - 2ms/step\n",
            "Epoch 714/800\n",
            "40/40 - 0s - loss: 870.2430 - val_loss: 844.0045 - 72ms/epoch - 2ms/step\n",
            "Epoch 715/800\n",
            "40/40 - 0s - loss: 880.7294 - val_loss: 841.5765 - 82ms/epoch - 2ms/step\n",
            "Epoch 716/800\n",
            "40/40 - 0s - loss: 892.0654 - val_loss: 866.8692 - 77ms/epoch - 2ms/step\n",
            "Epoch 717/800\n",
            "40/40 - 0s - loss: 892.7503 - val_loss: 853.6635 - 73ms/epoch - 2ms/step\n",
            "Epoch 718/800\n",
            "40/40 - 0s - loss: 882.0756 - val_loss: 837.2576 - 78ms/epoch - 2ms/step\n",
            "Epoch 719/800\n",
            "40/40 - 0s - loss: 863.8257 - val_loss: 820.1558 - 74ms/epoch - 2ms/step\n",
            "Epoch 720/800\n",
            "40/40 - 0s - loss: 865.6889 - val_loss: 827.3688 - 75ms/epoch - 2ms/step\n",
            "Epoch 721/800\n",
            "40/40 - 0s - loss: 871.8927 - val_loss: 837.8352 - 78ms/epoch - 2ms/step\n",
            "Epoch 722/800\n",
            "40/40 - 0s - loss: 875.5718 - val_loss: 850.3159 - 88ms/epoch - 2ms/step\n",
            "Epoch 723/800\n",
            "40/40 - 0s - loss: 877.3130 - val_loss: 873.1712 - 72ms/epoch - 2ms/step\n",
            "Epoch 724/800\n",
            "40/40 - 0s - loss: 884.8336 - val_loss: 866.8703 - 75ms/epoch - 2ms/step\n",
            "Epoch 725/800\n",
            "40/40 - 0s - loss: 895.0496 - val_loss: 845.7786 - 87ms/epoch - 2ms/step\n",
            "Epoch 726/800\n",
            "40/40 - 0s - loss: 893.9581 - val_loss: 863.1881 - 69ms/epoch - 2ms/step\n",
            "Epoch 727/800\n",
            "40/40 - 0s - loss: 890.8560 - val_loss: 849.6007 - 79ms/epoch - 2ms/step\n",
            "Epoch 728/800\n",
            "40/40 - 0s - loss: 898.8400 - val_loss: 875.4399 - 114ms/epoch - 3ms/step\n",
            "Epoch 729/800\n",
            "40/40 - 0s - loss: 899.4824 - val_loss: 854.7631 - 80ms/epoch - 2ms/step\n",
            "Epoch 730/800\n",
            "40/40 - 0s - loss: 899.9305 - val_loss: 880.0477 - 82ms/epoch - 2ms/step\n",
            "Epoch 731/800\n",
            "40/40 - 0s - loss: 906.8350 - val_loss: 914.4148 - 85ms/epoch - 2ms/step\n",
            "Epoch 732/800\n",
            "40/40 - 0s - loss: 931.4365 - val_loss: 900.5150 - 66ms/epoch - 2ms/step\n",
            "Epoch 733/800\n",
            "40/40 - 0s - loss: 957.1724 - val_loss: 928.2427 - 74ms/epoch - 2ms/step\n",
            "Epoch 734/800\n",
            "40/40 - 0s - loss: 947.0446 - val_loss: 913.0894 - 74ms/epoch - 2ms/step\n",
            "Epoch 735/800\n",
            "40/40 - 0s - loss: 933.5771 - val_loss: 876.9618 - 88ms/epoch - 2ms/step\n",
            "Epoch 736/800\n",
            "40/40 - 0s - loss: 903.3252 - val_loss: 869.4739 - 71ms/epoch - 2ms/step\n",
            "Epoch 737/800\n",
            "40/40 - 0s - loss: 891.1356 - val_loss: 827.0939 - 70ms/epoch - 2ms/step\n",
            "Epoch 738/800\n",
            "40/40 - 0s - loss: 867.1113 - val_loss: 824.6176 - 71ms/epoch - 2ms/step\n",
            "Epoch 739/800\n",
            "40/40 - 0s - loss: 854.9744 - val_loss: 822.0170 - 72ms/epoch - 2ms/step\n",
            "Epoch 740/800\n",
            "40/40 - 0s - loss: 853.2468 - val_loss: 810.7048 - 71ms/epoch - 2ms/step\n",
            "Epoch 741/800\n",
            "40/40 - 0s - loss: 853.7096 - val_loss: 823.0448 - 69ms/epoch - 2ms/step\n",
            "Epoch 742/800\n",
            "40/40 - 0s - loss: 851.5855 - val_loss: 815.5983 - 75ms/epoch - 2ms/step\n",
            "Epoch 743/800\n",
            "40/40 - 0s - loss: 851.4810 - val_loss: 813.9193 - 71ms/epoch - 2ms/step\n",
            "Epoch 744/800\n",
            "40/40 - 0s - loss: 853.4858 - val_loss: 832.4114 - 68ms/epoch - 2ms/step\n",
            "Epoch 745/800\n",
            "40/40 - 0s - loss: 865.5428 - val_loss: 827.3018 - 82ms/epoch - 2ms/step\n",
            "Epoch 746/800\n",
            "40/40 - 0s - loss: 863.0352 - val_loss: 845.6949 - 78ms/epoch - 2ms/step\n",
            "Epoch 747/800\n",
            "40/40 - 0s - loss: 861.9177 - val_loss: 819.0359 - 72ms/epoch - 2ms/step\n",
            "Epoch 748/800\n",
            "40/40 - 0s - loss: 848.1743 - val_loss: 809.3630 - 68ms/epoch - 2ms/step\n",
            "Epoch 749/800\n",
            "40/40 - 0s - loss: 852.8818 - val_loss: 824.2512 - 70ms/epoch - 2ms/step\n",
            "Epoch 750/800\n",
            "40/40 - 0s - loss: 857.0731 - val_loss: 826.3418 - 70ms/epoch - 2ms/step\n",
            "Epoch 751/800\n",
            "40/40 - 0s - loss: 854.7606 - val_loss: 832.0386 - 70ms/epoch - 2ms/step\n",
            "Epoch 752/800\n",
            "40/40 - 0s - loss: 869.9262 - val_loss: 844.1555 - 69ms/epoch - 2ms/step\n",
            "Epoch 753/800\n",
            "40/40 - 0s - loss: 878.3224 - val_loss: 842.4456 - 70ms/epoch - 2ms/step\n",
            "Epoch 754/800\n",
            "40/40 - 0s - loss: 869.2331 - val_loss: 838.1066 - 70ms/epoch - 2ms/step\n",
            "Epoch 755/800\n",
            "40/40 - 0s - loss: 877.3484 - val_loss: 838.2748 - 70ms/epoch - 2ms/step\n",
            "Epoch 756/800\n",
            "40/40 - 0s - loss: 871.5959 - val_loss: 833.6453 - 74ms/epoch - 2ms/step\n",
            "Epoch 757/800\n",
            "40/40 - 0s - loss: 877.5002 - val_loss: 837.3349 - 69ms/epoch - 2ms/step\n",
            "Epoch 758/800\n",
            "40/40 - 0s - loss: 880.3181 - val_loss: 837.9486 - 71ms/epoch - 2ms/step\n",
            "Epoch 759/800\n",
            "40/40 - 0s - loss: 882.9172 - val_loss: 847.4652 - 73ms/epoch - 2ms/step\n",
            "Epoch 760/800\n",
            "40/40 - 0s - loss: 882.7061 - val_loss: 838.3958 - 74ms/epoch - 2ms/step\n",
            "Epoch 761/800\n",
            "40/40 - 0s - loss: 882.9884 - val_loss: 863.0728 - 71ms/epoch - 2ms/step\n",
            "Epoch 762/800\n",
            "40/40 - 0s - loss: 898.3454 - val_loss: 865.7922 - 73ms/epoch - 2ms/step\n",
            "Epoch 763/800\n",
            "40/40 - 0s - loss: 903.8457 - val_loss: 869.0341 - 73ms/epoch - 2ms/step\n",
            "Epoch 764/800\n",
            "40/40 - 0s - loss: 895.1130 - val_loss: 853.8878 - 72ms/epoch - 2ms/step\n",
            "Epoch 765/800\n",
            "40/40 - 0s - loss: 880.4904 - val_loss: 855.7313 - 72ms/epoch - 2ms/step\n",
            "Epoch 766/800\n",
            "40/40 - 0s - loss: 890.4095 - val_loss: 857.6227 - 72ms/epoch - 2ms/step\n",
            "Epoch 767/800\n",
            "40/40 - 0s - loss: 898.0349 - val_loss: 874.0161 - 72ms/epoch - 2ms/step\n",
            "Epoch 768/800\n",
            "40/40 - 0s - loss: 891.3812 - val_loss: 862.1161 - 69ms/epoch - 2ms/step\n",
            "Epoch 769/800\n",
            "40/40 - 0s - loss: 901.6841 - val_loss: 871.4036 - 68ms/epoch - 2ms/step\n",
            "Epoch 770/800\n",
            "40/40 - 0s - loss: 890.8450 - val_loss: 855.5665 - 71ms/epoch - 2ms/step\n",
            "Epoch 771/800\n",
            "40/40 - 0s - loss: 891.1527 - val_loss: 857.9890 - 69ms/epoch - 2ms/step\n",
            "Epoch 772/800\n",
            "40/40 - 0s - loss: 904.6150 - val_loss: 855.7002 - 71ms/epoch - 2ms/step\n",
            "Epoch 773/800\n",
            "40/40 - 0s - loss: 897.5807 - val_loss: 856.3001 - 69ms/epoch - 2ms/step\n",
            "Epoch 774/800\n",
            "40/40 - 0s - loss: 876.4169 - val_loss: 838.0296 - 70ms/epoch - 2ms/step\n",
            "Epoch 775/800\n",
            "40/40 - 0s - loss: 865.7894 - val_loss: 837.7642 - 68ms/epoch - 2ms/step\n",
            "Epoch 776/800\n",
            "40/40 - 0s - loss: 862.2906 - val_loss: 836.5674 - 70ms/epoch - 2ms/step\n",
            "Epoch 777/800\n",
            "40/40 - 0s - loss: 872.4275 - val_loss: 835.4805 - 72ms/epoch - 2ms/step\n",
            "Epoch 778/800\n",
            "40/40 - 0s - loss: 874.9623 - val_loss: 839.3779 - 69ms/epoch - 2ms/step\n",
            "Epoch 779/800\n",
            "40/40 - 0s - loss: 872.3306 - val_loss: 838.8595 - 70ms/epoch - 2ms/step\n",
            "Epoch 780/800\n",
            "40/40 - 0s - loss: 868.6516 - val_loss: 832.4261 - 79ms/epoch - 2ms/step\n",
            "Epoch 781/800\n",
            "40/40 - 0s - loss: 859.7020 - val_loss: 830.7039 - 74ms/epoch - 2ms/step\n",
            "Epoch 782/800\n",
            "40/40 - 0s - loss: 857.6163 - val_loss: 825.9337 - 72ms/epoch - 2ms/step\n",
            "Epoch 783/800\n",
            "40/40 - 0s - loss: 860.9891 - val_loss: 821.8242 - 73ms/epoch - 2ms/step\n",
            "Epoch 784/800\n",
            "40/40 - 0s - loss: 868.8271 - val_loss: 849.6501 - 75ms/epoch - 2ms/step\n",
            "Epoch 785/800\n",
            "40/40 - 0s - loss: 873.4078 - val_loss: 839.6484 - 70ms/epoch - 2ms/step\n",
            "Epoch 786/800\n",
            "40/40 - 0s - loss: 862.9047 - val_loss: 839.8589 - 68ms/epoch - 2ms/step\n",
            "Epoch 787/800\n",
            "40/40 - 0s - loss: 863.6095 - val_loss: 827.6064 - 71ms/epoch - 2ms/step\n",
            "Epoch 788/800\n",
            "40/40 - 0s - loss: 856.8932 - val_loss: 818.3776 - 70ms/epoch - 2ms/step\n",
            "Epoch 789/800\n",
            "40/40 - 0s - loss: 857.8085 - val_loss: 833.1946 - 70ms/epoch - 2ms/step\n",
            "Epoch 790/800\n",
            "40/40 - 0s - loss: 854.2864 - val_loss: 817.5017 - 71ms/epoch - 2ms/step\n",
            "Epoch 791/800\n",
            "40/40 - 0s - loss: 851.3431 - val_loss: 824.1391 - 70ms/epoch - 2ms/step\n",
            "Epoch 792/800\n",
            "40/40 - 0s - loss: 861.5093 - val_loss: 834.5158 - 68ms/epoch - 2ms/step\n",
            "Epoch 793/800\n",
            "40/40 - 0s - loss: 868.1988 - val_loss: 835.7507 - 68ms/epoch - 2ms/step\n",
            "Epoch 794/800\n",
            "40/40 - 0s - loss: 872.2079 - val_loss: 838.1672 - 69ms/epoch - 2ms/step\n",
            "Epoch 795/800\n",
            "40/40 - 0s - loss: 874.3462 - val_loss: 835.4821 - 71ms/epoch - 2ms/step\n",
            "Epoch 796/800\n",
            "40/40 - 0s - loss: 872.9766 - val_loss: 843.7544 - 69ms/epoch - 2ms/step\n",
            "Epoch 797/800\n",
            "40/40 - 0s - loss: 877.8945 - val_loss: 851.0601 - 68ms/epoch - 2ms/step\n",
            "Epoch 798/800\n",
            "40/40 - 0s - loss: 886.4225 - val_loss: 852.8105 - 71ms/epoch - 2ms/step\n",
            "Epoch 799/800\n",
            "40/40 - 0s - loss: 890.5150 - val_loss: 857.0752 - 73ms/epoch - 2ms/step\n",
            "Epoch 800/800\n",
            "40/40 - 0s - loss: 880.0495 - val_loss: 833.8971 - 73ms/epoch - 2ms/step\n"
          ]
        }
      ],
      "source": [
        "# fit the autoencoder model to reconstruct input\n",
        "history = model_2.fit(x, x, epochs=800, batch_size=16, verbose=2, validation_data=(x,x))\n",
        "# plot loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "J6NH4Ya7TYrK"
      },
      "outputs": [],
      "source": [
        "# define encoder\n",
        "def get_model_3(n_inputs=324):\n",
        "  visible = Input(shape=(n_inputs,))\n",
        "  # encoder level 1\n",
        "  e = Dense(n_inputs)(visible)\n",
        "  # e = BatchNormalization()(e)\n",
        "  e = ReLU()(e)\n",
        "\n",
        "  e = Dense(97)(e)\n",
        "  # e = BatchNormalization()(e)\n",
        "  e = ReLU()(e)\n",
        "\n",
        "  e = Dense(29)(e)\n",
        "  # e = BatchNormalization()(e)\n",
        "  e = ReLU()(e)\n",
        "\n",
        "  # bottleneck\n",
        "  # n_bottleneck = round(float(n_inputs) / 2.0)\n",
        "  bottleneck = Dense(9)(e)\n",
        "  # e = BatchNormalization()(bottleneck)\n",
        "\n",
        "  e = Dense(29)(bottleneck)\n",
        "  # e = BatchNormalization()(e)\n",
        "  e = ReLU()(e)\n",
        "\n",
        "  e = Dense(97)(e)\n",
        "  # e = BatchNormalization()(e)\n",
        "  e = ReLU()(e)\n",
        "\n",
        "  # decoder level 1\n",
        "  # d = Dense(n_inputs*2)(bottleneck)\n",
        "  # d = BatchNormalization()(d)\n",
        "  # d = LeakyReLU()(d)\n",
        "  # output layer\n",
        "  output = Dense(n_inputs, activation='linear')(e)\n",
        "  # define autoencoder model\n",
        "  model = Model(inputs=visible, outputs=output)\n",
        "  # compile autoencoder model\n",
        "  model.compile(optimizer='adam', loss='mse')\n",
        "  # plot the autoencoder\n",
        "  # plot_model(model, 'autoencoder_compress.png', show_shapes=True)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ll7qxepsTbi1",
        "outputId": "b9eff4b6-c16d-4881-efcb-af160a63f494"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 324)]             0         \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 324)               105300    \n",
            "                                                                 \n",
            " re_lu_13 (ReLU)             (None, 324)               0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 97)                31525     \n",
            "                                                                 \n",
            " re_lu_14 (ReLU)             (None, 97)                0         \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 29)                2842      \n",
            "                                                                 \n",
            " re_lu_15 (ReLU)             (None, 29)                0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 9)                 270       \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 29)                290       \n",
            "                                                                 \n",
            " re_lu_16 (ReLU)             (None, 29)                0         \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 97)                2910      \n",
            "                                                                 \n",
            " re_lu_17 (ReLU)             (None, 97)                0         \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 324)               31752     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 174,889\n",
            "Trainable params: 174,889\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_3 = get_model_3()\n",
        "model_3.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z85VPXerVWOD",
        "outputId": "ba8cee38-15a4-4993-f751-2ad3138f5c2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "40/40 - 0s - loss: 13100.2490 - val_loss: 10502.5762 - 444ms/epoch - 11ms/step\n",
            "Epoch 2/1000\n",
            "40/40 - 0s - loss: 8790.7959 - val_loss: 7903.9189 - 82ms/epoch - 2ms/step\n",
            "Epoch 3/1000\n",
            "40/40 - 0s - loss: 7806.0854 - val_loss: 7524.4648 - 73ms/epoch - 2ms/step\n",
            "Epoch 4/1000\n",
            "40/40 - 0s - loss: 7421.1611 - val_loss: 7066.0576 - 77ms/epoch - 2ms/step\n",
            "Epoch 5/1000\n",
            "40/40 - 0s - loss: 6944.3354 - val_loss: 6615.0942 - 79ms/epoch - 2ms/step\n",
            "Epoch 6/1000\n",
            "40/40 - 0s - loss: 6539.3066 - val_loss: 6290.1489 - 77ms/epoch - 2ms/step\n",
            "Epoch 7/1000\n",
            "40/40 - 0s - loss: 6224.0923 - val_loss: 5995.1904 - 74ms/epoch - 2ms/step\n",
            "Epoch 8/1000\n",
            "40/40 - 0s - loss: 5965.6221 - val_loss: 5785.2124 - 77ms/epoch - 2ms/step\n",
            "Epoch 9/1000\n",
            "40/40 - 0s - loss: 5795.8442 - val_loss: 5694.8418 - 87ms/epoch - 2ms/step\n",
            "Epoch 10/1000\n",
            "40/40 - 0s - loss: 5667.2798 - val_loss: 5513.9004 - 79ms/epoch - 2ms/step\n",
            "Epoch 11/1000\n",
            "40/40 - 0s - loss: 5496.6479 - val_loss: 5378.5796 - 78ms/epoch - 2ms/step\n",
            "Epoch 12/1000\n",
            "40/40 - 0s - loss: 5352.7109 - val_loss: 5224.6055 - 81ms/epoch - 2ms/step\n",
            "Epoch 13/1000\n",
            "40/40 - 0s - loss: 5242.0249 - val_loss: 5082.6592 - 74ms/epoch - 2ms/step\n",
            "Epoch 14/1000\n",
            "40/40 - 0s - loss: 5115.8911 - val_loss: 4998.7974 - 76ms/epoch - 2ms/step\n",
            "Epoch 15/1000\n",
            "40/40 - 0s - loss: 5038.3135 - val_loss: 4941.7329 - 77ms/epoch - 2ms/step\n",
            "Epoch 16/1000\n",
            "40/40 - 0s - loss: 4968.8472 - val_loss: 4837.5000 - 80ms/epoch - 2ms/step\n",
            "Epoch 17/1000\n",
            "40/40 - 0s - loss: 4864.3423 - val_loss: 4760.0171 - 79ms/epoch - 2ms/step\n",
            "Epoch 18/1000\n",
            "40/40 - 0s - loss: 4782.8301 - val_loss: 4771.7710 - 74ms/epoch - 2ms/step\n",
            "Epoch 19/1000\n",
            "40/40 - 0s - loss: 4749.9473 - val_loss: 4625.8960 - 79ms/epoch - 2ms/step\n",
            "Epoch 20/1000\n",
            "40/40 - 0s - loss: 4673.8672 - val_loss: 4592.2388 - 79ms/epoch - 2ms/step\n",
            "Epoch 21/1000\n",
            "40/40 - 0s - loss: 4615.3208 - val_loss: 4507.3608 - 80ms/epoch - 2ms/step\n",
            "Epoch 22/1000\n",
            "40/40 - 0s - loss: 4554.0039 - val_loss: 4496.6475 - 78ms/epoch - 2ms/step\n",
            "Epoch 23/1000\n",
            "40/40 - 0s - loss: 4582.2007 - val_loss: 4469.5396 - 75ms/epoch - 2ms/step\n",
            "Epoch 24/1000\n",
            "40/40 - 0s - loss: 4510.2407 - val_loss: 4443.2104 - 92ms/epoch - 2ms/step\n",
            "Epoch 25/1000\n",
            "40/40 - 0s - loss: 4451.3931 - val_loss: 4429.5132 - 81ms/epoch - 2ms/step\n",
            "Epoch 26/1000\n",
            "40/40 - 0s - loss: 4446.0820 - val_loss: 4330.4043 - 77ms/epoch - 2ms/step\n",
            "Epoch 27/1000\n",
            "40/40 - 0s - loss: 4407.1362 - val_loss: 4309.5127 - 80ms/epoch - 2ms/step\n",
            "Epoch 28/1000\n",
            "40/40 - 0s - loss: 4373.7090 - val_loss: 4302.4219 - 81ms/epoch - 2ms/step\n",
            "Epoch 29/1000\n",
            "40/40 - 0s - loss: 4347.1807 - val_loss: 4269.4409 - 79ms/epoch - 2ms/step\n",
            "Epoch 30/1000\n",
            "40/40 - 0s - loss: 4307.5557 - val_loss: 4228.6709 - 79ms/epoch - 2ms/step\n",
            "Epoch 31/1000\n",
            "40/40 - 0s - loss: 4272.0776 - val_loss: 4170.2544 - 73ms/epoch - 2ms/step\n",
            "Epoch 32/1000\n",
            "40/40 - 0s - loss: 4242.3760 - val_loss: 4195.6562 - 81ms/epoch - 2ms/step\n",
            "Epoch 33/1000\n",
            "40/40 - 0s - loss: 4227.5674 - val_loss: 4127.0576 - 73ms/epoch - 2ms/step\n",
            "Epoch 34/1000\n",
            "40/40 - 0s - loss: 4205.4688 - val_loss: 4144.2749 - 79ms/epoch - 2ms/step\n",
            "Epoch 35/1000\n",
            "40/40 - 0s - loss: 4194.9385 - val_loss: 4100.9868 - 83ms/epoch - 2ms/step\n",
            "Epoch 36/1000\n",
            "40/40 - 0s - loss: 4180.7607 - val_loss: 4087.9363 - 77ms/epoch - 2ms/step\n",
            "Epoch 37/1000\n",
            "40/40 - 0s - loss: 4157.4448 - val_loss: 4114.5532 - 82ms/epoch - 2ms/step\n",
            "Epoch 38/1000\n",
            "40/40 - 0s - loss: 4175.1660 - val_loss: 4078.9048 - 72ms/epoch - 2ms/step\n",
            "Epoch 39/1000\n",
            "40/40 - 0s - loss: 4135.4863 - val_loss: 4072.5967 - 78ms/epoch - 2ms/step\n",
            "Epoch 40/1000\n",
            "40/40 - 0s - loss: 4131.3931 - val_loss: 4036.1355 - 78ms/epoch - 2ms/step\n",
            "Epoch 41/1000\n",
            "40/40 - 0s - loss: 4118.5591 - val_loss: 4079.8301 - 77ms/epoch - 2ms/step\n",
            "Epoch 42/1000\n",
            "40/40 - 0s - loss: 4104.4678 - val_loss: 4051.5864 - 81ms/epoch - 2ms/step\n",
            "Epoch 43/1000\n",
            "40/40 - 0s - loss: 4105.4727 - val_loss: 4011.0122 - 75ms/epoch - 2ms/step\n",
            "Epoch 44/1000\n",
            "40/40 - 0s - loss: 4089.7468 - val_loss: 4050.1584 - 82ms/epoch - 2ms/step\n",
            "Epoch 45/1000\n",
            "40/40 - 0s - loss: 4087.4521 - val_loss: 3994.9175 - 73ms/epoch - 2ms/step\n",
            "Epoch 46/1000\n",
            "40/40 - 0s - loss: 4034.0723 - val_loss: 3924.7395 - 77ms/epoch - 2ms/step\n",
            "Epoch 47/1000\n",
            "40/40 - 0s - loss: 3989.6050 - val_loss: 3907.8105 - 75ms/epoch - 2ms/step\n",
            "Epoch 48/1000\n",
            "40/40 - 0s - loss: 3975.3503 - val_loss: 3884.5496 - 77ms/epoch - 2ms/step\n",
            "Epoch 49/1000\n",
            "40/40 - 0s - loss: 3967.1416 - val_loss: 3879.7603 - 75ms/epoch - 2ms/step\n",
            "Epoch 50/1000\n",
            "40/40 - 0s - loss: 3963.9976 - val_loss: 3871.2041 - 75ms/epoch - 2ms/step\n",
            "Epoch 51/1000\n",
            "40/40 - 0s - loss: 3940.1006 - val_loss: 3862.4934 - 80ms/epoch - 2ms/step\n",
            "Epoch 52/1000\n",
            "40/40 - 0s - loss: 3898.6960 - val_loss: 3842.7417 - 78ms/epoch - 2ms/step\n",
            "Epoch 53/1000\n",
            "40/40 - 0s - loss: 3884.3635 - val_loss: 3801.5984 - 71ms/epoch - 2ms/step\n",
            "Epoch 54/1000\n",
            "40/40 - 0s - loss: 3900.1714 - val_loss: 3798.2212 - 75ms/epoch - 2ms/step\n",
            "Epoch 55/1000\n",
            "40/40 - 0s - loss: 3894.7468 - val_loss: 3793.2576 - 82ms/epoch - 2ms/step\n",
            "Epoch 56/1000\n",
            "40/40 - 0s - loss: 3842.4780 - val_loss: 3754.7283 - 71ms/epoch - 2ms/step\n",
            "Epoch 57/1000\n",
            "40/40 - 0s - loss: 3822.0110 - val_loss: 3779.2041 - 80ms/epoch - 2ms/step\n",
            "Epoch 58/1000\n",
            "40/40 - 0s - loss: 3822.6946 - val_loss: 3732.5762 - 73ms/epoch - 2ms/step\n",
            "Epoch 59/1000\n",
            "40/40 - 0s - loss: 3798.1841 - val_loss: 3715.3403 - 77ms/epoch - 2ms/step\n",
            "Epoch 60/1000\n",
            "40/40 - 0s - loss: 3817.3330 - val_loss: 3764.2959 - 77ms/epoch - 2ms/step\n",
            "Epoch 61/1000\n",
            "40/40 - 0s - loss: 3780.3235 - val_loss: 3680.1514 - 77ms/epoch - 2ms/step\n",
            "Epoch 62/1000\n",
            "40/40 - 0s - loss: 3770.7444 - val_loss: 3701.2705 - 74ms/epoch - 2ms/step\n",
            "Epoch 63/1000\n",
            "40/40 - 0s - loss: 3737.4304 - val_loss: 3644.7185 - 75ms/epoch - 2ms/step\n",
            "Epoch 64/1000\n",
            "40/40 - 0s - loss: 3706.3242 - val_loss: 3602.6165 - 78ms/epoch - 2ms/step\n",
            "Epoch 65/1000\n",
            "40/40 - 0s - loss: 3714.5239 - val_loss: 3649.3313 - 71ms/epoch - 2ms/step\n",
            "Epoch 66/1000\n",
            "40/40 - 0s - loss: 3709.7515 - val_loss: 3642.7456 - 76ms/epoch - 2ms/step\n",
            "Epoch 67/1000\n",
            "40/40 - 0s - loss: 3735.4712 - val_loss: 3647.0801 - 80ms/epoch - 2ms/step\n",
            "Epoch 68/1000\n",
            "40/40 - 0s - loss: 3684.3416 - val_loss: 3606.5723 - 79ms/epoch - 2ms/step\n",
            "Epoch 69/1000\n",
            "40/40 - 0s - loss: 3667.1921 - val_loss: 3577.8552 - 79ms/epoch - 2ms/step\n",
            "Epoch 70/1000\n",
            "40/40 - 0s - loss: 3631.7485 - val_loss: 3540.8684 - 76ms/epoch - 2ms/step\n",
            "Epoch 71/1000\n",
            "40/40 - 0s - loss: 3666.5217 - val_loss: 3600.9194 - 74ms/epoch - 2ms/step\n",
            "Epoch 72/1000\n",
            "40/40 - 0s - loss: 3642.1650 - val_loss: 3553.2063 - 76ms/epoch - 2ms/step\n",
            "Epoch 73/1000\n",
            "40/40 - 0s - loss: 3627.4988 - val_loss: 3533.8059 - 73ms/epoch - 2ms/step\n",
            "Epoch 74/1000\n",
            "40/40 - 0s - loss: 3579.8621 - val_loss: 3520.0852 - 80ms/epoch - 2ms/step\n",
            "Epoch 75/1000\n",
            "40/40 - 0s - loss: 3599.2012 - val_loss: 3578.1799 - 71ms/epoch - 2ms/step\n",
            "Epoch 76/1000\n",
            "40/40 - 0s - loss: 3604.8923 - val_loss: 3487.4104 - 76ms/epoch - 2ms/step\n",
            "Epoch 77/1000\n",
            "40/40 - 0s - loss: 3558.6084 - val_loss: 3455.2468 - 77ms/epoch - 2ms/step\n",
            "Epoch 78/1000\n",
            "40/40 - 0s - loss: 3522.8176 - val_loss: 3434.4583 - 73ms/epoch - 2ms/step\n",
            "Epoch 79/1000\n",
            "40/40 - 0s - loss: 3508.1953 - val_loss: 3411.5259 - 70ms/epoch - 2ms/step\n",
            "Epoch 80/1000\n",
            "40/40 - 0s - loss: 3503.7834 - val_loss: 3435.8647 - 81ms/epoch - 2ms/step\n",
            "Epoch 81/1000\n",
            "40/40 - 0s - loss: 3507.5530 - val_loss: 3397.5833 - 87ms/epoch - 2ms/step\n",
            "Epoch 82/1000\n",
            "40/40 - 0s - loss: 3491.7808 - val_loss: 3424.8274 - 72ms/epoch - 2ms/step\n",
            "Epoch 83/1000\n",
            "40/40 - 0s - loss: 3495.4666 - val_loss: 3397.0322 - 77ms/epoch - 2ms/step\n",
            "Epoch 84/1000\n",
            "40/40 - 0s - loss: 3469.3652 - val_loss: 3366.6274 - 76ms/epoch - 2ms/step\n",
            "Epoch 85/1000\n",
            "40/40 - 0s - loss: 3451.1133 - val_loss: 3376.9712 - 82ms/epoch - 2ms/step\n",
            "Epoch 86/1000\n",
            "40/40 - 0s - loss: 3433.7874 - val_loss: 3320.0032 - 83ms/epoch - 2ms/step\n",
            "Epoch 87/1000\n",
            "40/40 - 0s - loss: 3427.2605 - val_loss: 3343.7249 - 82ms/epoch - 2ms/step\n",
            "Epoch 88/1000\n",
            "40/40 - 0s - loss: 3428.0129 - val_loss: 3333.9099 - 83ms/epoch - 2ms/step\n",
            "Epoch 89/1000\n",
            "40/40 - 0s - loss: 3473.6919 - val_loss: 3439.1890 - 83ms/epoch - 2ms/step\n",
            "Epoch 90/1000\n",
            "40/40 - 0s - loss: 3476.1489 - val_loss: 3358.3757 - 80ms/epoch - 2ms/step\n",
            "Epoch 91/1000\n",
            "40/40 - 0s - loss: 3425.6262 - val_loss: 3330.4001 - 75ms/epoch - 2ms/step\n",
            "Epoch 92/1000\n",
            "40/40 - 0s - loss: 3396.7261 - val_loss: 3293.6895 - 73ms/epoch - 2ms/step\n",
            "Epoch 93/1000\n",
            "40/40 - 0s - loss: 3368.3208 - val_loss: 3270.1453 - 79ms/epoch - 2ms/step\n",
            "Epoch 94/1000\n",
            "40/40 - 0s - loss: 3352.5349 - val_loss: 3291.8733 - 75ms/epoch - 2ms/step\n",
            "Epoch 95/1000\n",
            "40/40 - 0s - loss: 3336.6467 - val_loss: 3264.8960 - 72ms/epoch - 2ms/step\n",
            "Epoch 96/1000\n",
            "40/40 - 0s - loss: 3326.3545 - val_loss: 3246.1077 - 75ms/epoch - 2ms/step\n",
            "Epoch 97/1000\n",
            "40/40 - 0s - loss: 3332.3396 - val_loss: 3261.9783 - 75ms/epoch - 2ms/step\n",
            "Epoch 98/1000\n",
            "40/40 - 0s - loss: 3334.9402 - val_loss: 3235.0718 - 74ms/epoch - 2ms/step\n",
            "Epoch 99/1000\n",
            "40/40 - 0s - loss: 3310.2185 - val_loss: 3212.6562 - 74ms/epoch - 2ms/step\n",
            "Epoch 100/1000\n",
            "40/40 - 0s - loss: 3332.0947 - val_loss: 3243.8989 - 74ms/epoch - 2ms/step\n",
            "Epoch 101/1000\n",
            "40/40 - 0s - loss: 3309.7744 - val_loss: 3212.2666 - 85ms/epoch - 2ms/step\n",
            "Epoch 102/1000\n",
            "40/40 - 0s - loss: 3297.6167 - val_loss: 3231.3372 - 75ms/epoch - 2ms/step\n",
            "Epoch 103/1000\n",
            "40/40 - 0s - loss: 3296.7092 - val_loss: 3203.9578 - 71ms/epoch - 2ms/step\n",
            "Epoch 104/1000\n",
            "40/40 - 0s - loss: 3261.8926 - val_loss: 3162.7144 - 80ms/epoch - 2ms/step\n",
            "Epoch 105/1000\n",
            "40/40 - 0s - loss: 3274.1147 - val_loss: 3204.8115 - 79ms/epoch - 2ms/step\n",
            "Epoch 106/1000\n",
            "40/40 - 0s - loss: 3259.7798 - val_loss: 3185.9895 - 82ms/epoch - 2ms/step\n",
            "Epoch 107/1000\n",
            "40/40 - 0s - loss: 3251.3252 - val_loss: 3156.0891 - 80ms/epoch - 2ms/step\n",
            "Epoch 108/1000\n",
            "40/40 - 0s - loss: 3250.1204 - val_loss: 3180.1284 - 82ms/epoch - 2ms/step\n",
            "Epoch 109/1000\n",
            "40/40 - 0s - loss: 3278.2444 - val_loss: 3191.2705 - 80ms/epoch - 2ms/step\n",
            "Epoch 110/1000\n",
            "40/40 - 0s - loss: 3278.0176 - val_loss: 3186.3911 - 79ms/epoch - 2ms/step\n",
            "Epoch 111/1000\n",
            "40/40 - 0s - loss: 3251.3640 - val_loss: 3135.5332 - 75ms/epoch - 2ms/step\n",
            "Epoch 112/1000\n",
            "40/40 - 0s - loss: 3210.8027 - val_loss: 3121.7690 - 76ms/epoch - 2ms/step\n",
            "Epoch 113/1000\n",
            "40/40 - 0s - loss: 3204.6577 - val_loss: 3110.7439 - 75ms/epoch - 2ms/step\n",
            "Epoch 114/1000\n",
            "40/40 - 0s - loss: 3179.9363 - val_loss: 3107.9417 - 75ms/epoch - 2ms/step\n",
            "Epoch 115/1000\n",
            "40/40 - 0s - loss: 3197.6296 - val_loss: 3107.6594 - 76ms/epoch - 2ms/step\n",
            "Epoch 116/1000\n",
            "40/40 - 0s - loss: 3187.7717 - val_loss: 3094.9470 - 76ms/epoch - 2ms/step\n",
            "Epoch 117/1000\n",
            "40/40 - 0s - loss: 3168.6682 - val_loss: 3095.9187 - 86ms/epoch - 2ms/step\n",
            "Epoch 118/1000\n",
            "40/40 - 0s - loss: 3167.7964 - val_loss: 3089.9800 - 78ms/epoch - 2ms/step\n",
            "Epoch 119/1000\n",
            "40/40 - 0s - loss: 3179.2749 - val_loss: 3092.9561 - 82ms/epoch - 2ms/step\n",
            "Epoch 120/1000\n",
            "40/40 - 0s - loss: 3157.1458 - val_loss: 3079.1365 - 73ms/epoch - 2ms/step\n",
            "Epoch 121/1000\n",
            "40/40 - 0s - loss: 3150.7229 - val_loss: 3056.0334 - 76ms/epoch - 2ms/step\n",
            "Epoch 122/1000\n",
            "40/40 - 0s - loss: 3145.8252 - val_loss: 3072.7993 - 81ms/epoch - 2ms/step\n",
            "Epoch 123/1000\n",
            "40/40 - 0s - loss: 3155.3857 - val_loss: 3023.6411 - 72ms/epoch - 2ms/step\n",
            "Epoch 124/1000\n",
            "40/40 - 0s - loss: 3120.6235 - val_loss: 3040.9722 - 70ms/epoch - 2ms/step\n",
            "Epoch 125/1000\n",
            "40/40 - 0s - loss: 3123.0620 - val_loss: 3030.7214 - 80ms/epoch - 2ms/step\n",
            "Epoch 126/1000\n",
            "40/40 - 0s - loss: 3112.9868 - val_loss: 2998.3413 - 77ms/epoch - 2ms/step\n",
            "Epoch 127/1000\n",
            "40/40 - 0s - loss: 3083.9851 - val_loss: 2996.2803 - 82ms/epoch - 2ms/step\n",
            "Epoch 128/1000\n",
            "40/40 - 0s - loss: 3081.7288 - val_loss: 2977.9692 - 89ms/epoch - 2ms/step\n",
            "Epoch 129/1000\n",
            "40/40 - 0s - loss: 3085.7104 - val_loss: 3000.5190 - 80ms/epoch - 2ms/step\n",
            "Epoch 130/1000\n",
            "40/40 - 0s - loss: 3087.9290 - val_loss: 2997.6296 - 75ms/epoch - 2ms/step\n",
            "Epoch 131/1000\n",
            "40/40 - 0s - loss: 3100.0962 - val_loss: 2987.5862 - 77ms/epoch - 2ms/step\n",
            "Epoch 132/1000\n",
            "40/40 - 0s - loss: 3091.2881 - val_loss: 3071.6907 - 77ms/epoch - 2ms/step\n",
            "Epoch 133/1000\n",
            "40/40 - 0s - loss: 3121.7698 - val_loss: 3039.0801 - 80ms/epoch - 2ms/step\n",
            "Epoch 134/1000\n",
            "40/40 - 0s - loss: 3105.5815 - val_loss: 2986.6860 - 84ms/epoch - 2ms/step\n",
            "Epoch 135/1000\n",
            "40/40 - 0s - loss: 3068.9500 - val_loss: 2980.6733 - 81ms/epoch - 2ms/step\n",
            "Epoch 136/1000\n",
            "40/40 - 0s - loss: 3061.8525 - val_loss: 2947.8030 - 81ms/epoch - 2ms/step\n",
            "Epoch 137/1000\n",
            "40/40 - 0s - loss: 3051.5688 - val_loss: 3013.3545 - 71ms/epoch - 2ms/step\n",
            "Epoch 138/1000\n",
            "40/40 - 0s - loss: 3051.8894 - val_loss: 2963.4814 - 79ms/epoch - 2ms/step\n",
            "Epoch 139/1000\n",
            "40/40 - 0s - loss: 3060.0930 - val_loss: 2957.7988 - 73ms/epoch - 2ms/step\n",
            "Epoch 140/1000\n",
            "40/40 - 0s - loss: 3023.2808 - val_loss: 2925.6221 - 71ms/epoch - 2ms/step\n",
            "Epoch 141/1000\n",
            "40/40 - 0s - loss: 3018.4365 - val_loss: 2955.4854 - 81ms/epoch - 2ms/step\n",
            "Epoch 142/1000\n",
            "40/40 - 0s - loss: 3007.2285 - val_loss: 2932.9976 - 73ms/epoch - 2ms/step\n",
            "Epoch 143/1000\n",
            "40/40 - 0s - loss: 3012.4368 - val_loss: 2937.8806 - 79ms/epoch - 2ms/step\n",
            "Epoch 144/1000\n",
            "40/40 - 0s - loss: 3004.4248 - val_loss: 2897.9697 - 78ms/epoch - 2ms/step\n",
            "Epoch 145/1000\n",
            "40/40 - 0s - loss: 2992.7329 - val_loss: 2915.1738 - 73ms/epoch - 2ms/step\n",
            "Epoch 146/1000\n",
            "40/40 - 0s - loss: 2997.7686 - val_loss: 2934.0903 - 76ms/epoch - 2ms/step\n",
            "Epoch 147/1000\n",
            "40/40 - 0s - loss: 2974.7798 - val_loss: 2868.5254 - 78ms/epoch - 2ms/step\n",
            "Epoch 148/1000\n",
            "40/40 - 0s - loss: 2964.3611 - val_loss: 2922.1848 - 72ms/epoch - 2ms/step\n",
            "Epoch 149/1000\n",
            "40/40 - 0s - loss: 2961.2410 - val_loss: 2860.6667 - 74ms/epoch - 2ms/step\n",
            "Epoch 150/1000\n",
            "40/40 - 0s - loss: 2950.6838 - val_loss: 2888.4409 - 75ms/epoch - 2ms/step\n",
            "Epoch 151/1000\n",
            "40/40 - 0s - loss: 2941.9250 - val_loss: 2859.0732 - 75ms/epoch - 2ms/step\n",
            "Epoch 152/1000\n",
            "40/40 - 0s - loss: 2947.2920 - val_loss: 2858.2490 - 81ms/epoch - 2ms/step\n",
            "Epoch 153/1000\n",
            "40/40 - 0s - loss: 2947.3840 - val_loss: 2882.6875 - 74ms/epoch - 2ms/step\n",
            "Epoch 154/1000\n",
            "40/40 - 0s - loss: 2954.5586 - val_loss: 2874.8977 - 76ms/epoch - 2ms/step\n",
            "Epoch 155/1000\n",
            "40/40 - 0s - loss: 2959.8301 - val_loss: 2842.6511 - 74ms/epoch - 2ms/step\n",
            "Epoch 156/1000\n",
            "40/40 - 0s - loss: 2951.4863 - val_loss: 2840.7273 - 81ms/epoch - 2ms/step\n",
            "Epoch 157/1000\n",
            "40/40 - 0s - loss: 2916.7473 - val_loss: 2813.4998 - 74ms/epoch - 2ms/step\n",
            "Epoch 158/1000\n",
            "40/40 - 0s - loss: 2897.2068 - val_loss: 2801.4976 - 112ms/epoch - 3ms/step\n",
            "Epoch 159/1000\n",
            "40/40 - 0s - loss: 2917.9224 - val_loss: 2840.7048 - 94ms/epoch - 2ms/step\n",
            "Epoch 160/1000\n",
            "40/40 - 0s - loss: 2917.8489 - val_loss: 2844.5266 - 88ms/epoch - 2ms/step\n",
            "Epoch 161/1000\n",
            "40/40 - 0s - loss: 2925.7119 - val_loss: 2812.0735 - 86ms/epoch - 2ms/step\n",
            "Epoch 162/1000\n",
            "40/40 - 0s - loss: 2916.7004 - val_loss: 2829.1162 - 82ms/epoch - 2ms/step\n",
            "Epoch 163/1000\n",
            "40/40 - 0s - loss: 2882.8464 - val_loss: 2796.8284 - 74ms/epoch - 2ms/step\n",
            "Epoch 164/1000\n",
            "40/40 - 0s - loss: 2870.1921 - val_loss: 2863.3459 - 97ms/epoch - 2ms/step\n",
            "Epoch 165/1000\n",
            "40/40 - 0s - loss: 2881.7363 - val_loss: 2784.7605 - 76ms/epoch - 2ms/step\n",
            "Epoch 166/1000\n",
            "40/40 - 0s - loss: 2882.1338 - val_loss: 2806.4712 - 81ms/epoch - 2ms/step\n",
            "Epoch 167/1000\n",
            "40/40 - 0s - loss: 2892.3242 - val_loss: 2796.6836 - 85ms/epoch - 2ms/step\n",
            "Epoch 168/1000\n",
            "40/40 - 0s - loss: 2874.1667 - val_loss: 2832.2654 - 74ms/epoch - 2ms/step\n",
            "Epoch 169/1000\n",
            "40/40 - 0s - loss: 2877.5635 - val_loss: 2808.8423 - 71ms/epoch - 2ms/step\n",
            "Epoch 170/1000\n",
            "40/40 - 0s - loss: 2868.8372 - val_loss: 2778.1416 - 80ms/epoch - 2ms/step\n",
            "Epoch 171/1000\n",
            "40/40 - 0s - loss: 2870.5542 - val_loss: 2792.2898 - 80ms/epoch - 2ms/step\n",
            "Epoch 172/1000\n",
            "40/40 - 0s - loss: 2843.4270 - val_loss: 2754.9243 - 73ms/epoch - 2ms/step\n",
            "Epoch 173/1000\n",
            "40/40 - 0s - loss: 2834.1304 - val_loss: 2748.0771 - 73ms/epoch - 2ms/step\n",
            "Epoch 174/1000\n",
            "40/40 - 0s - loss: 2833.2708 - val_loss: 2755.0481 - 78ms/epoch - 2ms/step\n",
            "Epoch 175/1000\n",
            "40/40 - 0s - loss: 2828.9934 - val_loss: 2800.1924 - 77ms/epoch - 2ms/step\n",
            "Epoch 176/1000\n",
            "40/40 - 0s - loss: 2836.7068 - val_loss: 2730.9395 - 74ms/epoch - 2ms/step\n",
            "Epoch 177/1000\n",
            "40/40 - 0s - loss: 2837.6558 - val_loss: 2767.6675 - 79ms/epoch - 2ms/step\n",
            "Epoch 178/1000\n",
            "40/40 - 0s - loss: 2844.0039 - val_loss: 2739.2625 - 74ms/epoch - 2ms/step\n",
            "Epoch 179/1000\n",
            "40/40 - 0s - loss: 2815.9988 - val_loss: 2779.1167 - 75ms/epoch - 2ms/step\n",
            "Epoch 180/1000\n",
            "40/40 - 0s - loss: 2838.3481 - val_loss: 2731.1755 - 79ms/epoch - 2ms/step\n",
            "Epoch 181/1000\n",
            "40/40 - 0s - loss: 2838.1216 - val_loss: 2743.4106 - 79ms/epoch - 2ms/step\n",
            "Epoch 182/1000\n",
            "40/40 - 0s - loss: 2832.8245 - val_loss: 2726.1123 - 78ms/epoch - 2ms/step\n",
            "Epoch 183/1000\n",
            "40/40 - 0s - loss: 2811.1987 - val_loss: 2740.1743 - 93ms/epoch - 2ms/step\n",
            "Epoch 184/1000\n",
            "40/40 - 0s - loss: 2805.1040 - val_loss: 2733.9080 - 73ms/epoch - 2ms/step\n",
            "Epoch 185/1000\n",
            "40/40 - 0s - loss: 2813.0210 - val_loss: 2689.3059 - 76ms/epoch - 2ms/step\n",
            "Epoch 186/1000\n",
            "40/40 - 0s - loss: 2801.5508 - val_loss: 2716.1565 - 83ms/epoch - 2ms/step\n",
            "Epoch 187/1000\n",
            "40/40 - 0s - loss: 2815.0718 - val_loss: 2733.3093 - 73ms/epoch - 2ms/step\n",
            "Epoch 188/1000\n",
            "40/40 - 0s - loss: 2806.7700 - val_loss: 2698.2190 - 82ms/epoch - 2ms/step\n",
            "Epoch 189/1000\n",
            "40/40 - 0s - loss: 2816.1208 - val_loss: 2688.3484 - 76ms/epoch - 2ms/step\n",
            "Epoch 190/1000\n",
            "40/40 - 0s - loss: 2798.1619 - val_loss: 2682.6362 - 75ms/epoch - 2ms/step\n",
            "Epoch 191/1000\n",
            "40/40 - 0s - loss: 2771.8604 - val_loss: 2654.7717 - 75ms/epoch - 2ms/step\n",
            "Epoch 192/1000\n",
            "40/40 - 0s - loss: 2750.0974 - val_loss: 2693.1055 - 77ms/epoch - 2ms/step\n",
            "Epoch 193/1000\n",
            "40/40 - 0s - loss: 2768.0466 - val_loss: 2719.5071 - 75ms/epoch - 2ms/step\n",
            "Epoch 194/1000\n",
            "40/40 - 0s - loss: 2805.4270 - val_loss: 2733.5967 - 73ms/epoch - 2ms/step\n",
            "Epoch 195/1000\n",
            "40/40 - 0s - loss: 2814.7742 - val_loss: 2732.6003 - 75ms/epoch - 2ms/step\n",
            "Epoch 196/1000\n",
            "40/40 - 0s - loss: 2795.1538 - val_loss: 2680.7009 - 79ms/epoch - 2ms/step\n",
            "Epoch 197/1000\n",
            "40/40 - 0s - loss: 2756.0535 - val_loss: 2653.9172 - 72ms/epoch - 2ms/step\n",
            "Epoch 198/1000\n",
            "40/40 - 0s - loss: 2744.6719 - val_loss: 2655.1526 - 74ms/epoch - 2ms/step\n",
            "Epoch 199/1000\n",
            "40/40 - 0s - loss: 2744.4500 - val_loss: 2683.8694 - 74ms/epoch - 2ms/step\n",
            "Epoch 200/1000\n",
            "40/40 - 0s - loss: 2752.0266 - val_loss: 2701.9827 - 77ms/epoch - 2ms/step\n",
            "Epoch 201/1000\n",
            "40/40 - 0s - loss: 2750.8997 - val_loss: 2631.7905 - 73ms/epoch - 2ms/step\n",
            "Epoch 202/1000\n",
            "40/40 - 0s - loss: 2755.7539 - val_loss: 2719.9460 - 72ms/epoch - 2ms/step\n",
            "Epoch 203/1000\n",
            "40/40 - 0s - loss: 2748.4380 - val_loss: 2704.0320 - 79ms/epoch - 2ms/step\n",
            "Epoch 204/1000\n",
            "40/40 - 0s - loss: 2747.4294 - val_loss: 2621.9272 - 79ms/epoch - 2ms/step\n",
            "Epoch 205/1000\n",
            "40/40 - 0s - loss: 2735.1946 - val_loss: 2654.5984 - 76ms/epoch - 2ms/step\n",
            "Epoch 206/1000\n",
            "40/40 - 0s - loss: 2728.0459 - val_loss: 2647.5862 - 71ms/epoch - 2ms/step\n",
            "Epoch 207/1000\n",
            "40/40 - 0s - loss: 2727.8752 - val_loss: 2637.8137 - 81ms/epoch - 2ms/step\n",
            "Epoch 208/1000\n",
            "40/40 - 0s - loss: 2716.4675 - val_loss: 2668.4268 - 71ms/epoch - 2ms/step\n",
            "Epoch 209/1000\n",
            "40/40 - 0s - loss: 2724.6313 - val_loss: 2603.8440 - 79ms/epoch - 2ms/step\n",
            "Epoch 210/1000\n",
            "40/40 - 0s - loss: 2712.0315 - val_loss: 2703.1404 - 78ms/epoch - 2ms/step\n",
            "Epoch 211/1000\n",
            "40/40 - 0s - loss: 2729.6978 - val_loss: 2660.5730 - 75ms/epoch - 2ms/step\n",
            "Epoch 212/1000\n",
            "40/40 - 0s - loss: 2717.9421 - val_loss: 2615.2939 - 76ms/epoch - 2ms/step\n",
            "Epoch 213/1000\n",
            "40/40 - 0s - loss: 2719.6165 - val_loss: 2615.3591 - 81ms/epoch - 2ms/step\n",
            "Epoch 214/1000\n",
            "40/40 - 0s - loss: 2697.2866 - val_loss: 2632.2131 - 79ms/epoch - 2ms/step\n",
            "Epoch 215/1000\n",
            "40/40 - 0s - loss: 2725.7649 - val_loss: 2599.7681 - 83ms/epoch - 2ms/step\n",
            "Epoch 216/1000\n",
            "40/40 - 0s - loss: 2718.7554 - val_loss: 2636.2859 - 85ms/epoch - 2ms/step\n",
            "Epoch 217/1000\n",
            "40/40 - 0s - loss: 2721.7598 - val_loss: 2673.1506 - 80ms/epoch - 2ms/step\n",
            "Epoch 218/1000\n",
            "40/40 - 0s - loss: 2709.7031 - val_loss: 2588.8103 - 78ms/epoch - 2ms/step\n",
            "Epoch 219/1000\n",
            "40/40 - 0s - loss: 2669.8652 - val_loss: 2598.4109 - 81ms/epoch - 2ms/step\n",
            "Epoch 220/1000\n",
            "40/40 - 0s - loss: 2687.4172 - val_loss: 2616.8159 - 89ms/epoch - 2ms/step\n",
            "Epoch 221/1000\n",
            "40/40 - 0s - loss: 2676.8035 - val_loss: 2595.5603 - 79ms/epoch - 2ms/step\n",
            "Epoch 222/1000\n",
            "40/40 - 0s - loss: 2683.9822 - val_loss: 2594.9976 - 80ms/epoch - 2ms/step\n",
            "Epoch 223/1000\n",
            "40/40 - 0s - loss: 2676.9277 - val_loss: 2616.7141 - 91ms/epoch - 2ms/step\n",
            "Epoch 224/1000\n",
            "40/40 - 0s - loss: 2681.1072 - val_loss: 2581.5359 - 76ms/epoch - 2ms/step\n",
            "Epoch 225/1000\n",
            "40/40 - 0s - loss: 2671.8555 - val_loss: 2585.5195 - 74ms/epoch - 2ms/step\n",
            "Epoch 226/1000\n",
            "40/40 - 0s - loss: 2668.8374 - val_loss: 2573.7498 - 84ms/epoch - 2ms/step\n",
            "Epoch 227/1000\n",
            "40/40 - 0s - loss: 2679.2080 - val_loss: 2572.4766 - 83ms/epoch - 2ms/step\n",
            "Epoch 228/1000\n",
            "40/40 - 0s - loss: 2664.4316 - val_loss: 2621.8513 - 77ms/epoch - 2ms/step\n",
            "Epoch 229/1000\n",
            "40/40 - 0s - loss: 2699.2334 - val_loss: 2593.5657 - 74ms/epoch - 2ms/step\n",
            "Epoch 230/1000\n",
            "40/40 - 0s - loss: 2669.0286 - val_loss: 2602.6841 - 76ms/epoch - 2ms/step\n",
            "Epoch 231/1000\n",
            "40/40 - 0s - loss: 2664.7593 - val_loss: 2583.5005 - 75ms/epoch - 2ms/step\n",
            "Epoch 232/1000\n",
            "40/40 - 0s - loss: 2652.9460 - val_loss: 2578.9631 - 80ms/epoch - 2ms/step\n",
            "Epoch 233/1000\n",
            "40/40 - 0s - loss: 2650.0371 - val_loss: 2545.0818 - 82ms/epoch - 2ms/step\n",
            "Epoch 234/1000\n",
            "40/40 - 0s - loss: 2655.7407 - val_loss: 2583.1294 - 76ms/epoch - 2ms/step\n",
            "Epoch 235/1000\n",
            "40/40 - 0s - loss: 2645.2986 - val_loss: 2544.8179 - 77ms/epoch - 2ms/step\n",
            "Epoch 236/1000\n",
            "40/40 - 0s - loss: 2636.9224 - val_loss: 2504.3533 - 72ms/epoch - 2ms/step\n",
            "Epoch 237/1000\n",
            "40/40 - 0s - loss: 2617.9800 - val_loss: 2536.3340 - 69ms/epoch - 2ms/step\n",
            "Epoch 238/1000\n",
            "40/40 - 0s - loss: 2609.2070 - val_loss: 2541.1389 - 80ms/epoch - 2ms/step\n",
            "Epoch 239/1000\n",
            "40/40 - 0s - loss: 2620.9663 - val_loss: 2600.2449 - 76ms/epoch - 2ms/step\n",
            "Epoch 240/1000\n",
            "40/40 - 0s - loss: 2642.2209 - val_loss: 2564.7852 - 79ms/epoch - 2ms/step\n",
            "Epoch 241/1000\n",
            "40/40 - 0s - loss: 2627.9229 - val_loss: 2572.7373 - 75ms/epoch - 2ms/step\n",
            "Epoch 242/1000\n",
            "40/40 - 0s - loss: 2639.1448 - val_loss: 2596.5654 - 75ms/epoch - 2ms/step\n",
            "Epoch 243/1000\n",
            "40/40 - 0s - loss: 2633.8794 - val_loss: 2534.9995 - 76ms/epoch - 2ms/step\n",
            "Epoch 244/1000\n",
            "40/40 - 0s - loss: 2644.0950 - val_loss: 2547.2500 - 75ms/epoch - 2ms/step\n",
            "Epoch 245/1000\n",
            "40/40 - 0s - loss: 2623.2927 - val_loss: 2516.9705 - 76ms/epoch - 2ms/step\n",
            "Epoch 246/1000\n",
            "40/40 - 0s - loss: 2606.0562 - val_loss: 2554.8555 - 83ms/epoch - 2ms/step\n",
            "Epoch 247/1000\n",
            "40/40 - 0s - loss: 2626.4070 - val_loss: 2528.6372 - 79ms/epoch - 2ms/step\n",
            "Epoch 248/1000\n",
            "40/40 - 0s - loss: 2607.3252 - val_loss: 2522.2266 - 83ms/epoch - 2ms/step\n",
            "Epoch 249/1000\n",
            "40/40 - 0s - loss: 2589.1255 - val_loss: 2515.4756 - 79ms/epoch - 2ms/step\n",
            "Epoch 250/1000\n",
            "40/40 - 0s - loss: 2585.1692 - val_loss: 2515.2283 - 107ms/epoch - 3ms/step\n",
            "Epoch 251/1000\n",
            "40/40 - 0s - loss: 2596.4597 - val_loss: 2514.0020 - 87ms/epoch - 2ms/step\n",
            "Epoch 252/1000\n",
            "40/40 - 0s - loss: 2600.1697 - val_loss: 2507.7888 - 97ms/epoch - 2ms/step\n",
            "Epoch 253/1000\n",
            "40/40 - 0s - loss: 2576.4478 - val_loss: 2505.3926 - 87ms/epoch - 2ms/step\n",
            "Epoch 254/1000\n",
            "40/40 - 0s - loss: 2577.2590 - val_loss: 2502.1714 - 72ms/epoch - 2ms/step\n",
            "Epoch 255/1000\n",
            "40/40 - 0s - loss: 2578.6948 - val_loss: 2519.3591 - 71ms/epoch - 2ms/step\n",
            "Epoch 256/1000\n",
            "40/40 - 0s - loss: 2620.5540 - val_loss: 2568.1970 - 82ms/epoch - 2ms/step\n",
            "Epoch 257/1000\n",
            "40/40 - 0s - loss: 2587.0508 - val_loss: 2523.6221 - 94ms/epoch - 2ms/step\n",
            "Epoch 258/1000\n",
            "40/40 - 0s - loss: 2596.3362 - val_loss: 2471.0813 - 107ms/epoch - 3ms/step\n",
            "Epoch 259/1000\n",
            "40/40 - 0s - loss: 2602.2900 - val_loss: 2512.9844 - 88ms/epoch - 2ms/step\n",
            "Epoch 260/1000\n",
            "40/40 - 0s - loss: 2595.3337 - val_loss: 2553.1516 - 135ms/epoch - 3ms/step\n",
            "Epoch 261/1000\n",
            "40/40 - 0s - loss: 2597.4326 - val_loss: 2491.5183 - 106ms/epoch - 3ms/step\n",
            "Epoch 262/1000\n",
            "40/40 - 0s - loss: 2620.7585 - val_loss: 2557.8167 - 90ms/epoch - 2ms/step\n",
            "Epoch 263/1000\n",
            "40/40 - 0s - loss: 2611.8623 - val_loss: 2562.1667 - 90ms/epoch - 2ms/step\n",
            "Epoch 264/1000\n",
            "40/40 - 0s - loss: 2586.1514 - val_loss: 2481.8027 - 94ms/epoch - 2ms/step\n",
            "Epoch 265/1000\n",
            "40/40 - 0s - loss: 2558.5366 - val_loss: 2461.5408 - 83ms/epoch - 2ms/step\n",
            "Epoch 266/1000\n",
            "40/40 - 0s - loss: 2578.9629 - val_loss: 2457.7661 - 85ms/epoch - 2ms/step\n",
            "Epoch 267/1000\n",
            "40/40 - 0s - loss: 2543.2690 - val_loss: 2457.5715 - 88ms/epoch - 2ms/step\n",
            "Epoch 268/1000\n",
            "40/40 - 0s - loss: 2553.1887 - val_loss: 2436.3513 - 100ms/epoch - 2ms/step\n",
            "Epoch 269/1000\n",
            "40/40 - 0s - loss: 2529.7993 - val_loss: 2434.4314 - 113ms/epoch - 3ms/step\n",
            "Epoch 270/1000\n",
            "40/40 - 0s - loss: 2535.9128 - val_loss: 2443.1396 - 111ms/epoch - 3ms/step\n",
            "Epoch 271/1000\n",
            "40/40 - 0s - loss: 2537.6436 - val_loss: 2453.1692 - 83ms/epoch - 2ms/step\n",
            "Epoch 272/1000\n",
            "40/40 - 0s - loss: 2533.5857 - val_loss: 2443.8542 - 77ms/epoch - 2ms/step\n",
            "Epoch 273/1000\n",
            "40/40 - 0s - loss: 2520.7439 - val_loss: 2481.7212 - 88ms/epoch - 2ms/step\n",
            "Epoch 274/1000\n",
            "40/40 - 0s - loss: 2548.1877 - val_loss: 2472.0959 - 83ms/epoch - 2ms/step\n",
            "Epoch 275/1000\n",
            "40/40 - 0s - loss: 2573.2769 - val_loss: 2495.5337 - 83ms/epoch - 2ms/step\n",
            "Epoch 276/1000\n",
            "40/40 - 0s - loss: 2565.4722 - val_loss: 2458.2761 - 86ms/epoch - 2ms/step\n",
            "Epoch 277/1000\n",
            "40/40 - 0s - loss: 2544.0847 - val_loss: 2501.1392 - 75ms/epoch - 2ms/step\n",
            "Epoch 278/1000\n",
            "40/40 - 0s - loss: 2557.9741 - val_loss: 2463.3801 - 85ms/epoch - 2ms/step\n",
            "Epoch 279/1000\n",
            "40/40 - 0s - loss: 2559.8745 - val_loss: 2466.0183 - 94ms/epoch - 2ms/step\n",
            "Epoch 280/1000\n",
            "40/40 - 0s - loss: 2530.0754 - val_loss: 2439.4480 - 86ms/epoch - 2ms/step\n",
            "Epoch 281/1000\n",
            "40/40 - 0s - loss: 2512.1606 - val_loss: 2454.8010 - 87ms/epoch - 2ms/step\n",
            "Epoch 282/1000\n",
            "40/40 - 0s - loss: 2529.3796 - val_loss: 2482.3845 - 81ms/epoch - 2ms/step\n",
            "Epoch 283/1000\n",
            "40/40 - 0s - loss: 2523.3140 - val_loss: 2466.8579 - 82ms/epoch - 2ms/step\n",
            "Epoch 284/1000\n",
            "40/40 - 0s - loss: 2519.2544 - val_loss: 2422.6731 - 78ms/epoch - 2ms/step\n",
            "Epoch 285/1000\n",
            "40/40 - 0s - loss: 2516.3372 - val_loss: 2428.2993 - 76ms/epoch - 2ms/step\n",
            "Epoch 286/1000\n",
            "40/40 - 0s - loss: 2518.6572 - val_loss: 2429.8862 - 84ms/epoch - 2ms/step\n",
            "Epoch 287/1000\n",
            "40/40 - 0s - loss: 2524.3997 - val_loss: 2462.0286 - 78ms/epoch - 2ms/step\n",
            "Epoch 288/1000\n",
            "40/40 - 0s - loss: 2536.1162 - val_loss: 2515.1931 - 79ms/epoch - 2ms/step\n",
            "Epoch 289/1000\n",
            "40/40 - 0s - loss: 2560.9578 - val_loss: 2520.9905 - 72ms/epoch - 2ms/step\n",
            "Epoch 290/1000\n",
            "40/40 - 0s - loss: 2567.4036 - val_loss: 2485.1790 - 79ms/epoch - 2ms/step\n",
            "Epoch 291/1000\n",
            "40/40 - 0s - loss: 2532.2434 - val_loss: 2468.2273 - 71ms/epoch - 2ms/step\n",
            "Epoch 292/1000\n",
            "40/40 - 0s - loss: 2532.7637 - val_loss: 2432.6772 - 82ms/epoch - 2ms/step\n",
            "Epoch 293/1000\n",
            "40/40 - 0s - loss: 2545.1033 - val_loss: 2459.7920 - 79ms/epoch - 2ms/step\n",
            "Epoch 294/1000\n",
            "40/40 - 0s - loss: 2543.3447 - val_loss: 2469.3865 - 83ms/epoch - 2ms/step\n",
            "Epoch 295/1000\n",
            "40/40 - 0s - loss: 2548.8728 - val_loss: 2478.5696 - 86ms/epoch - 2ms/step\n",
            "Epoch 296/1000\n",
            "40/40 - 0s - loss: 2530.4685 - val_loss: 2446.3452 - 88ms/epoch - 2ms/step\n",
            "Epoch 297/1000\n",
            "40/40 - 0s - loss: 2490.4961 - val_loss: 2422.5647 - 77ms/epoch - 2ms/step\n",
            "Epoch 298/1000\n",
            "40/40 - 0s - loss: 2506.1414 - val_loss: 2430.4446 - 75ms/epoch - 2ms/step\n",
            "Epoch 299/1000\n",
            "40/40 - 0s - loss: 2493.9270 - val_loss: 2429.5737 - 82ms/epoch - 2ms/step\n",
            "Epoch 300/1000\n",
            "40/40 - 0s - loss: 2482.3567 - val_loss: 2436.2031 - 77ms/epoch - 2ms/step\n",
            "Epoch 301/1000\n",
            "40/40 - 0s - loss: 2482.8254 - val_loss: 2387.8545 - 75ms/epoch - 2ms/step\n",
            "Epoch 302/1000\n",
            "40/40 - 0s - loss: 2504.8325 - val_loss: 2415.7534 - 80ms/epoch - 2ms/step\n",
            "Epoch 303/1000\n",
            "40/40 - 0s - loss: 2495.6067 - val_loss: 2390.3848 - 74ms/epoch - 2ms/step\n",
            "Epoch 304/1000\n",
            "40/40 - 0s - loss: 2490.4695 - val_loss: 2426.9683 - 81ms/epoch - 2ms/step\n",
            "Epoch 305/1000\n",
            "40/40 - 0s - loss: 2509.6990 - val_loss: 2428.5771 - 95ms/epoch - 2ms/step\n",
            "Epoch 306/1000\n",
            "40/40 - 0s - loss: 2524.1707 - val_loss: 2400.6726 - 89ms/epoch - 2ms/step\n",
            "Epoch 307/1000\n",
            "40/40 - 0s - loss: 2498.1318 - val_loss: 2422.6841 - 118ms/epoch - 3ms/step\n",
            "Epoch 308/1000\n",
            "40/40 - 0s - loss: 2482.2598 - val_loss: 2385.2864 - 100ms/epoch - 2ms/step\n",
            "Epoch 309/1000\n",
            "40/40 - 0s - loss: 2471.2751 - val_loss: 2412.5178 - 79ms/epoch - 2ms/step\n",
            "Epoch 310/1000\n",
            "40/40 - 0s - loss: 2468.3125 - val_loss: 2399.6084 - 81ms/epoch - 2ms/step\n",
            "Epoch 311/1000\n",
            "40/40 - 0s - loss: 2509.3777 - val_loss: 2456.0032 - 100ms/epoch - 3ms/step\n",
            "Epoch 312/1000\n",
            "40/40 - 0s - loss: 2495.5710 - val_loss: 2434.6689 - 83ms/epoch - 2ms/step\n",
            "Epoch 313/1000\n",
            "40/40 - 0s - loss: 2486.0105 - val_loss: 2372.3147 - 75ms/epoch - 2ms/step\n",
            "Epoch 314/1000\n",
            "40/40 - 0s - loss: 2458.0427 - val_loss: 2385.1660 - 92ms/epoch - 2ms/step\n",
            "Epoch 315/1000\n",
            "40/40 - 0s - loss: 2471.0283 - val_loss: 2402.7969 - 95ms/epoch - 2ms/step\n",
            "Epoch 316/1000\n",
            "40/40 - 0s - loss: 2482.3276 - val_loss: 2381.6248 - 85ms/epoch - 2ms/step\n",
            "Epoch 317/1000\n",
            "40/40 - 0s - loss: 2465.3013 - val_loss: 2364.3091 - 75ms/epoch - 2ms/step\n",
            "Epoch 318/1000\n",
            "40/40 - 0s - loss: 2452.2195 - val_loss: 2375.7817 - 85ms/epoch - 2ms/step\n",
            "Epoch 319/1000\n",
            "40/40 - 0s - loss: 2440.3623 - val_loss: 2343.4258 - 87ms/epoch - 2ms/step\n",
            "Epoch 320/1000\n",
            "40/40 - 0s - loss: 2441.7507 - val_loss: 2381.0530 - 72ms/epoch - 2ms/step\n",
            "Epoch 321/1000\n",
            "40/40 - 0s - loss: 2472.8582 - val_loss: 2420.3911 - 79ms/epoch - 2ms/step\n",
            "Epoch 322/1000\n",
            "40/40 - 0s - loss: 2478.2759 - val_loss: 2424.5012 - 94ms/epoch - 2ms/step\n",
            "Epoch 323/1000\n",
            "40/40 - 0s - loss: 2479.7173 - val_loss: 2374.7202 - 71ms/epoch - 2ms/step\n",
            "Epoch 324/1000\n",
            "40/40 - 0s - loss: 2441.3530 - val_loss: 2353.3000 - 83ms/epoch - 2ms/step\n",
            "Epoch 325/1000\n",
            "40/40 - 0s - loss: 2435.4495 - val_loss: 2366.8191 - 83ms/epoch - 2ms/step\n",
            "Epoch 326/1000\n",
            "40/40 - 0s - loss: 2449.7676 - val_loss: 2359.1143 - 76ms/epoch - 2ms/step\n",
            "Epoch 327/1000\n",
            "40/40 - 0s - loss: 2433.2932 - val_loss: 2337.6313 - 84ms/epoch - 2ms/step\n",
            "Epoch 328/1000\n",
            "40/40 - 0s - loss: 2427.0095 - val_loss: 2352.5166 - 82ms/epoch - 2ms/step\n",
            "Epoch 329/1000\n",
            "40/40 - 0s - loss: 2445.4468 - val_loss: 2429.4167 - 75ms/epoch - 2ms/step\n",
            "Epoch 330/1000\n",
            "40/40 - 0s - loss: 2481.7466 - val_loss: 2398.1870 - 75ms/epoch - 2ms/step\n",
            "Epoch 331/1000\n",
            "40/40 - 0s - loss: 2455.6709 - val_loss: 2399.9023 - 75ms/epoch - 2ms/step\n",
            "Epoch 332/1000\n",
            "40/40 - 0s - loss: 2469.1382 - val_loss: 2392.2859 - 84ms/epoch - 2ms/step\n",
            "Epoch 333/1000\n",
            "40/40 - 0s - loss: 2457.5930 - val_loss: 2357.3833 - 82ms/epoch - 2ms/step\n",
            "Epoch 334/1000\n",
            "40/40 - 0s - loss: 2463.2500 - val_loss: 2357.3303 - 83ms/epoch - 2ms/step\n",
            "Epoch 335/1000\n",
            "40/40 - 0s - loss: 2468.2329 - val_loss: 2414.2729 - 83ms/epoch - 2ms/step\n",
            "Epoch 336/1000\n",
            "40/40 - 0s - loss: 2478.0447 - val_loss: 2391.7029 - 73ms/epoch - 2ms/step\n",
            "Epoch 337/1000\n",
            "40/40 - 0s - loss: 2454.5808 - val_loss: 2366.7146 - 89ms/epoch - 2ms/step\n",
            "Epoch 338/1000\n",
            "40/40 - 0s - loss: 2433.0281 - val_loss: 2365.2881 - 89ms/epoch - 2ms/step\n",
            "Epoch 339/1000\n",
            "40/40 - 0s - loss: 2434.9390 - val_loss: 2358.6548 - 75ms/epoch - 2ms/step\n",
            "Epoch 340/1000\n",
            "40/40 - 0s - loss: 2428.9309 - val_loss: 2341.4226 - 78ms/epoch - 2ms/step\n",
            "Epoch 341/1000\n",
            "40/40 - 0s - loss: 2426.3491 - val_loss: 2369.3679 - 75ms/epoch - 2ms/step\n",
            "Epoch 342/1000\n",
            "40/40 - 0s - loss: 2455.8491 - val_loss: 2361.0461 - 85ms/epoch - 2ms/step\n",
            "Epoch 343/1000\n",
            "40/40 - 0s - loss: 2432.7778 - val_loss: 2314.4377 - 72ms/epoch - 2ms/step\n",
            "Epoch 344/1000\n",
            "40/40 - 0s - loss: 2446.1780 - val_loss: 2369.0942 - 73ms/epoch - 2ms/step\n",
            "Epoch 345/1000\n",
            "40/40 - 0s - loss: 2429.1677 - val_loss: 2349.4734 - 83ms/epoch - 2ms/step\n",
            "Epoch 346/1000\n",
            "40/40 - 0s - loss: 2446.1233 - val_loss: 2359.3623 - 99ms/epoch - 2ms/step\n",
            "Epoch 347/1000\n",
            "40/40 - 0s - loss: 2427.2197 - val_loss: 2359.9260 - 84ms/epoch - 2ms/step\n",
            "Epoch 348/1000\n",
            "40/40 - 0s - loss: 2420.9280 - val_loss: 2335.5205 - 79ms/epoch - 2ms/step\n",
            "Epoch 349/1000\n",
            "40/40 - 0s - loss: 2423.9292 - val_loss: 2360.2334 - 89ms/epoch - 2ms/step\n",
            "Epoch 350/1000\n",
            "40/40 - 0s - loss: 2439.6226 - val_loss: 2371.2864 - 83ms/epoch - 2ms/step\n",
            "Epoch 351/1000\n",
            "40/40 - 0s - loss: 2444.7898 - val_loss: 2327.1887 - 83ms/epoch - 2ms/step\n",
            "Epoch 352/1000\n",
            "40/40 - 0s - loss: 2449.6726 - val_loss: 2375.0315 - 91ms/epoch - 2ms/step\n",
            "Epoch 353/1000\n",
            "40/40 - 0s - loss: 2453.0059 - val_loss: 2369.1816 - 78ms/epoch - 2ms/step\n",
            "Epoch 354/1000\n",
            "40/40 - 0s - loss: 2446.4932 - val_loss: 2351.6538 - 98ms/epoch - 2ms/step\n",
            "Epoch 355/1000\n",
            "40/40 - 0s - loss: 2435.2976 - val_loss: 2347.1389 - 92ms/epoch - 2ms/step\n",
            "Epoch 356/1000\n",
            "40/40 - 0s - loss: 2419.1001 - val_loss: 2333.3918 - 85ms/epoch - 2ms/step\n",
            "Epoch 357/1000\n",
            "40/40 - 0s - loss: 2396.7585 - val_loss: 2327.3740 - 84ms/epoch - 2ms/step\n",
            "Epoch 358/1000\n",
            "40/40 - 0s - loss: 2407.0774 - val_loss: 2329.2253 - 97ms/epoch - 2ms/step\n",
            "Epoch 359/1000\n",
            "40/40 - 0s - loss: 2407.5659 - val_loss: 2310.7590 - 81ms/epoch - 2ms/step\n",
            "Epoch 360/1000\n",
            "40/40 - 0s - loss: 2404.3875 - val_loss: 2301.6204 - 86ms/epoch - 2ms/step\n",
            "Epoch 361/1000\n",
            "40/40 - 0s - loss: 2381.2627 - val_loss: 2293.3501 - 101ms/epoch - 3ms/step\n",
            "Epoch 362/1000\n",
            "40/40 - 0s - loss: 2399.3381 - val_loss: 2298.3953 - 86ms/epoch - 2ms/step\n",
            "Epoch 363/1000\n",
            "40/40 - 0s - loss: 2396.0400 - val_loss: 2341.6760 - 79ms/epoch - 2ms/step\n",
            "Epoch 364/1000\n",
            "40/40 - 0s - loss: 2446.5435 - val_loss: 2391.6255 - 83ms/epoch - 2ms/step\n",
            "Epoch 365/1000\n",
            "40/40 - 0s - loss: 2417.4126 - val_loss: 2303.8184 - 86ms/epoch - 2ms/step\n",
            "Epoch 366/1000\n",
            "40/40 - 0s - loss: 2405.0225 - val_loss: 2346.5479 - 81ms/epoch - 2ms/step\n",
            "Epoch 367/1000\n",
            "40/40 - 0s - loss: 2392.3342 - val_loss: 2321.5422 - 93ms/epoch - 2ms/step\n",
            "Epoch 368/1000\n",
            "40/40 - 0s - loss: 2417.4094 - val_loss: 2342.7156 - 85ms/epoch - 2ms/step\n",
            "Epoch 369/1000\n",
            "40/40 - 0s - loss: 2415.7295 - val_loss: 2339.0386 - 92ms/epoch - 2ms/step\n",
            "Epoch 370/1000\n",
            "40/40 - 0s - loss: 2406.8826 - val_loss: 2335.1187 - 80ms/epoch - 2ms/step\n",
            "Epoch 371/1000\n",
            "40/40 - 0s - loss: 2389.7322 - val_loss: 2352.3650 - 85ms/epoch - 2ms/step\n",
            "Epoch 372/1000\n",
            "40/40 - 0s - loss: 2409.2046 - val_loss: 2289.4319 - 92ms/epoch - 2ms/step\n",
            "Epoch 373/1000\n",
            "40/40 - 0s - loss: 2410.8745 - val_loss: 2347.1658 - 86ms/epoch - 2ms/step\n",
            "Epoch 374/1000\n",
            "40/40 - 0s - loss: 2403.8086 - val_loss: 2316.4587 - 84ms/epoch - 2ms/step\n",
            "Epoch 375/1000\n",
            "40/40 - 0s - loss: 2399.8782 - val_loss: 2321.0664 - 92ms/epoch - 2ms/step\n",
            "Epoch 376/1000\n",
            "40/40 - 0s - loss: 2385.3601 - val_loss: 2312.1660 - 78ms/epoch - 2ms/step\n",
            "Epoch 377/1000\n",
            "40/40 - 0s - loss: 2385.7903 - val_loss: 2286.1753 - 104ms/epoch - 3ms/step\n",
            "Epoch 378/1000\n",
            "40/40 - 0s - loss: 2387.6936 - val_loss: 2324.6992 - 80ms/epoch - 2ms/step\n",
            "Epoch 379/1000\n",
            "40/40 - 0s - loss: 2386.0303 - val_loss: 2268.0359 - 84ms/epoch - 2ms/step\n",
            "Epoch 380/1000\n",
            "40/40 - 0s - loss: 2373.7063 - val_loss: 2368.3667 - 81ms/epoch - 2ms/step\n",
            "Epoch 381/1000\n",
            "40/40 - 0s - loss: 2391.1121 - val_loss: 2309.2485 - 80ms/epoch - 2ms/step\n",
            "Epoch 382/1000\n",
            "40/40 - 0s - loss: 2391.4272 - val_loss: 2303.0903 - 86ms/epoch - 2ms/step\n",
            "Epoch 383/1000\n",
            "40/40 - 0s - loss: 2381.3433 - val_loss: 2330.2158 - 83ms/epoch - 2ms/step\n",
            "Epoch 384/1000\n",
            "40/40 - 0s - loss: 2417.2849 - val_loss: 2346.2927 - 90ms/epoch - 2ms/step\n",
            "Epoch 385/1000\n",
            "40/40 - 0s - loss: 2407.0554 - val_loss: 2287.9441 - 85ms/epoch - 2ms/step\n",
            "Epoch 386/1000\n",
            "40/40 - 0s - loss: 2371.3599 - val_loss: 2339.4045 - 85ms/epoch - 2ms/step\n",
            "Epoch 387/1000\n",
            "40/40 - 0s - loss: 2414.2969 - val_loss: 2311.3362 - 81ms/epoch - 2ms/step\n",
            "Epoch 388/1000\n",
            "40/40 - 0s - loss: 2407.6760 - val_loss: 2304.9709 - 84ms/epoch - 2ms/step\n",
            "Epoch 389/1000\n",
            "40/40 - 0s - loss: 2420.1880 - val_loss: 2355.6106 - 79ms/epoch - 2ms/step\n",
            "Epoch 390/1000\n",
            "40/40 - 0s - loss: 2404.6655 - val_loss: 2298.1606 - 79ms/epoch - 2ms/step\n",
            "Epoch 391/1000\n",
            "40/40 - 0s - loss: 2387.0566 - val_loss: 2300.4641 - 82ms/epoch - 2ms/step\n",
            "Epoch 392/1000\n",
            "40/40 - 0s - loss: 2354.5510 - val_loss: 2259.1108 - 79ms/epoch - 2ms/step\n",
            "Epoch 393/1000\n",
            "40/40 - 0s - loss: 2357.3323 - val_loss: 2326.2927 - 92ms/epoch - 2ms/step\n",
            "Epoch 394/1000\n",
            "40/40 - 0s - loss: 2372.7407 - val_loss: 2289.7427 - 85ms/epoch - 2ms/step\n",
            "Epoch 395/1000\n",
            "40/40 - 0s - loss: 2375.5554 - val_loss: 2296.2842 - 87ms/epoch - 2ms/step\n",
            "Epoch 396/1000\n",
            "40/40 - 0s - loss: 2372.0720 - val_loss: 2300.8157 - 91ms/epoch - 2ms/step\n",
            "Epoch 397/1000\n",
            "40/40 - 0s - loss: 2384.7061 - val_loss: 2342.4360 - 82ms/epoch - 2ms/step\n",
            "Epoch 398/1000\n",
            "40/40 - 0s - loss: 2398.9238 - val_loss: 2263.8977 - 84ms/epoch - 2ms/step\n",
            "Epoch 399/1000\n",
            "40/40 - 0s - loss: 2385.4592 - val_loss: 2288.5242 - 82ms/epoch - 2ms/step\n",
            "Epoch 400/1000\n",
            "40/40 - 0s - loss: 2355.7031 - val_loss: 2270.3643 - 96ms/epoch - 2ms/step\n",
            "Epoch 401/1000\n",
            "40/40 - 0s - loss: 2354.2954 - val_loss: 2283.8091 - 88ms/epoch - 2ms/step\n",
            "Epoch 402/1000\n",
            "40/40 - 0s - loss: 2344.6135 - val_loss: 2248.8665 - 81ms/epoch - 2ms/step\n",
            "Epoch 403/1000\n",
            "40/40 - 0s - loss: 2378.4277 - val_loss: 2287.5586 - 82ms/epoch - 2ms/step\n",
            "Epoch 404/1000\n",
            "40/40 - 0s - loss: 2357.6880 - val_loss: 2269.0249 - 86ms/epoch - 2ms/step\n",
            "Epoch 405/1000\n",
            "40/40 - 0s - loss: 2376.6626 - val_loss: 2330.7468 - 87ms/epoch - 2ms/step\n",
            "Epoch 406/1000\n",
            "40/40 - 0s - loss: 2382.5266 - val_loss: 2286.1646 - 83ms/epoch - 2ms/step\n",
            "Epoch 407/1000\n",
            "40/40 - 0s - loss: 2357.1733 - val_loss: 2242.3135 - 76ms/epoch - 2ms/step\n",
            "Epoch 408/1000\n",
            "40/40 - 0s - loss: 2356.7639 - val_loss: 2290.1609 - 87ms/epoch - 2ms/step\n",
            "Epoch 409/1000\n",
            "40/40 - 0s - loss: 2358.6763 - val_loss: 2242.9395 - 80ms/epoch - 2ms/step\n",
            "Epoch 410/1000\n",
            "40/40 - 0s - loss: 2365.9514 - val_loss: 2276.4351 - 84ms/epoch - 2ms/step\n",
            "Epoch 411/1000\n",
            "40/40 - 0s - loss: 2353.3218 - val_loss: 2336.1768 - 97ms/epoch - 2ms/step\n",
            "Epoch 412/1000\n",
            "40/40 - 0s - loss: 2393.9521 - val_loss: 2313.1790 - 84ms/epoch - 2ms/step\n",
            "Epoch 413/1000\n",
            "40/40 - 0s - loss: 2369.8511 - val_loss: 2303.8550 - 91ms/epoch - 2ms/step\n",
            "Epoch 414/1000\n",
            "40/40 - 0s - loss: 2384.3816 - val_loss: 2356.7126 - 91ms/epoch - 2ms/step\n",
            "Epoch 415/1000\n",
            "40/40 - 0s - loss: 2404.1890 - val_loss: 2262.4480 - 86ms/epoch - 2ms/step\n",
            "Epoch 416/1000\n",
            "40/40 - 0s - loss: 2392.5789 - val_loss: 2325.4431 - 99ms/epoch - 2ms/step\n",
            "Epoch 417/1000\n",
            "40/40 - 0s - loss: 2368.3979 - val_loss: 2261.9666 - 101ms/epoch - 3ms/step\n",
            "Epoch 418/1000\n",
            "40/40 - 0s - loss: 2339.9058 - val_loss: 2227.8223 - 86ms/epoch - 2ms/step\n",
            "Epoch 419/1000\n",
            "40/40 - 0s - loss: 2305.1335 - val_loss: 2235.0227 - 83ms/epoch - 2ms/step\n",
            "Epoch 420/1000\n",
            "40/40 - 0s - loss: 2318.0740 - val_loss: 2245.7585 - 85ms/epoch - 2ms/step\n",
            "Epoch 421/1000\n",
            "40/40 - 0s - loss: 2332.0295 - val_loss: 2271.9160 - 85ms/epoch - 2ms/step\n",
            "Epoch 422/1000\n",
            "40/40 - 0s - loss: 2338.6060 - val_loss: 2258.2649 - 87ms/epoch - 2ms/step\n",
            "Epoch 423/1000\n",
            "40/40 - 0s - loss: 2356.6829 - val_loss: 2253.1057 - 92ms/epoch - 2ms/step\n",
            "Epoch 424/1000\n",
            "40/40 - 0s - loss: 2359.2520 - val_loss: 2253.1904 - 74ms/epoch - 2ms/step\n",
            "Epoch 425/1000\n",
            "40/40 - 0s - loss: 2335.6206 - val_loss: 2258.9612 - 89ms/epoch - 2ms/step\n",
            "Epoch 426/1000\n",
            "40/40 - 0s - loss: 2320.8594 - val_loss: 2310.1946 - 89ms/epoch - 2ms/step\n",
            "Epoch 427/1000\n",
            "40/40 - 0s - loss: 2339.1860 - val_loss: 2232.3501 - 94ms/epoch - 2ms/step\n",
            "Epoch 428/1000\n",
            "40/40 - 0s - loss: 2362.2126 - val_loss: 2270.8501 - 84ms/epoch - 2ms/step\n",
            "Epoch 429/1000\n",
            "40/40 - 0s - loss: 2352.5137 - val_loss: 2247.6589 - 117ms/epoch - 3ms/step\n",
            "Epoch 430/1000\n",
            "40/40 - 0s - loss: 2327.8447 - val_loss: 2234.2756 - 95ms/epoch - 2ms/step\n",
            "Epoch 431/1000\n",
            "40/40 - 0s - loss: 2309.8691 - val_loss: 2270.1155 - 94ms/epoch - 2ms/step\n",
            "Epoch 432/1000\n",
            "40/40 - 0s - loss: 2366.5388 - val_loss: 2320.9377 - 95ms/epoch - 2ms/step\n",
            "Epoch 433/1000\n",
            "40/40 - 0s - loss: 2381.2942 - val_loss: 2304.0510 - 88ms/epoch - 2ms/step\n",
            "Epoch 434/1000\n",
            "40/40 - 0s - loss: 2385.9128 - val_loss: 2297.5432 - 103ms/epoch - 3ms/step\n",
            "Epoch 435/1000\n",
            "40/40 - 0s - loss: 2357.0774 - val_loss: 2239.2271 - 98ms/epoch - 2ms/step\n",
            "Epoch 436/1000\n",
            "40/40 - 0s - loss: 2330.1992 - val_loss: 2308.5591 - 87ms/epoch - 2ms/step\n",
            "Epoch 437/1000\n",
            "40/40 - 0s - loss: 2352.0303 - val_loss: 2249.0569 - 81ms/epoch - 2ms/step\n",
            "Epoch 438/1000\n",
            "40/40 - 0s - loss: 2314.1687 - val_loss: 2222.3484 - 84ms/epoch - 2ms/step\n",
            "Epoch 439/1000\n",
            "40/40 - 0s - loss: 2305.6125 - val_loss: 2193.8508 - 86ms/epoch - 2ms/step\n",
            "Epoch 440/1000\n",
            "40/40 - 0s - loss: 2283.3237 - val_loss: 2221.5522 - 75ms/epoch - 2ms/step\n",
            "Epoch 441/1000\n",
            "40/40 - 0s - loss: 2307.1912 - val_loss: 2224.1992 - 75ms/epoch - 2ms/step\n",
            "Epoch 442/1000\n",
            "40/40 - 0s - loss: 2304.4548 - val_loss: 2243.7798 - 100ms/epoch - 2ms/step\n",
            "Epoch 443/1000\n",
            "40/40 - 0s - loss: 2304.4741 - val_loss: 2233.0833 - 72ms/epoch - 2ms/step\n",
            "Epoch 444/1000\n",
            "40/40 - 0s - loss: 2303.7549 - val_loss: 2230.2654 - 87ms/epoch - 2ms/step\n",
            "Epoch 445/1000\n",
            "40/40 - 0s - loss: 2307.3728 - val_loss: 2232.6423 - 80ms/epoch - 2ms/step\n",
            "Epoch 446/1000\n",
            "40/40 - 0s - loss: 2304.8401 - val_loss: 2233.4451 - 91ms/epoch - 2ms/step\n",
            "Epoch 447/1000\n",
            "40/40 - 0s - loss: 2326.5254 - val_loss: 2275.9355 - 75ms/epoch - 2ms/step\n",
            "Epoch 448/1000\n",
            "40/40 - 0s - loss: 2321.1687 - val_loss: 2245.3916 - 95ms/epoch - 2ms/step\n",
            "Epoch 449/1000\n",
            "40/40 - 0s - loss: 2312.1619 - val_loss: 2223.6426 - 92ms/epoch - 2ms/step\n",
            "Epoch 450/1000\n",
            "40/40 - 0s - loss: 2283.9385 - val_loss: 2203.6255 - 86ms/epoch - 2ms/step\n",
            "Epoch 451/1000\n",
            "40/40 - 0s - loss: 2299.9236 - val_loss: 2260.3413 - 84ms/epoch - 2ms/step\n",
            "Epoch 452/1000\n",
            "40/40 - 0s - loss: 2301.7271 - val_loss: 2214.2363 - 88ms/epoch - 2ms/step\n",
            "Epoch 453/1000\n",
            "40/40 - 0s - loss: 2296.4441 - val_loss: 2243.3455 - 80ms/epoch - 2ms/step\n",
            "Epoch 454/1000\n",
            "40/40 - 0s - loss: 2319.3958 - val_loss: 2234.4373 - 86ms/epoch - 2ms/step\n",
            "Epoch 455/1000\n",
            "40/40 - 0s - loss: 2315.1174 - val_loss: 2244.4360 - 84ms/epoch - 2ms/step\n",
            "Epoch 456/1000\n",
            "40/40 - 0s - loss: 2328.5581 - val_loss: 2301.0056 - 85ms/epoch - 2ms/step\n",
            "Epoch 457/1000\n",
            "40/40 - 0s - loss: 2321.3936 - val_loss: 2247.3152 - 77ms/epoch - 2ms/step\n",
            "Epoch 458/1000\n",
            "40/40 - 0s - loss: 2321.6831 - val_loss: 2272.5999 - 82ms/epoch - 2ms/step\n",
            "Epoch 459/1000\n",
            "40/40 - 0s - loss: 2330.3604 - val_loss: 2276.6646 - 82ms/epoch - 2ms/step\n",
            "Epoch 460/1000\n",
            "40/40 - 0s - loss: 2311.2468 - val_loss: 2222.2788 - 83ms/epoch - 2ms/step\n",
            "Epoch 461/1000\n",
            "40/40 - 0s - loss: 2324.5454 - val_loss: 2264.0110 - 89ms/epoch - 2ms/step\n",
            "Epoch 462/1000\n",
            "40/40 - 0s - loss: 2355.6238 - val_loss: 2296.2002 - 85ms/epoch - 2ms/step\n",
            "Epoch 463/1000\n",
            "40/40 - 0s - loss: 2336.7051 - val_loss: 2236.8711 - 79ms/epoch - 2ms/step\n",
            "Epoch 464/1000\n",
            "40/40 - 0s - loss: 2297.8987 - val_loss: 2220.4109 - 76ms/epoch - 2ms/step\n",
            "Epoch 465/1000\n",
            "40/40 - 0s - loss: 2310.9768 - val_loss: 2208.4783 - 82ms/epoch - 2ms/step\n",
            "Epoch 466/1000\n",
            "40/40 - 0s - loss: 2296.1292 - val_loss: 2231.5835 - 79ms/epoch - 2ms/step\n",
            "Epoch 467/1000\n",
            "40/40 - 0s - loss: 2281.8350 - val_loss: 2184.0649 - 80ms/epoch - 2ms/step\n",
            "Epoch 468/1000\n",
            "40/40 - 0s - loss: 2275.5647 - val_loss: 2207.5417 - 94ms/epoch - 2ms/step\n",
            "Epoch 469/1000\n",
            "40/40 - 0s - loss: 2293.2073 - val_loss: 2199.5520 - 84ms/epoch - 2ms/step\n",
            "Epoch 470/1000\n",
            "40/40 - 0s - loss: 2292.1736 - val_loss: 2205.7913 - 97ms/epoch - 2ms/step\n",
            "Epoch 471/1000\n",
            "40/40 - 0s - loss: 2286.5378 - val_loss: 2200.5630 - 93ms/epoch - 2ms/step\n",
            "Epoch 472/1000\n",
            "40/40 - 0s - loss: 2280.0618 - val_loss: 2251.2708 - 87ms/epoch - 2ms/step\n",
            "Epoch 473/1000\n",
            "40/40 - 0s - loss: 2310.4683 - val_loss: 2244.4568 - 85ms/epoch - 2ms/step\n",
            "Epoch 474/1000\n",
            "40/40 - 0s - loss: 2312.3977 - val_loss: 2222.4741 - 88ms/epoch - 2ms/step\n",
            "Epoch 475/1000\n",
            "40/40 - 0s - loss: 2319.7183 - val_loss: 2248.3291 - 77ms/epoch - 2ms/step\n",
            "Epoch 476/1000\n",
            "40/40 - 0s - loss: 2307.1860 - val_loss: 2223.6355 - 92ms/epoch - 2ms/step\n",
            "Epoch 477/1000\n",
            "40/40 - 0s - loss: 2281.7520 - val_loss: 2214.0310 - 89ms/epoch - 2ms/step\n",
            "Epoch 478/1000\n",
            "40/40 - 0s - loss: 2291.1296 - val_loss: 2196.7334 - 80ms/epoch - 2ms/step\n",
            "Epoch 479/1000\n",
            "40/40 - 0s - loss: 2294.6396 - val_loss: 2219.0842 - 79ms/epoch - 2ms/step\n",
            "Epoch 480/1000\n",
            "40/40 - 0s - loss: 2275.3333 - val_loss: 2209.3323 - 89ms/epoch - 2ms/step\n",
            "Epoch 481/1000\n",
            "40/40 - 0s - loss: 2262.2292 - val_loss: 2189.0703 - 76ms/epoch - 2ms/step\n",
            "Epoch 482/1000\n",
            "40/40 - 0s - loss: 2271.8606 - val_loss: 2237.8086 - 85ms/epoch - 2ms/step\n",
            "Epoch 483/1000\n",
            "40/40 - 0s - loss: 2316.4097 - val_loss: 2282.5811 - 88ms/epoch - 2ms/step\n",
            "Epoch 484/1000\n",
            "40/40 - 0s - loss: 2306.9016 - val_loss: 2249.0730 - 80ms/epoch - 2ms/step\n",
            "Epoch 485/1000\n",
            "40/40 - 0s - loss: 2311.6682 - val_loss: 2215.7788 - 88ms/epoch - 2ms/step\n",
            "Epoch 486/1000\n",
            "40/40 - 0s - loss: 2309.4255 - val_loss: 2196.7637 - 89ms/epoch - 2ms/step\n",
            "Epoch 487/1000\n",
            "40/40 - 0s - loss: 2286.5378 - val_loss: 2217.9246 - 81ms/epoch - 2ms/step\n",
            "Epoch 488/1000\n",
            "40/40 - 0s - loss: 2303.4460 - val_loss: 2212.0469 - 85ms/epoch - 2ms/step\n",
            "Epoch 489/1000\n",
            "40/40 - 0s - loss: 2288.3931 - val_loss: 2240.8130 - 97ms/epoch - 2ms/step\n",
            "Epoch 490/1000\n",
            "40/40 - 0s - loss: 2305.5798 - val_loss: 2224.9163 - 89ms/epoch - 2ms/step\n",
            "Epoch 491/1000\n",
            "40/40 - 0s - loss: 2295.3928 - val_loss: 2238.7422 - 84ms/epoch - 2ms/step\n",
            "Epoch 492/1000\n",
            "40/40 - 0s - loss: 2307.6111 - val_loss: 2209.2954 - 92ms/epoch - 2ms/step\n",
            "Epoch 493/1000\n",
            "40/40 - 0s - loss: 2290.1909 - val_loss: 2229.2146 - 81ms/epoch - 2ms/step\n",
            "Epoch 494/1000\n",
            "40/40 - 0s - loss: 2285.7834 - val_loss: 2221.3408 - 86ms/epoch - 2ms/step\n",
            "Epoch 495/1000\n",
            "40/40 - 0s - loss: 2274.6353 - val_loss: 2192.0879 - 89ms/epoch - 2ms/step\n",
            "Epoch 496/1000\n",
            "40/40 - 0s - loss: 2285.1233 - val_loss: 2179.4597 - 89ms/epoch - 2ms/step\n",
            "Epoch 497/1000\n",
            "40/40 - 0s - loss: 2285.3208 - val_loss: 2275.0083 - 87ms/epoch - 2ms/step\n",
            "Epoch 498/1000\n",
            "40/40 - 0s - loss: 2282.4343 - val_loss: 2185.7026 - 79ms/epoch - 2ms/step\n",
            "Epoch 499/1000\n",
            "40/40 - 0s - loss: 2275.6174 - val_loss: 2169.9128 - 88ms/epoch - 2ms/step\n",
            "Epoch 500/1000\n",
            "40/40 - 0s - loss: 2238.2544 - val_loss: 2174.1575 - 82ms/epoch - 2ms/step\n",
            "Epoch 501/1000\n",
            "40/40 - 0s - loss: 2256.9954 - val_loss: 2191.9685 - 76ms/epoch - 2ms/step\n",
            "Epoch 502/1000\n",
            "40/40 - 0s - loss: 2265.3994 - val_loss: 2189.5127 - 92ms/epoch - 2ms/step\n",
            "Epoch 503/1000\n",
            "40/40 - 0s - loss: 2244.8806 - val_loss: 2182.6460 - 73ms/epoch - 2ms/step\n",
            "Epoch 504/1000\n",
            "40/40 - 0s - loss: 2272.1218 - val_loss: 2219.4114 - 99ms/epoch - 2ms/step\n",
            "Epoch 505/1000\n",
            "40/40 - 0s - loss: 2276.5439 - val_loss: 2254.3552 - 84ms/epoch - 2ms/step\n",
            "Epoch 506/1000\n",
            "40/40 - 0s - loss: 2300.8345 - val_loss: 2229.8584 - 81ms/epoch - 2ms/step\n",
            "Epoch 507/1000\n",
            "40/40 - 0s - loss: 2295.8760 - val_loss: 2157.8467 - 88ms/epoch - 2ms/step\n",
            "Epoch 508/1000\n",
            "40/40 - 0s - loss: 2281.9824 - val_loss: 2200.6377 - 83ms/epoch - 2ms/step\n",
            "Epoch 509/1000\n",
            "40/40 - 0s - loss: 2281.5728 - val_loss: 2229.1184 - 77ms/epoch - 2ms/step\n",
            "Epoch 510/1000\n",
            "40/40 - 0s - loss: 2285.0850 - val_loss: 2195.2310 - 80ms/epoch - 2ms/step\n",
            "Epoch 511/1000\n",
            "40/40 - 0s - loss: 2269.4551 - val_loss: 2228.8845 - 92ms/epoch - 2ms/step\n",
            "Epoch 512/1000\n",
            "40/40 - 0s - loss: 2304.6836 - val_loss: 2194.6184 - 96ms/epoch - 2ms/step\n",
            "Epoch 513/1000\n",
            "40/40 - 0s - loss: 2266.8015 - val_loss: 2167.1545 - 79ms/epoch - 2ms/step\n",
            "Epoch 514/1000\n",
            "40/40 - 0s - loss: 2273.7439 - val_loss: 2198.7888 - 82ms/epoch - 2ms/step\n",
            "Epoch 515/1000\n",
            "40/40 - 0s - loss: 2271.9995 - val_loss: 2222.0876 - 83ms/epoch - 2ms/step\n",
            "Epoch 516/1000\n",
            "40/40 - 0s - loss: 2292.0229 - val_loss: 2221.1877 - 81ms/epoch - 2ms/step\n",
            "Epoch 517/1000\n",
            "40/40 - 0s - loss: 2264.6975 - val_loss: 2148.9626 - 81ms/epoch - 2ms/step\n",
            "Epoch 518/1000\n",
            "40/40 - 0s - loss: 2245.0327 - val_loss: 2174.0181 - 89ms/epoch - 2ms/step\n",
            "Epoch 519/1000\n",
            "40/40 - 0s - loss: 2261.4077 - val_loss: 2218.7302 - 85ms/epoch - 2ms/step\n",
            "Epoch 520/1000\n",
            "40/40 - 0s - loss: 2254.9890 - val_loss: 2179.9089 - 86ms/epoch - 2ms/step\n",
            "Epoch 521/1000\n",
            "40/40 - 0s - loss: 2266.3672 - val_loss: 2188.9602 - 91ms/epoch - 2ms/step\n",
            "Epoch 522/1000\n",
            "40/40 - 0s - loss: 2260.6719 - val_loss: 2183.8533 - 84ms/epoch - 2ms/step\n",
            "Epoch 523/1000\n",
            "40/40 - 0s - loss: 2273.0593 - val_loss: 2267.4443 - 80ms/epoch - 2ms/step\n",
            "Epoch 524/1000\n",
            "40/40 - 0s - loss: 2275.5491 - val_loss: 2192.3979 - 83ms/epoch - 2ms/step\n",
            "Epoch 525/1000\n",
            "40/40 - 0s - loss: 2252.2708 - val_loss: 2143.0664 - 75ms/epoch - 2ms/step\n",
            "Epoch 526/1000\n",
            "40/40 - 0s - loss: 2239.1089 - val_loss: 2164.0659 - 88ms/epoch - 2ms/step\n",
            "Epoch 527/1000\n",
            "40/40 - 0s - loss: 2254.2124 - val_loss: 2213.4604 - 89ms/epoch - 2ms/step\n",
            "Epoch 528/1000\n",
            "40/40 - 0s - loss: 2252.1963 - val_loss: 2188.0620 - 83ms/epoch - 2ms/step\n",
            "Epoch 529/1000\n",
            "40/40 - 0s - loss: 2269.2878 - val_loss: 2231.6074 - 87ms/epoch - 2ms/step\n",
            "Epoch 530/1000\n",
            "40/40 - 0s - loss: 2283.7163 - val_loss: 2217.2883 - 88ms/epoch - 2ms/step\n",
            "Epoch 531/1000\n",
            "40/40 - 0s - loss: 2265.9114 - val_loss: 2183.9023 - 78ms/epoch - 2ms/step\n",
            "Epoch 532/1000\n",
            "40/40 - 0s - loss: 2276.6497 - val_loss: 2234.0117 - 84ms/epoch - 2ms/step\n",
            "Epoch 533/1000\n",
            "40/40 - 0s - loss: 2273.8120 - val_loss: 2168.1538 - 87ms/epoch - 2ms/step\n",
            "Epoch 534/1000\n",
            "40/40 - 0s - loss: 2228.6770 - val_loss: 2161.6797 - 74ms/epoch - 2ms/step\n",
            "Epoch 535/1000\n",
            "40/40 - 0s - loss: 2225.9905 - val_loss: 2155.9128 - 86ms/epoch - 2ms/step\n",
            "Epoch 536/1000\n",
            "40/40 - 0s - loss: 2229.7764 - val_loss: 2173.2625 - 87ms/epoch - 2ms/step\n",
            "Epoch 537/1000\n",
            "40/40 - 0s - loss: 2240.8621 - val_loss: 2155.1963 - 90ms/epoch - 2ms/step\n",
            "Epoch 538/1000\n",
            "40/40 - 0s - loss: 2218.9883 - val_loss: 2157.0400 - 85ms/epoch - 2ms/step\n",
            "Epoch 539/1000\n",
            "40/40 - 0s - loss: 2217.3184 - val_loss: 2130.2122 - 74ms/epoch - 2ms/step\n",
            "Epoch 540/1000\n",
            "40/40 - 0s - loss: 2215.4844 - val_loss: 2150.6365 - 86ms/epoch - 2ms/step\n",
            "Epoch 541/1000\n",
            "40/40 - 0s - loss: 2216.7478 - val_loss: 2144.2927 - 88ms/epoch - 2ms/step\n",
            "Epoch 542/1000\n",
            "40/40 - 0s - loss: 2256.8943 - val_loss: 2231.6926 - 88ms/epoch - 2ms/step\n",
            "Epoch 543/1000\n",
            "40/40 - 0s - loss: 2262.5288 - val_loss: 2186.0999 - 80ms/epoch - 2ms/step\n",
            "Epoch 544/1000\n",
            "40/40 - 0s - loss: 2288.5972 - val_loss: 2180.9062 - 77ms/epoch - 2ms/step\n",
            "Epoch 545/1000\n",
            "40/40 - 0s - loss: 2279.5984 - val_loss: 2199.7876 - 90ms/epoch - 2ms/step\n",
            "Epoch 546/1000\n",
            "40/40 - 0s - loss: 2260.3662 - val_loss: 2165.6265 - 90ms/epoch - 2ms/step\n",
            "Epoch 547/1000\n",
            "40/40 - 0s - loss: 2234.2395 - val_loss: 2203.3645 - 84ms/epoch - 2ms/step\n",
            "Epoch 548/1000\n",
            "40/40 - 0s - loss: 2230.7642 - val_loss: 2127.8049 - 91ms/epoch - 2ms/step\n",
            "Epoch 549/1000\n",
            "40/40 - 0s - loss: 2214.6062 - val_loss: 2134.0259 - 87ms/epoch - 2ms/step\n",
            "Epoch 550/1000\n",
            "40/40 - 0s - loss: 2212.6367 - val_loss: 2128.2783 - 79ms/epoch - 2ms/step\n",
            "Epoch 551/1000\n",
            "40/40 - 0s - loss: 2213.9321 - val_loss: 2161.5312 - 86ms/epoch - 2ms/step\n",
            "Epoch 552/1000\n",
            "40/40 - 0s - loss: 2238.5176 - val_loss: 2154.3401 - 83ms/epoch - 2ms/step\n",
            "Epoch 553/1000\n",
            "40/40 - 0s - loss: 2246.1497 - val_loss: 2162.4370 - 77ms/epoch - 2ms/step\n",
            "Epoch 554/1000\n",
            "40/40 - 0s - loss: 2253.1663 - val_loss: 2193.4199 - 81ms/epoch - 2ms/step\n",
            "Epoch 555/1000\n",
            "40/40 - 0s - loss: 2254.4966 - val_loss: 2162.1658 - 77ms/epoch - 2ms/step\n",
            "Epoch 556/1000\n",
            "40/40 - 0s - loss: 2257.8274 - val_loss: 2173.2141 - 94ms/epoch - 2ms/step\n",
            "Epoch 557/1000\n",
            "40/40 - 0s - loss: 2242.8948 - val_loss: 2146.7898 - 79ms/epoch - 2ms/step\n",
            "Epoch 558/1000\n",
            "40/40 - 0s - loss: 2225.0579 - val_loss: 2161.5842 - 78ms/epoch - 2ms/step\n",
            "Epoch 559/1000\n",
            "40/40 - 0s - loss: 2222.8740 - val_loss: 2183.4661 - 89ms/epoch - 2ms/step\n",
            "Epoch 560/1000\n",
            "40/40 - 0s - loss: 2233.7231 - val_loss: 2151.9846 - 83ms/epoch - 2ms/step\n",
            "Epoch 561/1000\n",
            "40/40 - 0s - loss: 2236.5024 - val_loss: 2173.1973 - 75ms/epoch - 2ms/step\n",
            "Epoch 562/1000\n",
            "40/40 - 0s - loss: 2228.6292 - val_loss: 2155.5916 - 82ms/epoch - 2ms/step\n",
            "Epoch 563/1000\n",
            "40/40 - 0s - loss: 2222.9448 - val_loss: 2159.8262 - 88ms/epoch - 2ms/step\n",
            "Epoch 564/1000\n",
            "40/40 - 0s - loss: 2251.0439 - val_loss: 2183.0605 - 82ms/epoch - 2ms/step\n",
            "Epoch 565/1000\n",
            "40/40 - 0s - loss: 2245.3540 - val_loss: 2152.6860 - 97ms/epoch - 2ms/step\n",
            "Epoch 566/1000\n",
            "40/40 - 0s - loss: 2232.4854 - val_loss: 2190.3726 - 76ms/epoch - 2ms/step\n",
            "Epoch 567/1000\n",
            "40/40 - 0s - loss: 2227.7202 - val_loss: 2130.6172 - 91ms/epoch - 2ms/step\n",
            "Epoch 568/1000\n",
            "40/40 - 0s - loss: 2227.9465 - val_loss: 2163.3042 - 83ms/epoch - 2ms/step\n",
            "Epoch 569/1000\n",
            "40/40 - 0s - loss: 2204.6648 - val_loss: 2129.3735 - 94ms/epoch - 2ms/step\n",
            "Epoch 570/1000\n",
            "40/40 - 0s - loss: 2238.3271 - val_loss: 2165.2415 - 93ms/epoch - 2ms/step\n",
            "Epoch 571/1000\n",
            "40/40 - 0s - loss: 2250.7817 - val_loss: 2164.3997 - 83ms/epoch - 2ms/step\n",
            "Epoch 572/1000\n",
            "40/40 - 0s - loss: 2244.8906 - val_loss: 2183.0154 - 84ms/epoch - 2ms/step\n",
            "Epoch 573/1000\n",
            "40/40 - 0s - loss: 2237.4502 - val_loss: 2148.3813 - 85ms/epoch - 2ms/step\n",
            "Epoch 574/1000\n",
            "40/40 - 0s - loss: 2251.5659 - val_loss: 2168.8574 - 79ms/epoch - 2ms/step\n",
            "Epoch 575/1000\n",
            "40/40 - 0s - loss: 2238.0342 - val_loss: 2146.3777 - 90ms/epoch - 2ms/step\n",
            "Epoch 576/1000\n",
            "40/40 - 0s - loss: 2212.7498 - val_loss: 2156.2407 - 83ms/epoch - 2ms/step\n",
            "Epoch 577/1000\n",
            "40/40 - 0s - loss: 2210.7485 - val_loss: 2175.7031 - 80ms/epoch - 2ms/step\n",
            "Epoch 578/1000\n",
            "40/40 - 0s - loss: 2228.4653 - val_loss: 2210.3931 - 85ms/epoch - 2ms/step\n",
            "Epoch 579/1000\n",
            "40/40 - 0s - loss: 2246.7859 - val_loss: 2199.4905 - 78ms/epoch - 2ms/step\n",
            "Epoch 580/1000\n",
            "40/40 - 0s - loss: 2264.0916 - val_loss: 2163.4856 - 80ms/epoch - 2ms/step\n",
            "Epoch 581/1000\n",
            "40/40 - 0s - loss: 2246.3479 - val_loss: 2155.6968 - 77ms/epoch - 2ms/step\n",
            "Epoch 582/1000\n",
            "40/40 - 0s - loss: 2240.2493 - val_loss: 2182.4150 - 96ms/epoch - 2ms/step\n",
            "Epoch 583/1000\n",
            "40/40 - 0s - loss: 2246.1189 - val_loss: 2159.5386 - 78ms/epoch - 2ms/step\n",
            "Epoch 584/1000\n",
            "40/40 - 0s - loss: 2238.2778 - val_loss: 2175.5210 - 81ms/epoch - 2ms/step\n",
            "Epoch 585/1000\n",
            "40/40 - 0s - loss: 2221.7678 - val_loss: 2138.4570 - 95ms/epoch - 2ms/step\n",
            "Epoch 586/1000\n",
            "40/40 - 0s - loss: 2206.4873 - val_loss: 2112.9854 - 81ms/epoch - 2ms/step\n",
            "Epoch 587/1000\n",
            "40/40 - 0s - loss: 2222.4526 - val_loss: 2127.1240 - 87ms/epoch - 2ms/step\n",
            "Epoch 588/1000\n",
            "40/40 - 0s - loss: 2196.4893 - val_loss: 2137.0347 - 80ms/epoch - 2ms/step\n",
            "Epoch 589/1000\n",
            "40/40 - 0s - loss: 2188.9661 - val_loss: 2125.1870 - 87ms/epoch - 2ms/step\n",
            "Epoch 590/1000\n",
            "40/40 - 0s - loss: 2192.1997 - val_loss: 2097.3672 - 91ms/epoch - 2ms/step\n",
            "Epoch 591/1000\n",
            "40/40 - 0s - loss: 2228.8574 - val_loss: 2179.3000 - 81ms/epoch - 2ms/step\n",
            "Epoch 592/1000\n",
            "40/40 - 0s - loss: 2252.3325 - val_loss: 2146.3792 - 81ms/epoch - 2ms/step\n",
            "Epoch 593/1000\n",
            "40/40 - 0s - loss: 2215.9663 - val_loss: 2156.4695 - 81ms/epoch - 2ms/step\n",
            "Epoch 594/1000\n",
            "40/40 - 0s - loss: 2216.4583 - val_loss: 2108.5220 - 91ms/epoch - 2ms/step\n",
            "Epoch 595/1000\n",
            "40/40 - 0s - loss: 2191.2625 - val_loss: 2110.4014 - 78ms/epoch - 2ms/step\n",
            "Epoch 596/1000\n",
            "40/40 - 0s - loss: 2203.8203 - val_loss: 2142.2639 - 79ms/epoch - 2ms/step\n",
            "Epoch 597/1000\n",
            "40/40 - 0s - loss: 2222.9702 - val_loss: 2149.7839 - 91ms/epoch - 2ms/step\n",
            "Epoch 598/1000\n",
            "40/40 - 0s - loss: 2228.6323 - val_loss: 2171.8699 - 78ms/epoch - 2ms/step\n",
            "Epoch 599/1000\n",
            "40/40 - 0s - loss: 2244.8865 - val_loss: 2249.7830 - 72ms/epoch - 2ms/step\n",
            "Epoch 600/1000\n",
            "40/40 - 0s - loss: 2239.5601 - val_loss: 2154.9919 - 86ms/epoch - 2ms/step\n",
            "Epoch 601/1000\n",
            "40/40 - 0s - loss: 2223.7996 - val_loss: 2148.2600 - 92ms/epoch - 2ms/step\n",
            "Epoch 602/1000\n",
            "40/40 - 0s - loss: 2209.1467 - val_loss: 2165.8865 - 83ms/epoch - 2ms/step\n",
            "Epoch 603/1000\n",
            "40/40 - 0s - loss: 2207.6135 - val_loss: 2108.3391 - 82ms/epoch - 2ms/step\n",
            "Epoch 604/1000\n",
            "40/40 - 0s - loss: 2195.3918 - val_loss: 2132.3574 - 85ms/epoch - 2ms/step\n",
            "Epoch 605/1000\n",
            "40/40 - 0s - loss: 2196.6042 - val_loss: 2164.6340 - 79ms/epoch - 2ms/step\n",
            "Epoch 606/1000\n",
            "40/40 - 0s - loss: 2208.3049 - val_loss: 2144.9441 - 87ms/epoch - 2ms/step\n",
            "Epoch 607/1000\n",
            "40/40 - 0s - loss: 2205.3613 - val_loss: 2178.0081 - 96ms/epoch - 2ms/step\n",
            "Epoch 608/1000\n",
            "40/40 - 0s - loss: 2231.1404 - val_loss: 2143.1545 - 84ms/epoch - 2ms/step\n",
            "Epoch 609/1000\n",
            "40/40 - 0s - loss: 2203.8196 - val_loss: 2095.0288 - 85ms/epoch - 2ms/step\n",
            "Epoch 610/1000\n",
            "40/40 - 0s - loss: 2202.0942 - val_loss: 2137.0159 - 83ms/epoch - 2ms/step\n",
            "Epoch 611/1000\n",
            "40/40 - 0s - loss: 2212.1545 - val_loss: 2108.8120 - 82ms/epoch - 2ms/step\n",
            "Epoch 612/1000\n",
            "40/40 - 0s - loss: 2197.2314 - val_loss: 2116.7332 - 76ms/epoch - 2ms/step\n",
            "Epoch 613/1000\n",
            "40/40 - 0s - loss: 2163.6101 - val_loss: 2088.7529 - 83ms/epoch - 2ms/step\n",
            "Epoch 614/1000\n",
            "40/40 - 0s - loss: 2176.9045 - val_loss: 2119.2825 - 92ms/epoch - 2ms/step\n",
            "Epoch 615/1000\n",
            "40/40 - 0s - loss: 2179.7585 - val_loss: 2120.6038 - 78ms/epoch - 2ms/step\n",
            "Epoch 616/1000\n",
            "40/40 - 0s - loss: 2199.3950 - val_loss: 2121.8191 - 81ms/epoch - 2ms/step\n",
            "Epoch 617/1000\n",
            "40/40 - 0s - loss: 2191.9487 - val_loss: 2116.0752 - 93ms/epoch - 2ms/step\n",
            "Epoch 618/1000\n",
            "40/40 - 0s - loss: 2192.0237 - val_loss: 2084.8030 - 82ms/epoch - 2ms/step\n",
            "Epoch 619/1000\n",
            "40/40 - 0s - loss: 2196.7754 - val_loss: 2108.5903 - 92ms/epoch - 2ms/step\n",
            "Epoch 620/1000\n",
            "40/40 - 0s - loss: 2186.9658 - val_loss: 2111.7551 - 85ms/epoch - 2ms/step\n",
            "Epoch 621/1000\n",
            "40/40 - 0s - loss: 2197.4863 - val_loss: 2147.6941 - 82ms/epoch - 2ms/step\n",
            "Epoch 622/1000\n",
            "40/40 - 0s - loss: 2208.7827 - val_loss: 2178.5964 - 82ms/epoch - 2ms/step\n",
            "Epoch 623/1000\n",
            "40/40 - 0s - loss: 2225.6953 - val_loss: 2096.3613 - 92ms/epoch - 2ms/step\n",
            "Epoch 624/1000\n",
            "40/40 - 0s - loss: 2204.5210 - val_loss: 2128.0615 - 82ms/epoch - 2ms/step\n",
            "Epoch 625/1000\n",
            "40/40 - 0s - loss: 2190.5942 - val_loss: 2131.8770 - 95ms/epoch - 2ms/step\n",
            "Epoch 626/1000\n",
            "40/40 - 0s - loss: 2205.4470 - val_loss: 2176.5952 - 82ms/epoch - 2ms/step\n",
            "Epoch 627/1000\n",
            "40/40 - 0s - loss: 2216.9006 - val_loss: 2136.4714 - 92ms/epoch - 2ms/step\n",
            "Epoch 628/1000\n",
            "40/40 - 0s - loss: 2212.9360 - val_loss: 2120.3699 - 89ms/epoch - 2ms/step\n",
            "Epoch 629/1000\n",
            "40/40 - 0s - loss: 2177.2959 - val_loss: 2142.2681 - 82ms/epoch - 2ms/step\n",
            "Epoch 630/1000\n",
            "40/40 - 0s - loss: 2168.5496 - val_loss: 2074.3992 - 79ms/epoch - 2ms/step\n",
            "Epoch 631/1000\n",
            "40/40 - 0s - loss: 2169.8623 - val_loss: 2109.9275 - 90ms/epoch - 2ms/step\n",
            "Epoch 632/1000\n",
            "40/40 - 0s - loss: 2190.4700 - val_loss: 2120.2385 - 88ms/epoch - 2ms/step\n",
            "Epoch 633/1000\n",
            "40/40 - 0s - loss: 2177.8228 - val_loss: 2082.9609 - 88ms/epoch - 2ms/step\n",
            "Epoch 634/1000\n",
            "40/40 - 0s - loss: 2193.3655 - val_loss: 2125.5483 - 85ms/epoch - 2ms/step\n",
            "Epoch 635/1000\n",
            "40/40 - 0s - loss: 2204.9053 - val_loss: 2163.0115 - 79ms/epoch - 2ms/step\n",
            "Epoch 636/1000\n",
            "40/40 - 0s - loss: 2210.1858 - val_loss: 2172.6663 - 80ms/epoch - 2ms/step\n",
            "Epoch 637/1000\n",
            "40/40 - 0s - loss: 2215.0271 - val_loss: 2112.4480 - 95ms/epoch - 2ms/step\n",
            "Epoch 638/1000\n",
            "40/40 - 0s - loss: 2210.8171 - val_loss: 2164.2690 - 90ms/epoch - 2ms/step\n",
            "Epoch 639/1000\n",
            "40/40 - 0s - loss: 2199.6860 - val_loss: 2121.5488 - 80ms/epoch - 2ms/step\n",
            "Epoch 640/1000\n",
            "40/40 - 0s - loss: 2202.9158 - val_loss: 2153.9722 - 92ms/epoch - 2ms/step\n",
            "Epoch 641/1000\n",
            "40/40 - 0s - loss: 2190.2429 - val_loss: 2104.8318 - 85ms/epoch - 2ms/step\n",
            "Epoch 642/1000\n",
            "40/40 - 0s - loss: 2179.6880 - val_loss: 2081.8872 - 76ms/epoch - 2ms/step\n",
            "Epoch 643/1000\n",
            "40/40 - 0s - loss: 2168.2744 - val_loss: 2115.8547 - 85ms/epoch - 2ms/step\n",
            "Epoch 644/1000\n",
            "40/40 - 0s - loss: 2157.0586 - val_loss: 2099.9126 - 95ms/epoch - 2ms/step\n",
            "Epoch 645/1000\n",
            "40/40 - 0s - loss: 2178.3940 - val_loss: 2120.3792 - 93ms/epoch - 2ms/step\n",
            "Epoch 646/1000\n",
            "40/40 - 0s - loss: 2211.0369 - val_loss: 2124.1929 - 83ms/epoch - 2ms/step\n",
            "Epoch 647/1000\n",
            "40/40 - 0s - loss: 2227.3906 - val_loss: 2116.4363 - 91ms/epoch - 2ms/step\n",
            "Epoch 648/1000\n",
            "40/40 - 0s - loss: 2237.4004 - val_loss: 2223.9631 - 84ms/epoch - 2ms/step\n",
            "Epoch 649/1000\n",
            "40/40 - 0s - loss: 2228.7253 - val_loss: 2151.4631 - 78ms/epoch - 2ms/step\n",
            "Epoch 650/1000\n",
            "40/40 - 0s - loss: 2195.8750 - val_loss: 2106.6587 - 138ms/epoch - 3ms/step\n",
            "Epoch 651/1000\n",
            "40/40 - 0s - loss: 2187.1685 - val_loss: 2129.9294 - 87ms/epoch - 2ms/step\n",
            "Epoch 652/1000\n",
            "40/40 - 0s - loss: 2198.7783 - val_loss: 2111.6565 - 105ms/epoch - 3ms/step\n",
            "Epoch 653/1000\n",
            "40/40 - 0s - loss: 2173.9922 - val_loss: 2099.2302 - 83ms/epoch - 2ms/step\n",
            "Epoch 654/1000\n",
            "40/40 - 0s - loss: 2183.3784 - val_loss: 2122.8784 - 84ms/epoch - 2ms/step\n",
            "Epoch 655/1000\n",
            "40/40 - 0s - loss: 2185.0588 - val_loss: 2159.0349 - 95ms/epoch - 2ms/step\n",
            "Epoch 656/1000\n",
            "40/40 - 0s - loss: 2200.2651 - val_loss: 2142.3027 - 84ms/epoch - 2ms/step\n",
            "Epoch 657/1000\n",
            "40/40 - 0s - loss: 2195.7610 - val_loss: 2093.7637 - 78ms/epoch - 2ms/step\n",
            "Epoch 658/1000\n",
            "40/40 - 0s - loss: 2169.5181 - val_loss: 2106.8118 - 96ms/epoch - 2ms/step\n",
            "Epoch 659/1000\n",
            "40/40 - 0s - loss: 2169.7131 - val_loss: 2114.5117 - 94ms/epoch - 2ms/step\n",
            "Epoch 660/1000\n",
            "40/40 - 0s - loss: 2170.3616 - val_loss: 2080.9763 - 74ms/epoch - 2ms/step\n",
            "Epoch 661/1000\n",
            "40/40 - 0s - loss: 2166.7847 - val_loss: 2062.9299 - 89ms/epoch - 2ms/step\n",
            "Epoch 662/1000\n",
            "40/40 - 0s - loss: 2141.9814 - val_loss: 2113.7969 - 92ms/epoch - 2ms/step\n",
            "Epoch 663/1000\n",
            "40/40 - 0s - loss: 2142.9277 - val_loss: 2094.3853 - 81ms/epoch - 2ms/step\n",
            "Epoch 664/1000\n",
            "40/40 - 0s - loss: 2162.8157 - val_loss: 2100.5186 - 86ms/epoch - 2ms/step\n",
            "Epoch 665/1000\n",
            "40/40 - 0s - loss: 2166.2864 - val_loss: 2076.1082 - 87ms/epoch - 2ms/step\n",
            "Epoch 666/1000\n",
            "40/40 - 0s - loss: 2175.3970 - val_loss: 2076.1384 - 84ms/epoch - 2ms/step\n",
            "Epoch 667/1000\n",
            "40/40 - 0s - loss: 2148.7393 - val_loss: 2056.0337 - 91ms/epoch - 2ms/step\n",
            "Epoch 668/1000\n",
            "40/40 - 0s - loss: 2180.6799 - val_loss: 2111.0981 - 82ms/epoch - 2ms/step\n",
            "Epoch 669/1000\n",
            "40/40 - 0s - loss: 2185.5369 - val_loss: 2103.5945 - 87ms/epoch - 2ms/step\n",
            "Epoch 670/1000\n",
            "40/40 - 0s - loss: 2165.2988 - val_loss: 2101.1667 - 85ms/epoch - 2ms/step\n",
            "Epoch 671/1000\n",
            "40/40 - 0s - loss: 2173.6074 - val_loss: 2094.4731 - 78ms/epoch - 2ms/step\n",
            "Epoch 672/1000\n",
            "40/40 - 0s - loss: 2165.8870 - val_loss: 2101.4231 - 84ms/epoch - 2ms/step\n",
            "Epoch 673/1000\n",
            "40/40 - 0s - loss: 2207.7769 - val_loss: 2148.1768 - 82ms/epoch - 2ms/step\n",
            "Epoch 674/1000\n",
            "40/40 - 0s - loss: 2211.0754 - val_loss: 2125.2480 - 84ms/epoch - 2ms/step\n",
            "Epoch 675/1000\n",
            "40/40 - 0s - loss: 2219.4072 - val_loss: 2170.5798 - 89ms/epoch - 2ms/step\n",
            "Epoch 676/1000\n",
            "40/40 - 0s - loss: 2233.0247 - val_loss: 2148.3633 - 76ms/epoch - 2ms/step\n",
            "Epoch 677/1000\n",
            "40/40 - 0s - loss: 2218.0017 - val_loss: 2117.6223 - 81ms/epoch - 2ms/step\n",
            "Epoch 678/1000\n",
            "40/40 - 0s - loss: 2180.8867 - val_loss: 2135.3455 - 89ms/epoch - 2ms/step\n",
            "Epoch 679/1000\n",
            "40/40 - 0s - loss: 2190.9724 - val_loss: 2108.9011 - 78ms/epoch - 2ms/step\n",
            "Epoch 680/1000\n",
            "40/40 - 0s - loss: 2166.8726 - val_loss: 2107.1218 - 83ms/epoch - 2ms/step\n",
            "Epoch 681/1000\n",
            "40/40 - 0s - loss: 2159.6084 - val_loss: 2038.0557 - 91ms/epoch - 2ms/step\n",
            "Epoch 682/1000\n",
            "40/40 - 0s - loss: 2138.9707 - val_loss: 2068.1621 - 85ms/epoch - 2ms/step\n",
            "Epoch 683/1000\n",
            "40/40 - 0s - loss: 2127.1655 - val_loss: 2082.5781 - 81ms/epoch - 2ms/step\n",
            "Epoch 684/1000\n",
            "40/40 - 0s - loss: 2135.8145 - val_loss: 2048.5737 - 97ms/epoch - 2ms/step\n",
            "Epoch 685/1000\n",
            "40/40 - 0s - loss: 2130.8977 - val_loss: 2052.4709 - 76ms/epoch - 2ms/step\n",
            "Epoch 686/1000\n",
            "40/40 - 0s - loss: 2125.0708 - val_loss: 2048.7961 - 95ms/epoch - 2ms/step\n",
            "Epoch 687/1000\n",
            "40/40 - 0s - loss: 2144.4641 - val_loss: 2098.0901 - 85ms/epoch - 2ms/step\n",
            "Epoch 688/1000\n",
            "40/40 - 0s - loss: 2168.6790 - val_loss: 2083.8176 - 84ms/epoch - 2ms/step\n",
            "Epoch 689/1000\n",
            "40/40 - 0s - loss: 2152.0085 - val_loss: 2060.5024 - 80ms/epoch - 2ms/step\n",
            "Epoch 690/1000\n",
            "40/40 - 0s - loss: 2160.9253 - val_loss: 2085.6895 - 91ms/epoch - 2ms/step\n",
            "Epoch 691/1000\n",
            "40/40 - 0s - loss: 2154.5662 - val_loss: 2095.9316 - 80ms/epoch - 2ms/step\n",
            "Epoch 692/1000\n",
            "40/40 - 0s - loss: 2149.4504 - val_loss: 2088.4080 - 86ms/epoch - 2ms/step\n",
            "Epoch 693/1000\n",
            "40/40 - 0s - loss: 2148.0127 - val_loss: 2081.0417 - 85ms/epoch - 2ms/step\n",
            "Epoch 694/1000\n",
            "40/40 - 0s - loss: 2147.3030 - val_loss: 2083.9519 - 74ms/epoch - 2ms/step\n",
            "Epoch 695/1000\n",
            "40/40 - 0s - loss: 2148.4834 - val_loss: 2096.1555 - 89ms/epoch - 2ms/step\n",
            "Epoch 696/1000\n",
            "40/40 - 0s - loss: 2148.0161 - val_loss: 2093.7344 - 81ms/epoch - 2ms/step\n",
            "Epoch 697/1000\n",
            "40/40 - 0s - loss: 2155.9084 - val_loss: 2096.0015 - 82ms/epoch - 2ms/step\n",
            "Epoch 698/1000\n",
            "40/40 - 0s - loss: 2158.7349 - val_loss: 2075.2974 - 77ms/epoch - 2ms/step\n",
            "Epoch 699/1000\n",
            "40/40 - 0s - loss: 2177.3381 - val_loss: 2135.7219 - 83ms/epoch - 2ms/step\n",
            "Epoch 700/1000\n",
            "40/40 - 0s - loss: 2172.2915 - val_loss: 2136.4209 - 96ms/epoch - 2ms/step\n",
            "Epoch 701/1000\n",
            "40/40 - 0s - loss: 2165.8301 - val_loss: 2098.8706 - 84ms/epoch - 2ms/step\n",
            "Epoch 702/1000\n",
            "40/40 - 0s - loss: 2189.3447 - val_loss: 2113.5005 - 91ms/epoch - 2ms/step\n",
            "Epoch 703/1000\n",
            "40/40 - 0s - loss: 2178.1013 - val_loss: 2098.5403 - 88ms/epoch - 2ms/step\n",
            "Epoch 704/1000\n",
            "40/40 - 0s - loss: 2181.5500 - val_loss: 2127.5459 - 81ms/epoch - 2ms/step\n",
            "Epoch 705/1000\n",
            "40/40 - 0s - loss: 2166.1865 - val_loss: 2100.4526 - 84ms/epoch - 2ms/step\n",
            "Epoch 706/1000\n",
            "40/40 - 0s - loss: 2148.9431 - val_loss: 2068.7959 - 93ms/epoch - 2ms/step\n",
            "Epoch 707/1000\n",
            "40/40 - 0s - loss: 2155.7192 - val_loss: 2109.9204 - 83ms/epoch - 2ms/step\n",
            "Epoch 708/1000\n",
            "40/40 - 0s - loss: 2174.1489 - val_loss: 2073.6914 - 80ms/epoch - 2ms/step\n",
            "Epoch 709/1000\n",
            "40/40 - 0s - loss: 2154.9697 - val_loss: 2132.7617 - 91ms/epoch - 2ms/step\n",
            "Epoch 710/1000\n",
            "40/40 - 0s - loss: 2180.1965 - val_loss: 2087.7739 - 81ms/epoch - 2ms/step\n",
            "Epoch 711/1000\n",
            "40/40 - 0s - loss: 2152.4900 - val_loss: 2062.7798 - 77ms/epoch - 2ms/step\n",
            "Epoch 712/1000\n",
            "40/40 - 0s - loss: 2151.8459 - val_loss: 2074.1624 - 90ms/epoch - 2ms/step\n",
            "Epoch 713/1000\n",
            "40/40 - 0s - loss: 2139.8760 - val_loss: 2076.2605 - 83ms/epoch - 2ms/step\n",
            "Epoch 714/1000\n",
            "40/40 - 0s - loss: 2180.2227 - val_loss: 2164.7925 - 92ms/epoch - 2ms/step\n",
            "Epoch 715/1000\n",
            "40/40 - 0s - loss: 2172.3057 - val_loss: 2126.7222 - 87ms/epoch - 2ms/step\n",
            "Epoch 716/1000\n",
            "40/40 - 0s - loss: 2179.0156 - val_loss: 2172.4241 - 82ms/epoch - 2ms/step\n",
            "Epoch 717/1000\n",
            "40/40 - 0s - loss: 2210.8792 - val_loss: 2207.1165 - 84ms/epoch - 2ms/step\n",
            "Epoch 718/1000\n",
            "40/40 - 0s - loss: 2264.1689 - val_loss: 2166.1804 - 84ms/epoch - 2ms/step\n",
            "Epoch 719/1000\n",
            "40/40 - 0s - loss: 2202.5332 - val_loss: 2104.6343 - 91ms/epoch - 2ms/step\n",
            "Epoch 720/1000\n",
            "40/40 - 0s - loss: 2200.6833 - val_loss: 2107.7107 - 82ms/epoch - 2ms/step\n",
            "Epoch 721/1000\n",
            "40/40 - 0s - loss: 2208.5015 - val_loss: 2125.1353 - 96ms/epoch - 2ms/step\n",
            "Epoch 722/1000\n",
            "40/40 - 0s - loss: 2179.2063 - val_loss: 2101.4048 - 80ms/epoch - 2ms/step\n",
            "Epoch 723/1000\n",
            "40/40 - 0s - loss: 2170.3796 - val_loss: 2076.5166 - 85ms/epoch - 2ms/step\n",
            "Epoch 724/1000\n",
            "40/40 - 0s - loss: 2137.2422 - val_loss: 2038.6696 - 88ms/epoch - 2ms/step\n",
            "Epoch 725/1000\n",
            "40/40 - 0s - loss: 2146.9739 - val_loss: 2101.9673 - 88ms/epoch - 2ms/step\n",
            "Epoch 726/1000\n",
            "40/40 - 0s - loss: 2154.2959 - val_loss: 2116.0364 - 81ms/epoch - 2ms/step\n",
            "Epoch 727/1000\n",
            "40/40 - 0s - loss: 2168.6643 - val_loss: 2084.7263 - 84ms/epoch - 2ms/step\n",
            "Epoch 728/1000\n",
            "40/40 - 0s - loss: 2150.5793 - val_loss: 2070.1951 - 88ms/epoch - 2ms/step\n",
            "Epoch 729/1000\n",
            "40/40 - 0s - loss: 2143.3479 - val_loss: 2059.8721 - 82ms/epoch - 2ms/step\n",
            "Epoch 730/1000\n",
            "40/40 - 0s - loss: 2144.1741 - val_loss: 2058.7183 - 79ms/epoch - 2ms/step\n",
            "Epoch 731/1000\n",
            "40/40 - 0s - loss: 2138.1663 - val_loss: 2053.3784 - 92ms/epoch - 2ms/step\n",
            "Epoch 732/1000\n",
            "40/40 - 0s - loss: 2136.2666 - val_loss: 2098.7441 - 77ms/epoch - 2ms/step\n",
            "Epoch 733/1000\n",
            "40/40 - 0s - loss: 2142.4023 - val_loss: 2075.4319 - 91ms/epoch - 2ms/step\n",
            "Epoch 734/1000\n",
            "40/40 - 0s - loss: 2123.3149 - val_loss: 2077.2441 - 87ms/epoch - 2ms/step\n",
            "Epoch 735/1000\n",
            "40/40 - 0s - loss: 2155.3782 - val_loss: 2089.9016 - 80ms/epoch - 2ms/step\n",
            "Epoch 736/1000\n",
            "40/40 - 0s - loss: 2145.2939 - val_loss: 2072.4609 - 94ms/epoch - 2ms/step\n",
            "Epoch 737/1000\n",
            "40/40 - 0s - loss: 2144.6018 - val_loss: 2062.2073 - 82ms/epoch - 2ms/step\n",
            "Epoch 738/1000\n",
            "40/40 - 0s - loss: 2127.9663 - val_loss: 2083.2437 - 78ms/epoch - 2ms/step\n",
            "Epoch 739/1000\n",
            "40/40 - 0s - loss: 2156.5266 - val_loss: 2076.4402 - 91ms/epoch - 2ms/step\n",
            "Epoch 740/1000\n",
            "40/40 - 0s - loss: 2149.3826 - val_loss: 2089.1240 - 78ms/epoch - 2ms/step\n",
            "Epoch 741/1000\n",
            "40/40 - 0s - loss: 2120.0957 - val_loss: 2025.8762 - 84ms/epoch - 2ms/step\n",
            "Epoch 742/1000\n",
            "40/40 - 0s - loss: 2115.3203 - val_loss: 2049.1602 - 87ms/epoch - 2ms/step\n",
            "Epoch 743/1000\n",
            "40/40 - 0s - loss: 2122.6841 - val_loss: 2083.9043 - 95ms/epoch - 2ms/step\n",
            "Epoch 744/1000\n",
            "40/40 - 0s - loss: 2118.1355 - val_loss: 2067.7617 - 80ms/epoch - 2ms/step\n",
            "Epoch 745/1000\n",
            "40/40 - 0s - loss: 2126.5789 - val_loss: 2068.6711 - 80ms/epoch - 2ms/step\n",
            "Epoch 746/1000\n",
            "40/40 - 0s - loss: 2125.6392 - val_loss: 2059.0806 - 80ms/epoch - 2ms/step\n",
            "Epoch 747/1000\n",
            "40/40 - 0s - loss: 2124.5747 - val_loss: 2071.0691 - 87ms/epoch - 2ms/step\n",
            "Epoch 748/1000\n",
            "40/40 - 0s - loss: 2144.1904 - val_loss: 2123.8535 - 78ms/epoch - 2ms/step\n",
            "Epoch 749/1000\n",
            "40/40 - 0s - loss: 2155.4001 - val_loss: 2102.7439 - 94ms/epoch - 2ms/step\n",
            "Epoch 750/1000\n",
            "40/40 - 0s - loss: 2156.8118 - val_loss: 2069.4744 - 79ms/epoch - 2ms/step\n",
            "Epoch 751/1000\n",
            "40/40 - 0s - loss: 2127.9866 - val_loss: 2067.0405 - 76ms/epoch - 2ms/step\n",
            "Epoch 752/1000\n",
            "40/40 - 0s - loss: 2156.6841 - val_loss: 2059.7493 - 94ms/epoch - 2ms/step\n",
            "Epoch 753/1000\n",
            "40/40 - 0s - loss: 2129.7498 - val_loss: 2047.2372 - 101ms/epoch - 3ms/step\n",
            "Epoch 754/1000\n",
            "40/40 - 0s - loss: 2132.0361 - val_loss: 2071.6694 - 75ms/epoch - 2ms/step\n",
            "Epoch 755/1000\n",
            "40/40 - 0s - loss: 2141.2542 - val_loss: 2041.9646 - 92ms/epoch - 2ms/step\n",
            "Epoch 756/1000\n",
            "40/40 - 0s - loss: 2132.0601 - val_loss: 2044.4314 - 81ms/epoch - 2ms/step\n",
            "Epoch 757/1000\n",
            "40/40 - 0s - loss: 2121.9451 - val_loss: 2062.1284 - 83ms/epoch - 2ms/step\n",
            "Epoch 758/1000\n",
            "40/40 - 0s - loss: 2125.3232 - val_loss: 2040.6897 - 79ms/epoch - 2ms/step\n",
            "Epoch 759/1000\n",
            "40/40 - 0s - loss: 2112.1548 - val_loss: 2074.9424 - 86ms/epoch - 2ms/step\n",
            "Epoch 760/1000\n",
            "40/40 - 0s - loss: 2132.9795 - val_loss: 2044.1411 - 84ms/epoch - 2ms/step\n",
            "Epoch 761/1000\n",
            "40/40 - 0s - loss: 2144.0549 - val_loss: 2086.7539 - 90ms/epoch - 2ms/step\n",
            "Epoch 762/1000\n",
            "40/40 - 0s - loss: 2157.0112 - val_loss: 2066.3982 - 82ms/epoch - 2ms/step\n",
            "Epoch 763/1000\n",
            "40/40 - 0s - loss: 2137.1602 - val_loss: 2052.2754 - 96ms/epoch - 2ms/step\n",
            "Epoch 764/1000\n",
            "40/40 - 0s - loss: 2119.5620 - val_loss: 2043.7928 - 83ms/epoch - 2ms/step\n",
            "Epoch 765/1000\n",
            "40/40 - 0s - loss: 2132.0305 - val_loss: 2064.4158 - 83ms/epoch - 2ms/step\n",
            "Epoch 766/1000\n",
            "40/40 - 0s - loss: 2122.9360 - val_loss: 2037.3279 - 83ms/epoch - 2ms/step\n",
            "Epoch 767/1000\n",
            "40/40 - 0s - loss: 2121.9270 - val_loss: 2044.7726 - 79ms/epoch - 2ms/step\n",
            "Epoch 768/1000\n",
            "40/40 - 0s - loss: 2131.6565 - val_loss: 2055.7683 - 96ms/epoch - 2ms/step\n",
            "Epoch 769/1000\n",
            "40/40 - 0s - loss: 2125.4705 - val_loss: 2049.3645 - 75ms/epoch - 2ms/step\n",
            "Epoch 770/1000\n",
            "40/40 - 0s - loss: 2124.1721 - val_loss: 2075.2219 - 79ms/epoch - 2ms/step\n",
            "Epoch 771/1000\n",
            "40/40 - 0s - loss: 2144.5620 - val_loss: 2093.0632 - 84ms/epoch - 2ms/step\n",
            "Epoch 772/1000\n",
            "40/40 - 0s - loss: 2163.7908 - val_loss: 2119.1157 - 81ms/epoch - 2ms/step\n",
            "Epoch 773/1000\n",
            "40/40 - 0s - loss: 2178.6179 - val_loss: 2087.6248 - 90ms/epoch - 2ms/step\n",
            "Epoch 774/1000\n",
            "40/40 - 0s - loss: 2210.3452 - val_loss: 2151.1926 - 84ms/epoch - 2ms/step\n",
            "Epoch 775/1000\n",
            "40/40 - 0s - loss: 2199.3782 - val_loss: 2076.6733 - 76ms/epoch - 2ms/step\n",
            "Epoch 776/1000\n",
            "40/40 - 0s - loss: 2157.7595 - val_loss: 2076.6404 - 77ms/epoch - 2ms/step\n",
            "Epoch 777/1000\n",
            "40/40 - 0s - loss: 2139.3186 - val_loss: 2036.3444 - 93ms/epoch - 2ms/step\n",
            "Epoch 778/1000\n",
            "40/40 - 0s - loss: 2138.4966 - val_loss: 2042.9574 - 80ms/epoch - 2ms/step\n",
            "Epoch 779/1000\n",
            "40/40 - 0s - loss: 2125.8967 - val_loss: 2076.4827 - 90ms/epoch - 2ms/step\n",
            "Epoch 780/1000\n",
            "40/40 - 0s - loss: 2126.5071 - val_loss: 2085.8792 - 99ms/epoch - 2ms/step\n",
            "Epoch 781/1000\n",
            "40/40 - 0s - loss: 2125.6760 - val_loss: 2070.2495 - 78ms/epoch - 2ms/step\n",
            "Epoch 782/1000\n",
            "40/40 - 0s - loss: 2119.5972 - val_loss: 2070.1799 - 87ms/epoch - 2ms/step\n",
            "Epoch 783/1000\n",
            "40/40 - 0s - loss: 2141.5364 - val_loss: 2075.5181 - 88ms/epoch - 2ms/step\n",
            "Epoch 784/1000\n",
            "40/40 - 0s - loss: 2136.3987 - val_loss: 2084.2778 - 88ms/epoch - 2ms/step\n",
            "Epoch 785/1000\n",
            "40/40 - 0s - loss: 2139.9128 - val_loss: 2038.8512 - 82ms/epoch - 2ms/step\n",
            "Epoch 786/1000\n",
            "40/40 - 0s - loss: 2132.9751 - val_loss: 2080.9290 - 81ms/epoch - 2ms/step\n",
            "Epoch 787/1000\n",
            "40/40 - 0s - loss: 2146.5693 - val_loss: 2087.6099 - 88ms/epoch - 2ms/step\n",
            "Epoch 788/1000\n",
            "40/40 - 0s - loss: 2131.6377 - val_loss: 2053.5181 - 77ms/epoch - 2ms/step\n",
            "Epoch 789/1000\n",
            "40/40 - 0s - loss: 2138.1252 - val_loss: 2085.7104 - 87ms/epoch - 2ms/step\n",
            "Epoch 790/1000\n",
            "40/40 - 0s - loss: 2135.1926 - val_loss: 2028.9797 - 83ms/epoch - 2ms/step\n",
            "Epoch 791/1000\n",
            "40/40 - 0s - loss: 2110.3066 - val_loss: 2055.3455 - 80ms/epoch - 2ms/step\n",
            "Epoch 792/1000\n",
            "40/40 - 0s - loss: 2127.5044 - val_loss: 2065.2751 - 84ms/epoch - 2ms/step\n",
            "Epoch 793/1000\n",
            "40/40 - 0s - loss: 2128.8743 - val_loss: 2049.3699 - 85ms/epoch - 2ms/step\n",
            "Epoch 794/1000\n",
            "40/40 - 0s - loss: 2138.1780 - val_loss: 2075.0203 - 81ms/epoch - 2ms/step\n",
            "Epoch 795/1000\n",
            "40/40 - 0s - loss: 2142.6853 - val_loss: 2090.4429 - 78ms/epoch - 2ms/step\n",
            "Epoch 796/1000\n",
            "40/40 - 0s - loss: 2155.7920 - val_loss: 2065.6772 - 80ms/epoch - 2ms/step\n",
            "Epoch 797/1000\n",
            "40/40 - 0s - loss: 2151.5210 - val_loss: 2104.7576 - 78ms/epoch - 2ms/step\n",
            "Epoch 798/1000\n",
            "40/40 - 0s - loss: 2166.4802 - val_loss: 2090.8240 - 82ms/epoch - 2ms/step\n",
            "Epoch 799/1000\n",
            "40/40 - 0s - loss: 2152.7295 - val_loss: 2058.9924 - 88ms/epoch - 2ms/step\n",
            "Epoch 800/1000\n",
            "40/40 - 0s - loss: 2118.3054 - val_loss: 2050.5427 - 83ms/epoch - 2ms/step\n",
            "Epoch 801/1000\n",
            "40/40 - 0s - loss: 2098.8923 - val_loss: 2032.5093 - 85ms/epoch - 2ms/step\n",
            "Epoch 802/1000\n",
            "40/40 - 0s - loss: 2103.8645 - val_loss: 2023.4375 - 83ms/epoch - 2ms/step\n",
            "Epoch 803/1000\n",
            "40/40 - 0s - loss: 2128.1521 - val_loss: 2022.0590 - 102ms/epoch - 3ms/step\n",
            "Epoch 804/1000\n",
            "40/40 - 0s - loss: 2116.9077 - val_loss: 2036.0757 - 82ms/epoch - 2ms/step\n",
            "Epoch 805/1000\n",
            "40/40 - 0s - loss: 2085.9119 - val_loss: 2016.6948 - 87ms/epoch - 2ms/step\n",
            "Epoch 806/1000\n",
            "40/40 - 0s - loss: 2101.1997 - val_loss: 2038.1685 - 78ms/epoch - 2ms/step\n",
            "Epoch 807/1000\n",
            "40/40 - 0s - loss: 2104.1028 - val_loss: 2043.8092 - 75ms/epoch - 2ms/step\n",
            "Epoch 808/1000\n",
            "40/40 - 0s - loss: 2118.3435 - val_loss: 2035.7332 - 90ms/epoch - 2ms/step\n",
            "Epoch 809/1000\n",
            "40/40 - 0s - loss: 2103.6467 - val_loss: 2039.7736 - 89ms/epoch - 2ms/step\n",
            "Epoch 810/1000\n",
            "40/40 - 0s - loss: 2120.1306 - val_loss: 2121.1184 - 85ms/epoch - 2ms/step\n",
            "Epoch 811/1000\n",
            "40/40 - 0s - loss: 2146.3013 - val_loss: 2069.5466 - 91ms/epoch - 2ms/step\n",
            "Epoch 812/1000\n",
            "40/40 - 0s - loss: 2150.5542 - val_loss: 2073.2803 - 82ms/epoch - 2ms/step\n",
            "Epoch 813/1000\n",
            "40/40 - 0s - loss: 2118.1165 - val_loss: 2066.0967 - 78ms/epoch - 2ms/step\n",
            "Epoch 814/1000\n",
            "40/40 - 0s - loss: 2135.5408 - val_loss: 2043.3727 - 83ms/epoch - 2ms/step\n",
            "Epoch 815/1000\n",
            "40/40 - 0s - loss: 2124.8513 - val_loss: 2031.5986 - 90ms/epoch - 2ms/step\n",
            "Epoch 816/1000\n",
            "40/40 - 0s - loss: 2108.2585 - val_loss: 2000.7703 - 77ms/epoch - 2ms/step\n",
            "Epoch 817/1000\n",
            "40/40 - 0s - loss: 2089.3418 - val_loss: 2014.6447 - 84ms/epoch - 2ms/step\n",
            "Epoch 818/1000\n",
            "40/40 - 0s - loss: 2114.6372 - val_loss: 2048.6143 - 81ms/epoch - 2ms/step\n",
            "Epoch 819/1000\n",
            "40/40 - 0s - loss: 2132.0166 - val_loss: 2115.5264 - 93ms/epoch - 2ms/step\n",
            "Epoch 820/1000\n",
            "40/40 - 0s - loss: 2127.4390 - val_loss: 2050.6855 - 85ms/epoch - 2ms/step\n",
            "Epoch 821/1000\n",
            "40/40 - 0s - loss: 2136.7334 - val_loss: 2116.5579 - 77ms/epoch - 2ms/step\n",
            "Epoch 822/1000\n",
            "40/40 - 0s - loss: 2119.3875 - val_loss: 2018.6401 - 143ms/epoch - 4ms/step\n",
            "Epoch 823/1000\n",
            "40/40 - 0s - loss: 2110.0889 - val_loss: 2011.1981 - 86ms/epoch - 2ms/step\n",
            "Epoch 824/1000\n",
            "40/40 - 0s - loss: 2103.0083 - val_loss: 2035.6643 - 96ms/epoch - 2ms/step\n",
            "Epoch 825/1000\n",
            "40/40 - 0s - loss: 2100.4783 - val_loss: 2039.2026 - 95ms/epoch - 2ms/step\n",
            "Epoch 826/1000\n",
            "40/40 - 0s - loss: 2100.8770 - val_loss: 2032.1285 - 80ms/epoch - 2ms/step\n",
            "Epoch 827/1000\n",
            "40/40 - 0s - loss: 2090.7161 - val_loss: 2034.7612 - 91ms/epoch - 2ms/step\n",
            "Epoch 828/1000\n",
            "40/40 - 0s - loss: 2089.6272 - val_loss: 2028.5245 - 79ms/epoch - 2ms/step\n",
            "Epoch 829/1000\n",
            "40/40 - 0s - loss: 2077.8660 - val_loss: 1986.6871 - 84ms/epoch - 2ms/step\n",
            "Epoch 830/1000\n",
            "40/40 - 0s - loss: 2075.6023 - val_loss: 2013.6620 - 78ms/epoch - 2ms/step\n",
            "Epoch 831/1000\n",
            "40/40 - 0s - loss: 2092.4854 - val_loss: 2008.6656 - 88ms/epoch - 2ms/step\n",
            "Epoch 832/1000\n",
            "40/40 - 0s - loss: 2100.6960 - val_loss: 2037.8425 - 83ms/epoch - 2ms/step\n",
            "Epoch 833/1000\n",
            "40/40 - 0s - loss: 2104.3887 - val_loss: 2058.9138 - 79ms/epoch - 2ms/step\n",
            "Epoch 834/1000\n",
            "40/40 - 0s - loss: 2128.2354 - val_loss: 2096.8057 - 81ms/epoch - 2ms/step\n",
            "Epoch 835/1000\n",
            "40/40 - 0s - loss: 2139.7031 - val_loss: 2064.1619 - 90ms/epoch - 2ms/step\n",
            "Epoch 836/1000\n",
            "40/40 - 0s - loss: 2121.9768 - val_loss: 2030.5957 - 77ms/epoch - 2ms/step\n",
            "Epoch 837/1000\n",
            "40/40 - 0s - loss: 2103.2144 - val_loss: 2078.2869 - 84ms/epoch - 2ms/step\n",
            "Epoch 838/1000\n",
            "40/40 - 0s - loss: 2114.1748 - val_loss: 2025.8096 - 94ms/epoch - 2ms/step\n",
            "Epoch 839/1000\n",
            "40/40 - 0s - loss: 2124.2173 - val_loss: 2045.4894 - 98ms/epoch - 2ms/step\n",
            "Epoch 840/1000\n",
            "40/40 - 0s - loss: 2105.1614 - val_loss: 2023.5592 - 102ms/epoch - 3ms/step\n",
            "Epoch 841/1000\n",
            "40/40 - 0s - loss: 2113.4370 - val_loss: 2041.2294 - 86ms/epoch - 2ms/step\n",
            "Epoch 842/1000\n",
            "40/40 - 0s - loss: 2096.6855 - val_loss: 2034.6720 - 82ms/epoch - 2ms/step\n",
            "Epoch 843/1000\n",
            "40/40 - 0s - loss: 2107.6091 - val_loss: 2046.2590 - 88ms/epoch - 2ms/step\n",
            "Epoch 844/1000\n",
            "40/40 - 0s - loss: 2110.1797 - val_loss: 2057.2676 - 87ms/epoch - 2ms/step\n",
            "Epoch 845/1000\n",
            "40/40 - 0s - loss: 2123.8540 - val_loss: 2045.3251 - 90ms/epoch - 2ms/step\n",
            "Epoch 846/1000\n",
            "40/40 - 0s - loss: 2155.2412 - val_loss: 2058.7344 - 94ms/epoch - 2ms/step\n",
            "Epoch 847/1000\n",
            "40/40 - 0s - loss: 2149.3440 - val_loss: 2097.4507 - 92ms/epoch - 2ms/step\n",
            "Epoch 848/1000\n",
            "40/40 - 0s - loss: 2137.7112 - val_loss: 2068.0132 - 81ms/epoch - 2ms/step\n",
            "Epoch 849/1000\n",
            "40/40 - 0s - loss: 2127.6802 - val_loss: 2053.4824 - 77ms/epoch - 2ms/step\n",
            "Epoch 850/1000\n",
            "40/40 - 0s - loss: 2096.2842 - val_loss: 2036.9037 - 98ms/epoch - 2ms/step\n",
            "Epoch 851/1000\n",
            "40/40 - 0s - loss: 2090.9924 - val_loss: 1997.9088 - 91ms/epoch - 2ms/step\n",
            "Epoch 852/1000\n",
            "40/40 - 0s - loss: 2079.8696 - val_loss: 2031.2325 - 76ms/epoch - 2ms/step\n",
            "Epoch 853/1000\n",
            "40/40 - 0s - loss: 2091.9941 - val_loss: 2028.4922 - 81ms/epoch - 2ms/step\n",
            "Epoch 854/1000\n",
            "40/40 - 0s - loss: 2101.9441 - val_loss: 2043.8833 - 88ms/epoch - 2ms/step\n",
            "Epoch 855/1000\n",
            "40/40 - 0s - loss: 2087.9541 - val_loss: 2000.4626 - 98ms/epoch - 2ms/step\n",
            "Epoch 856/1000\n",
            "40/40 - 0s - loss: 2100.5669 - val_loss: 2058.6084 - 100ms/epoch - 2ms/step\n",
            "Epoch 857/1000\n",
            "40/40 - 0s - loss: 2093.7632 - val_loss: 2026.4600 - 96ms/epoch - 2ms/step\n",
            "Epoch 858/1000\n",
            "40/40 - 0s - loss: 2118.3848 - val_loss: 2067.0334 - 84ms/epoch - 2ms/step\n",
            "Epoch 859/1000\n",
            "40/40 - 0s - loss: 2123.6658 - val_loss: 2047.7709 - 86ms/epoch - 2ms/step\n",
            "Epoch 860/1000\n",
            "40/40 - 0s - loss: 2107.2615 - val_loss: 2032.5874 - 101ms/epoch - 3ms/step\n",
            "Epoch 861/1000\n",
            "40/40 - 0s - loss: 2091.2417 - val_loss: 2007.2523 - 78ms/epoch - 2ms/step\n",
            "Epoch 862/1000\n",
            "40/40 - 0s - loss: 2097.7310 - val_loss: 2029.6908 - 97ms/epoch - 2ms/step\n",
            "Epoch 863/1000\n",
            "40/40 - 0s - loss: 2092.6062 - val_loss: 2035.9347 - 93ms/epoch - 2ms/step\n",
            "Epoch 864/1000\n",
            "40/40 - 0s - loss: 2115.2959 - val_loss: 2066.5330 - 93ms/epoch - 2ms/step\n",
            "Epoch 865/1000\n",
            "40/40 - 0s - loss: 2127.5500 - val_loss: 2015.9832 - 87ms/epoch - 2ms/step\n",
            "Epoch 866/1000\n",
            "40/40 - 0s - loss: 2088.2122 - val_loss: 2007.7754 - 92ms/epoch - 2ms/step\n",
            "Epoch 867/1000\n",
            "40/40 - 0s - loss: 2066.6604 - val_loss: 1982.3263 - 85ms/epoch - 2ms/step\n",
            "Epoch 868/1000\n",
            "40/40 - 0s - loss: 2073.9304 - val_loss: 1998.5941 - 82ms/epoch - 2ms/step\n",
            "Epoch 869/1000\n",
            "40/40 - 0s - loss: 2089.4768 - val_loss: 2078.1858 - 85ms/epoch - 2ms/step\n",
            "Epoch 870/1000\n",
            "40/40 - 0s - loss: 2123.6306 - val_loss: 2024.2805 - 87ms/epoch - 2ms/step\n",
            "Epoch 871/1000\n",
            "40/40 - 0s - loss: 2106.8972 - val_loss: 2035.6061 - 81ms/epoch - 2ms/step\n",
            "Epoch 872/1000\n",
            "40/40 - 0s - loss: 2116.5706 - val_loss: 2041.4171 - 75ms/epoch - 2ms/step\n",
            "Epoch 873/1000\n",
            "40/40 - 0s - loss: 2102.7002 - val_loss: 2028.0442 - 88ms/epoch - 2ms/step\n",
            "Epoch 874/1000\n",
            "40/40 - 0s - loss: 2116.1548 - val_loss: 2036.3905 - 88ms/epoch - 2ms/step\n",
            "Epoch 875/1000\n",
            "40/40 - 0s - loss: 2117.9697 - val_loss: 2061.7959 - 96ms/epoch - 2ms/step\n",
            "Epoch 876/1000\n",
            "40/40 - 0s - loss: 2137.9822 - val_loss: 2059.1760 - 92ms/epoch - 2ms/step\n",
            "Epoch 877/1000\n",
            "40/40 - 0s - loss: 2134.1135 - val_loss: 2047.5577 - 98ms/epoch - 2ms/step\n",
            "Epoch 878/1000\n",
            "40/40 - 0s - loss: 2112.9260 - val_loss: 2035.8396 - 100ms/epoch - 3ms/step\n",
            "Epoch 879/1000\n",
            "40/40 - 0s - loss: 2099.3787 - val_loss: 2027.3051 - 88ms/epoch - 2ms/step\n",
            "Epoch 880/1000\n",
            "40/40 - 0s - loss: 2099.4187 - val_loss: 2056.9199 - 90ms/epoch - 2ms/step\n",
            "Epoch 881/1000\n",
            "40/40 - 0s - loss: 2098.3569 - val_loss: 2008.9752 - 95ms/epoch - 2ms/step\n",
            "Epoch 882/1000\n",
            "40/40 - 0s - loss: 2082.5779 - val_loss: 1990.8406 - 86ms/epoch - 2ms/step\n",
            "Epoch 883/1000\n",
            "40/40 - 0s - loss: 2066.1790 - val_loss: 2011.9652 - 88ms/epoch - 2ms/step\n",
            "Epoch 884/1000\n",
            "40/40 - 0s - loss: 2070.5388 - val_loss: 1971.4756 - 96ms/epoch - 2ms/step\n",
            "Epoch 885/1000\n",
            "40/40 - 0s - loss: 2043.3132 - val_loss: 2002.8770 - 78ms/epoch - 2ms/step\n",
            "Epoch 886/1000\n",
            "40/40 - 0s - loss: 2063.9922 - val_loss: 2010.3882 - 86ms/epoch - 2ms/step\n",
            "Epoch 887/1000\n",
            "40/40 - 0s - loss: 2078.1150 - val_loss: 1999.0925 - 88ms/epoch - 2ms/step\n",
            "Epoch 888/1000\n",
            "40/40 - 0s - loss: 2093.6465 - val_loss: 2016.3976 - 90ms/epoch - 2ms/step\n",
            "Epoch 889/1000\n",
            "40/40 - 0s - loss: 2088.0396 - val_loss: 2064.4683 - 83ms/epoch - 2ms/step\n",
            "Epoch 890/1000\n",
            "40/40 - 0s - loss: 2104.2122 - val_loss: 2024.8138 - 81ms/epoch - 2ms/step\n",
            "Epoch 891/1000\n",
            "40/40 - 0s - loss: 2102.0488 - val_loss: 2024.4139 - 85ms/epoch - 2ms/step\n",
            "Epoch 892/1000\n",
            "40/40 - 0s - loss: 2089.3079 - val_loss: 2039.2498 - 81ms/epoch - 2ms/step\n",
            "Epoch 893/1000\n",
            "40/40 - 0s - loss: 2092.9443 - val_loss: 2086.4604 - 92ms/epoch - 2ms/step\n",
            "Epoch 894/1000\n",
            "40/40 - 0s - loss: 2123.6990 - val_loss: 2040.8693 - 90ms/epoch - 2ms/step\n",
            "Epoch 895/1000\n",
            "40/40 - 0s - loss: 2105.5811 - val_loss: 2051.2705 - 95ms/epoch - 2ms/step\n",
            "Epoch 896/1000\n",
            "40/40 - 0s - loss: 2090.5198 - val_loss: 2060.2151 - 88ms/epoch - 2ms/step\n",
            "Epoch 897/1000\n",
            "40/40 - 0s - loss: 2101.5874 - val_loss: 2037.8718 - 83ms/epoch - 2ms/step\n",
            "Epoch 898/1000\n",
            "40/40 - 0s - loss: 2097.3108 - val_loss: 2043.8999 - 78ms/epoch - 2ms/step\n",
            "Epoch 899/1000\n",
            "40/40 - 0s - loss: 2082.7979 - val_loss: 1989.7081 - 83ms/epoch - 2ms/step\n",
            "Epoch 900/1000\n",
            "40/40 - 0s - loss: 2074.0176 - val_loss: 1982.5057 - 89ms/epoch - 2ms/step\n",
            "Epoch 901/1000\n",
            "40/40 - 0s - loss: 2053.7646 - val_loss: 1989.6820 - 95ms/epoch - 2ms/step\n",
            "Epoch 902/1000\n",
            "40/40 - 0s - loss: 2055.8552 - val_loss: 2009.7628 - 100ms/epoch - 3ms/step\n",
            "Epoch 903/1000\n",
            "40/40 - 0s - loss: 2078.0601 - val_loss: 2025.3817 - 83ms/epoch - 2ms/step\n",
            "Epoch 904/1000\n",
            "40/40 - 0s - loss: 2083.5095 - val_loss: 2042.5819 - 82ms/epoch - 2ms/step\n",
            "Epoch 905/1000\n",
            "40/40 - 0s - loss: 2081.6091 - val_loss: 2017.9147 - 81ms/epoch - 2ms/step\n",
            "Epoch 906/1000\n",
            "40/40 - 0s - loss: 2071.8613 - val_loss: 2047.9221 - 91ms/epoch - 2ms/step\n",
            "Epoch 907/1000\n",
            "40/40 - 0s - loss: 2128.8560 - val_loss: 2076.3777 - 82ms/epoch - 2ms/step\n",
            "Epoch 908/1000\n",
            "40/40 - 0s - loss: 2090.3484 - val_loss: 1996.0000 - 80ms/epoch - 2ms/step\n",
            "Epoch 909/1000\n",
            "40/40 - 0s - loss: 2079.7314 - val_loss: 2029.8593 - 96ms/epoch - 2ms/step\n",
            "Epoch 910/1000\n",
            "40/40 - 0s - loss: 2076.9712 - val_loss: 1986.2758 - 85ms/epoch - 2ms/step\n",
            "Epoch 911/1000\n",
            "40/40 - 0s - loss: 2073.7485 - val_loss: 2046.6443 - 87ms/epoch - 2ms/step\n",
            "Epoch 912/1000\n",
            "40/40 - 0s - loss: 2097.9480 - val_loss: 1999.7488 - 87ms/epoch - 2ms/step\n",
            "Epoch 913/1000\n",
            "40/40 - 0s - loss: 2089.3049 - val_loss: 2032.1132 - 93ms/epoch - 2ms/step\n",
            "Epoch 914/1000\n",
            "40/40 - 0s - loss: 2078.3799 - val_loss: 2020.0812 - 83ms/epoch - 2ms/step\n",
            "Epoch 915/1000\n",
            "40/40 - 0s - loss: 2095.4106 - val_loss: 2001.3762 - 99ms/epoch - 2ms/step\n",
            "Epoch 916/1000\n",
            "40/40 - 0s - loss: 2072.4121 - val_loss: 2049.0469 - 97ms/epoch - 2ms/step\n",
            "Epoch 917/1000\n",
            "40/40 - 0s - loss: 2081.8154 - val_loss: 2006.2760 - 84ms/epoch - 2ms/step\n",
            "Epoch 918/1000\n",
            "40/40 - 0s - loss: 2081.1987 - val_loss: 2043.0442 - 86ms/epoch - 2ms/step\n",
            "Epoch 919/1000\n",
            "40/40 - 0s - loss: 2087.0146 - val_loss: 2001.2294 - 83ms/epoch - 2ms/step\n",
            "Epoch 920/1000\n",
            "40/40 - 0s - loss: 2082.8540 - val_loss: 2023.8715 - 89ms/epoch - 2ms/step\n",
            "Epoch 921/1000\n",
            "40/40 - 0s - loss: 2073.1870 - val_loss: 1979.9961 - 83ms/epoch - 2ms/step\n",
            "Epoch 922/1000\n",
            "40/40 - 0s - loss: 2076.0034 - val_loss: 1996.7742 - 94ms/epoch - 2ms/step\n",
            "Epoch 923/1000\n",
            "40/40 - 0s - loss: 2102.6399 - val_loss: 2023.4155 - 83ms/epoch - 2ms/step\n",
            "Epoch 924/1000\n",
            "40/40 - 0s - loss: 2080.1543 - val_loss: 2003.5126 - 93ms/epoch - 2ms/step\n",
            "Epoch 925/1000\n",
            "40/40 - 0s - loss: 2069.4617 - val_loss: 2011.8975 - 79ms/epoch - 2ms/step\n",
            "Epoch 926/1000\n",
            "40/40 - 0s - loss: 2076.7517 - val_loss: 1985.9788 - 86ms/epoch - 2ms/step\n",
            "Epoch 927/1000\n",
            "40/40 - 0s - loss: 2073.2959 - val_loss: 2026.3051 - 79ms/epoch - 2ms/step\n",
            "Epoch 928/1000\n",
            "40/40 - 0s - loss: 2089.5046 - val_loss: 1992.6494 - 91ms/epoch - 2ms/step\n",
            "Epoch 929/1000\n",
            "40/40 - 0s - loss: 2105.1160 - val_loss: 2089.4031 - 91ms/epoch - 2ms/step\n",
            "Epoch 930/1000\n",
            "40/40 - 0s - loss: 2139.6799 - val_loss: 2031.5764 - 89ms/epoch - 2ms/step\n",
            "Epoch 931/1000\n",
            "40/40 - 0s - loss: 2088.0554 - val_loss: 2000.8347 - 83ms/epoch - 2ms/step\n",
            "Epoch 932/1000\n",
            "40/40 - 0s - loss: 2105.4609 - val_loss: 2017.8386 - 85ms/epoch - 2ms/step\n",
            "Epoch 933/1000\n",
            "40/40 - 0s - loss: 2088.3149 - val_loss: 2068.7949 - 85ms/epoch - 2ms/step\n",
            "Epoch 934/1000\n",
            "40/40 - 0s - loss: 2082.6843 - val_loss: 1976.8933 - 91ms/epoch - 2ms/step\n",
            "Epoch 935/1000\n",
            "40/40 - 0s - loss: 2070.7798 - val_loss: 1988.9836 - 98ms/epoch - 2ms/step\n",
            "Epoch 936/1000\n",
            "40/40 - 0s - loss: 2107.4326 - val_loss: 2038.4288 - 85ms/epoch - 2ms/step\n",
            "Epoch 937/1000\n",
            "40/40 - 0s - loss: 2094.3904 - val_loss: 1984.8879 - 77ms/epoch - 2ms/step\n",
            "Epoch 938/1000\n",
            "40/40 - 0s - loss: 2071.6553 - val_loss: 2000.8907 - 94ms/epoch - 2ms/step\n",
            "Epoch 939/1000\n",
            "40/40 - 0s - loss: 2059.1340 - val_loss: 1969.0519 - 82ms/epoch - 2ms/step\n",
            "Epoch 940/1000\n",
            "40/40 - 0s - loss: 2055.7939 - val_loss: 2007.6140 - 80ms/epoch - 2ms/step\n",
            "Epoch 941/1000\n",
            "40/40 - 0s - loss: 2066.2053 - val_loss: 1985.4185 - 92ms/epoch - 2ms/step\n",
            "Epoch 942/1000\n",
            "40/40 - 0s - loss: 2058.6938 - val_loss: 1976.6942 - 84ms/epoch - 2ms/step\n",
            "Epoch 943/1000\n",
            "40/40 - 0s - loss: 2070.0847 - val_loss: 1990.2410 - 73ms/epoch - 2ms/step\n",
            "Epoch 944/1000\n",
            "40/40 - 0s - loss: 2059.9744 - val_loss: 2010.4171 - 99ms/epoch - 2ms/step\n",
            "Epoch 945/1000\n",
            "40/40 - 0s - loss: 2087.0857 - val_loss: 2008.7242 - 81ms/epoch - 2ms/step\n",
            "Epoch 946/1000\n",
            "40/40 - 0s - loss: 2118.7576 - val_loss: 2055.7524 - 81ms/epoch - 2ms/step\n",
            "Epoch 947/1000\n",
            "40/40 - 0s - loss: 2130.1548 - val_loss: 2061.4038 - 84ms/epoch - 2ms/step\n",
            "Epoch 948/1000\n",
            "40/40 - 0s - loss: 2103.6365 - val_loss: 2022.1195 - 85ms/epoch - 2ms/step\n",
            "Epoch 949/1000\n",
            "40/40 - 0s - loss: 2089.9592 - val_loss: 2011.9810 - 87ms/epoch - 2ms/step\n",
            "Epoch 950/1000\n",
            "40/40 - 0s - loss: 2081.8616 - val_loss: 2027.7815 - 76ms/epoch - 2ms/step\n",
            "Epoch 951/1000\n",
            "40/40 - 0s - loss: 2076.2871 - val_loss: 2023.4891 - 137ms/epoch - 3ms/step\n",
            "Epoch 952/1000\n",
            "40/40 - 0s - loss: 2096.8259 - val_loss: 2036.3846 - 107ms/epoch - 3ms/step\n",
            "Epoch 953/1000\n",
            "40/40 - 0s - loss: 2068.5439 - val_loss: 1957.7633 - 114ms/epoch - 3ms/step\n",
            "Epoch 954/1000\n",
            "40/40 - 0s - loss: 2057.8018 - val_loss: 1995.5210 - 84ms/epoch - 2ms/step\n",
            "Epoch 955/1000\n",
            "40/40 - 0s - loss: 2078.9470 - val_loss: 2011.7992 - 90ms/epoch - 2ms/step\n",
            "Epoch 956/1000\n",
            "40/40 - 0s - loss: 2097.2595 - val_loss: 2027.8611 - 98ms/epoch - 2ms/step\n",
            "Epoch 957/1000\n",
            "40/40 - 0s - loss: 2074.5100 - val_loss: 1999.6276 - 97ms/epoch - 2ms/step\n",
            "Epoch 958/1000\n",
            "40/40 - 0s - loss: 2055.3262 - val_loss: 1974.7095 - 87ms/epoch - 2ms/step\n",
            "Epoch 959/1000\n",
            "40/40 - 0s - loss: 2088.9561 - val_loss: 2013.4926 - 88ms/epoch - 2ms/step\n",
            "Epoch 960/1000\n",
            "40/40 - 0s - loss: 2073.2676 - val_loss: 2002.0305 - 88ms/epoch - 2ms/step\n",
            "Epoch 961/1000\n",
            "40/40 - 0s - loss: 2071.6250 - val_loss: 1979.2638 - 85ms/epoch - 2ms/step\n",
            "Epoch 962/1000\n",
            "40/40 - 0s - loss: 2047.5199 - val_loss: 1991.9427 - 103ms/epoch - 3ms/step\n",
            "Epoch 963/1000\n",
            "40/40 - 0s - loss: 2093.0137 - val_loss: 1999.1257 - 91ms/epoch - 2ms/step\n",
            "Epoch 964/1000\n",
            "40/40 - 0s - loss: 2091.0659 - val_loss: 1998.9100 - 85ms/epoch - 2ms/step\n",
            "Epoch 965/1000\n",
            "40/40 - 0s - loss: 2078.4202 - val_loss: 1986.2896 - 87ms/epoch - 2ms/step\n",
            "Epoch 966/1000\n",
            "40/40 - 0s - loss: 2088.8171 - val_loss: 2025.0405 - 86ms/epoch - 2ms/step\n",
            "Epoch 967/1000\n",
            "40/40 - 0s - loss: 2071.3962 - val_loss: 2032.8740 - 86ms/epoch - 2ms/step\n",
            "Epoch 968/1000\n",
            "40/40 - 0s - loss: 2079.4829 - val_loss: 2033.4489 - 88ms/epoch - 2ms/step\n",
            "Epoch 969/1000\n",
            "40/40 - 0s - loss: 2095.1509 - val_loss: 2037.4310 - 78ms/epoch - 2ms/step\n",
            "Epoch 970/1000\n",
            "40/40 - 0s - loss: 2081.1394 - val_loss: 2000.2303 - 97ms/epoch - 2ms/step\n",
            "Epoch 971/1000\n",
            "40/40 - 0s - loss: 2078.6880 - val_loss: 2005.1749 - 81ms/epoch - 2ms/step\n",
            "Epoch 972/1000\n",
            "40/40 - 0s - loss: 2075.5984 - val_loss: 2038.7384 - 80ms/epoch - 2ms/step\n",
            "Epoch 973/1000\n",
            "40/40 - 0s - loss: 2081.4011 - val_loss: 2039.7457 - 97ms/epoch - 2ms/step\n",
            "Epoch 974/1000\n",
            "40/40 - 0s - loss: 2103.6985 - val_loss: 2027.4790 - 92ms/epoch - 2ms/step\n",
            "Epoch 975/1000\n",
            "40/40 - 0s - loss: 2073.7078 - val_loss: 2005.1641 - 82ms/epoch - 2ms/step\n",
            "Epoch 976/1000\n",
            "40/40 - 0s - loss: 2056.0305 - val_loss: 1966.8701 - 93ms/epoch - 2ms/step\n",
            "Epoch 977/1000\n",
            "40/40 - 0s - loss: 2031.1354 - val_loss: 1979.5468 - 88ms/epoch - 2ms/step\n",
            "Epoch 978/1000\n",
            "40/40 - 0s - loss: 2049.7034 - val_loss: 1987.8164 - 86ms/epoch - 2ms/step\n",
            "Epoch 979/1000\n",
            "40/40 - 0s - loss: 2057.5735 - val_loss: 2006.5007 - 97ms/epoch - 2ms/step\n",
            "Epoch 980/1000\n",
            "40/40 - 0s - loss: 2063.8818 - val_loss: 1950.2648 - 88ms/epoch - 2ms/step\n",
            "Epoch 981/1000\n",
            "40/40 - 0s - loss: 2051.6736 - val_loss: 2003.6221 - 86ms/epoch - 2ms/step\n",
            "Epoch 982/1000\n",
            "40/40 - 0s - loss: 2043.9076 - val_loss: 1970.9020 - 89ms/epoch - 2ms/step\n",
            "Epoch 983/1000\n",
            "40/40 - 0s - loss: 2053.7012 - val_loss: 1981.3021 - 81ms/epoch - 2ms/step\n",
            "Epoch 984/1000\n",
            "40/40 - 0s - loss: 2065.0730 - val_loss: 2040.2661 - 80ms/epoch - 2ms/step\n",
            "Epoch 985/1000\n",
            "40/40 - 0s - loss: 2092.7781 - val_loss: 2019.2548 - 89ms/epoch - 2ms/step\n",
            "Epoch 986/1000\n",
            "40/40 - 0s - loss: 2092.8403 - val_loss: 1982.3986 - 83ms/epoch - 2ms/step\n",
            "Epoch 987/1000\n",
            "40/40 - 0s - loss: 2096.3877 - val_loss: 1984.8347 - 93ms/epoch - 2ms/step\n",
            "Epoch 988/1000\n",
            "40/40 - 0s - loss: 2086.0193 - val_loss: 2004.8325 - 91ms/epoch - 2ms/step\n",
            "Epoch 989/1000\n",
            "40/40 - 0s - loss: 2104.4268 - val_loss: 2055.3584 - 85ms/epoch - 2ms/step\n",
            "Epoch 990/1000\n",
            "40/40 - 0s - loss: 2076.4553 - val_loss: 2014.2886 - 91ms/epoch - 2ms/step\n",
            "Epoch 991/1000\n",
            "40/40 - 0s - loss: 2081.6582 - val_loss: 2003.0446 - 92ms/epoch - 2ms/step\n",
            "Epoch 992/1000\n",
            "40/40 - 0s - loss: 2072.4590 - val_loss: 2004.7216 - 77ms/epoch - 2ms/step\n",
            "Epoch 993/1000\n",
            "40/40 - 0s - loss: 2050.2979 - val_loss: 1966.5189 - 100ms/epoch - 2ms/step\n",
            "Epoch 994/1000\n",
            "40/40 - 0s - loss: 2046.3361 - val_loss: 2049.7148 - 81ms/epoch - 2ms/step\n",
            "Epoch 995/1000\n",
            "40/40 - 0s - loss: 2066.5530 - val_loss: 1988.3743 - 88ms/epoch - 2ms/step\n",
            "Epoch 996/1000\n",
            "40/40 - 0s - loss: 2045.0487 - val_loss: 1983.3031 - 87ms/epoch - 2ms/step\n",
            "Epoch 997/1000\n",
            "40/40 - 0s - loss: 2040.9005 - val_loss: 2002.5023 - 76ms/epoch - 2ms/step\n",
            "Epoch 998/1000\n",
            "40/40 - 0s - loss: 2046.8546 - val_loss: 1942.5879 - 84ms/epoch - 2ms/step\n",
            "Epoch 999/1000\n",
            "40/40 - 0s - loss: 2035.0444 - val_loss: 1952.7448 - 84ms/epoch - 2ms/step\n",
            "Epoch 1000/1000\n",
            "40/40 - 0s - loss: 2040.4681 - val_loss: 2013.6671 - 79ms/epoch - 2ms/step\n"
          ]
        }
      ],
      "source": [
        "# fit the autoencoder model to reconstruct input\n",
        "history = model_3.fit(x, x, epochs=1000, batch_size=16, verbose=2, validation_data=(x,x))\n",
        "# plot loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "vOD-vEYDWfGH"
      },
      "outputs": [],
      "source": [
        "model_final1 = Model(inputs=model_3.input, outputs=model_3.layers[1].output)\n",
        "model_final1.trainable = False\n",
        "\n",
        "model_final2 = Model(inputs=model_3.input, outputs=model_3.layers[3].output)\n",
        "model_final2.trainable = False\n",
        "\n",
        "model_final3 = Model(inputs=model_3.input, outputs=model_3.layers[5].output)\n",
        "model_final3.trainable = False\n",
        "\n",
        "model_final4 = Model(inputs=model_3.input, outputs=model_3.layers[7].output)\n",
        "model_final4.trainable = False\n",
        "\n",
        "models = [model_final1, model_final2, model_final3, model_final4]\n",
        "# models = [model_final1, model_final4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "Ro59dTSxWVXD"
      },
      "outputs": [],
      "source": [
        "month_data.iloc[0]\n",
        "# To extract only the relavant infromation from data frame for autoencoder\n",
        "def get_feature(data):\n",
        "  new_data = []\n",
        "  for i in range(len(data)):\n",
        "    d = data.iloc[i]\n",
        "    new_data.append(list(d[1:]))\n",
        "  # print(new_data)\n",
        "  return np.array(new_data)\n",
        "\n",
        "# to combine all the features together\n",
        "def predictor(month,model_final):\n",
        "  # chacking for each MONTH\n",
        "  month_path = slp_months[month] #0th in dex means january\n",
        "  # reading month data\n",
        "  month_data = pd.read_csv(month_path)\n",
        "  feature = get_feature(month_data)\n",
        "  feature = feature[0:73]  #Here i am using anly data from 1948 to 2000\n",
        "  pred = np.array(feature)\n",
        "  pred.shape\n",
        "  pred_m = model_final(pred)\n",
        "  pred_f = pred_m.numpy()\n",
        "  return pred_f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "f_wuJcQEWdN2"
      },
      "outputs": [],
      "source": [
        "def get_top_pred(top,pred_info):\n",
        "  k = 0\n",
        "  for m in months:\n",
        "    pred_f = pred_info\n",
        "  cor_list = []\n",
        "  for i in range(len(pred_f[0])):\n",
        "    score = []\n",
        "    \n",
        "    for j in range(0,53):\n",
        "      score.append(pred_f[j][i])\n",
        "    corr, _ = pearsonr(rain_fall_data[0:53],score)\n",
        "    cor_list.append(abs(corr))\n",
        "    # print(corr)\n",
        "  list1=list(enumerate(cor_list)) #I have taken cosine rank[0] beacuse it is inside the list\n",
        "  list2=sorted(list1, key=lambda x: x[1],reverse=True)\n",
        "  top_feature_index = []\n",
        "  #here i am getting the top features index\n",
        "  for i in range(top):\n",
        "    index = list2[i][0]\n",
        "    top_feature_index.append(index)\n",
        "  # Here i am getting all the top features\n",
        "  predictor = []\n",
        "  for i in range(len(pred_f)):\n",
        "    temp = []\n",
        "    for j in top_feature_index:\n",
        "      # print(i,\"  \",j)\n",
        "      feature = pred_f[i][j]\n",
        "      temp.append(feature)\n",
        "    predictor.append(temp)\n",
        "  # print(list2)\n",
        "  return predictor\n",
        "  # print(list1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "0IOVxthRWxQU"
      },
      "outputs": [],
      "source": [
        "# np.concatenate((a, b.T), axis=1)\n",
        "def get_predictors(months,top,models):\n",
        "  slp = predictor(months[0],models[0])\n",
        "  # print(slp.shape)\n",
        "  pred = get_top_pred(top, slp)\n",
        "  # print(len(pred[0]))\n",
        "  pred = np.array(pred)\n",
        "  for mod in models[1:]:\n",
        "    slp = predictor(months[0],mod)\n",
        "    b = get_top_pred(top, slp)\n",
        "    pred = np.concatenate((pred,b), axis=1)\n",
        "  if(len(months)>1):\n",
        "    for i in months[1:]:\n",
        "      for mod in models[0:]:\n",
        "        slp = predictor(i,mod)\n",
        "        b = get_top_pred(top, slp)\n",
        "        pred = np.concatenate((pred,b), axis=1)\n",
        "  return pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0XDDrW8Wzr1",
        "outputId": "3ba4c1b5-722a-40fe-820b-c1aee92566ea"
      },
      "outputs": [],
      "source": [
        "# pred = get_top_pred(4,pred_f)\n",
        "from sklearn import preprocessing\n",
        "months = [0,1,2]\n",
        "pred = get_predictors(months,5,models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxcATZMaXMGM",
        "outputId": "c652d0fb-c4f9-4326-fbf4-d46a7e16f81a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "depth  1      0.11824115570530734\n",
            "depth  1      0.11824115570530734\n",
            "depth  1      0.11824115570530734\n",
            "depth  1      0.11824115570530734\n",
            "depth  1      0.11824115570530734\n",
            "depth  1      0.11824115570530734\n",
            "depth  1      0.11824115570530734\n",
            "depth  1      0.11824115570530734\n",
            "depth  1      0.11824115570530734\n",
            "depth  1      0.11824115570530734\n",
            "depth  1      0.11824115570530734\n",
            "depth  1      0.11824115570530734\n",
            "depth  1      0.11824115570530734\n",
            "depth  1      0.11824115570530734\n",
            "depth  1      0.11824115570530734\n",
            "depth  1      0.11824115570530734\n",
            "depth  1      0.11824115570530734\n",
            "depth  1      0.11824115570530734\n",
            "depth  1      0.11824115570530734\n",
            "depth  1      0.11824115570530734\n",
            "depth  1      0.11824115570530734\n",
            "depth  1      0.11824115570530734\n",
            "depth  1      0.11824115570530734\n",
            "depth  1      0.11824115570530734\n",
            "depth  1      0.11824115570530734\n",
            "depth  1      0.11824115570530734\n",
            "depth  1      0.11824115570530734\n",
            "depth  1      0.11824115570530734\n",
            "depth  1      0.11824115570530734\n",
            "depth  1      0.11824115570530734\n",
            "depth  1      0.11824115570530734\n",
            "depth  1      0.11824115570530734\n",
            "depth  1      0.11824115570530734\n",
            "depth  1      0.11824115570530734\n",
            "depth  1      0.11824115570530734\n",
            "depth  1      0.11824115570530734\n",
            "depth  1      0.11824115570530734\n",
            "depth  1      0.11824115570530734\n",
            "depth  1      0.11824115570530734\n",
            "depth  1      0.11824115570530734\n",
            "depth  2      0.11824115570530734\n",
            "depth  2      0.11824115570530734\n",
            "depth  2      0.11824115570530734\n",
            "depth  2      0.11824115570530734\n",
            "depth  2      0.11824115570530734\n",
            "depth  2      0.11824115570530734\n",
            "depth  2      0.11824115570530734\n",
            "depth  2      0.11824115570530734\n",
            "depth  2      0.11824115570530734\n",
            "depth  2      0.11824115570530734\n",
            "depth  2      0.11824115570530734\n",
            "depth  2      0.11824115570530734\n",
            "depth  2      0.11824115570530734\n",
            "depth  2      0.11824115570530734\n",
            "depth  2      0.11824115570530734\n",
            "depth  2      0.11824115570530734\n",
            "depth  2      0.11824115570530734\n",
            "depth  2      0.11824115570530734\n",
            "depth  2      0.11824115570530734\n",
            "depth  2      0.11824115570530734\n",
            "depth  2      0.11824115570530734\n",
            "depth  2      0.11824115570530734\n",
            "depth  2      0.11824115570530734\n",
            "depth  2      0.11824115570530734\n",
            "depth  2      0.11824115570530734\n",
            "depth  2      0.11824115570530734\n",
            "depth  2      0.11824115570530734\n",
            "depth  2      0.11824115570530734\n",
            "depth  2      0.11824115570530734\n",
            "depth  2      0.11824115570530734\n",
            "depth  2      0.11824115570530734\n",
            "depth  2      0.11824115570530734\n",
            "depth  2      0.11824115570530734\n",
            "depth  2      0.11824115570530734\n",
            "depth  2      0.11824115570530734\n",
            "depth  2      0.11824115570530734\n",
            "depth  2      0.11824115570530734\n",
            "depth  2      0.11824115570530734\n",
            "depth  2      0.11824115570530734\n",
            "depth  2      0.11824115570530734\n",
            "depth  3      0.11824115570530734\n",
            "depth  3      0.11824115570530734\n",
            "depth  3      0.11824115570530734\n",
            "depth  3      0.11824115570530734\n",
            "depth  3      0.11824115570530734\n",
            "depth  3      0.11824115570530734\n",
            "depth  3      0.11824115570530734\n",
            "depth  3      0.11824115570530734\n",
            "depth  3      0.11824115570530734\n",
            "depth  3      0.11824115570530734\n",
            "depth  3      0.11824115570530734\n",
            "depth  3      0.11824115570530734\n",
            "depth  3      0.11824115570530734\n",
            "depth  3      0.11824115570530734\n",
            "depth  3      0.11824115570530734\n",
            "depth  3      0.11824115570530734\n",
            "depth  3      0.11824115570530734\n",
            "depth  3      0.11824115570530734\n",
            "depth  3      0.11824115570530734\n",
            "depth  3      0.11824115570530734\n",
            "depth  3      0.11824115570530734\n",
            "depth  3      0.11824115570530734\n",
            "depth  3      0.11824115570530734\n",
            "depth  3      0.11824115570530734\n",
            "depth  3      0.11824115570530734\n",
            "depth  3      0.11824115570530734\n",
            "depth  3      0.11824115570530734\n",
            "depth  3      0.11824115570530734\n",
            "depth  3      0.11824115570530734\n",
            "depth  3      0.11824115570530734\n",
            "depth  3      0.11824115570530734\n",
            "depth  3      0.11824115570530734\n",
            "depth  3      0.11824115570530734\n",
            "depth  3      0.11824115570530734\n",
            "depth  3      0.11824115570530734\n",
            "depth  3      0.11824115570530734\n",
            "depth  3      0.11824115570530734\n",
            "depth  3      0.11824115570530734\n",
            "depth  3      0.11824115570530734\n",
            "depth  3      0.11824115570530734\n",
            "depth  4      0.11824115570530734\n",
            "depth  4      0.11824115570530734\n",
            "depth  4      0.11824115570530734\n",
            "depth  4      0.11824115570530734\n",
            "depth  4      0.11824115570530734\n",
            "depth  4      0.11824115570530734\n",
            "depth  4      0.11824115570530734\n",
            "depth  4      0.11824115570530734\n",
            "depth  4      0.11824115570530734\n",
            "depth  4      0.11824115570530734\n",
            "depth  4      0.11824115570530734\n",
            "depth  4      0.11824115570530734\n",
            "depth  4      0.11824115570530734\n",
            "depth  4      0.11824115570530734\n",
            "depth  4      0.11824115570530734\n",
            "depth  4      0.11824115570530734\n",
            "depth  4      0.11824115570530734\n",
            "depth  4      0.11824115570530734\n",
            "depth  4      0.11824115570530734\n",
            "depth  4      0.11824115570530734\n",
            "depth  4      0.11824115570530734\n",
            "depth  4      0.11824115570530734\n",
            "depth  4      0.11824115570530734\n",
            "depth  4      0.11824115570530734\n",
            "depth  4      0.11824115570530734\n",
            "depth  4      0.11824115570530734\n",
            "depth  4      0.11824115570530734\n",
            "depth  4      0.11824115570530734\n",
            "depth  4      0.11824115570530734\n",
            "depth  4      0.11824115570530734\n",
            "depth  4      0.11824115570530734\n",
            "depth  4      0.11824115570530734\n",
            "depth  4      0.11824115570530734\n",
            "depth  4      0.11824115570530734\n",
            "depth  4      0.11824115570530734\n",
            "depth  4      0.11824115570530734\n",
            "depth  4      0.11824115570530734\n",
            "depth  4      0.11824115570530734\n",
            "depth  4      0.11824115570530734\n",
            "depth  4      0.11824115570530734\n",
            "depth  5      0.11824115570530734\n",
            "depth  5      0.11824115570530734\n",
            "depth  5      0.11824115570530734\n",
            "depth  5      0.11824115570530734\n",
            "depth  5      0.11824115570530734\n",
            "depth  5      0.11824115570530734\n",
            "depth  5      0.11824115570530734\n",
            "depth  5      0.11824115570530734\n",
            "depth  5      0.11824115570530734\n",
            "depth  5      0.11824115570530734\n",
            "depth  5      0.11824115570530734\n",
            "depth  5      0.11824115570530734\n",
            "depth  5      0.11824115570530734\n",
            "depth  5      0.11824115570530734\n",
            "depth  5      0.11824115570530734\n",
            "depth  5      0.11824115570530734\n",
            "depth  5      0.11824115570530734\n",
            "depth  5      0.11824115570530734\n",
            "depth  5      0.11824115570530734\n",
            "depth  5      0.11824115570530734\n",
            "depth  5      0.11824115570530734\n",
            "depth  5      0.11824115570530734\n",
            "depth  5      0.11824115570530734\n",
            "depth  5      0.11824115570530734\n",
            "depth  5      0.11824115570530734\n",
            "depth  5      0.11824115570530734\n",
            "depth  5      0.11824115570530734\n",
            "depth  5      0.11824115570530734\n",
            "depth  5      0.11824115570530734\n",
            "depth  5      0.11824115570530734\n",
            "depth  5      0.11824115570530734\n",
            "depth  5      0.11824115570530734\n",
            "depth  5      0.11824115570530734\n",
            "depth  5      0.11824115570530734\n",
            "depth  5      0.11824115570530734\n",
            "depth  5      0.11824115570530734\n",
            "depth  5      0.11824115570530734\n",
            "depth  5      0.11824115570530734\n",
            "depth  5      0.11824115570530734\n",
            "depth  5      0.11824115570530734\n",
            "0.11824115570530734     0.11824115570530734\n"
          ]
        }
      ],
      "source": [
        "#This gave 0.76 for month feb\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "tree = DecisionTreeRegressor(max_depth=4)\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "cor_all = []\n",
        "reg_f = SVR(kernel = 'rbf')\n",
        "for i in range(1,6):\n",
        "  for j in range(40):\n",
        "    reg = BaggingRegressor( n_estimators=i, random_state=j).fit(pred[:53], rain_fall_data[:53])\n",
        "    regr = RandomForestRegressor(max_depth=i, random_state=j)\n",
        "    reg_f.fit(pred[:53], rain_fall_data[:53])\n",
        "    preds = reg_f.predict(pred[53:67])\n",
        "    corr, _ = pearsonr(rain_fall_data[53:67],preds)\n",
        "    cor_all.append(corr)\n",
        "    print(\"depth \",i,\"    \",corr)\n",
        "print(min(cor_all),\"   \",max(cor_all))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "OoKQ4nnIXTVA"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVR\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "#w_start = window start, w_end = window end  \n",
        "def get_top_pred(top,pred_info,w_start,w_end):\n",
        "  k = 0\n",
        "  for m in months:\n",
        "    pred_f = pred_info\n",
        "  cor_list = []\n",
        "  for i in range(len(pred_f[0])):\n",
        "    score = []\n",
        "    \n",
        "    for j in range(w_start,w_end):\n",
        "      score.append(pred_f[j][i])\n",
        "    corr, _ = pearsonr(rain_fall_data[w_start:w_end],score)\n",
        "    cor_list.append(corr)\n",
        "    # print(corr)\n",
        "  list1=list(enumerate(cor_list)) #I have taken cosine rank[0] beacuse it is inside the list\n",
        "  list2=sorted(list1, key=lambda x: x[1],reverse=True)\n",
        "  top_feature_index = []\n",
        "  #here i am getting the top features index\n",
        "  for i in range(top):\n",
        "    index = list2[i][0]\n",
        "    top_feature_index.append(index)\n",
        "  # Here i am getting all the top features\n",
        "  predictor = []\n",
        "  for i in range(len(pred_f)):\n",
        "    temp = []\n",
        "    for j in top_feature_index:\n",
        "      # print(i,\"  \",j)\n",
        "      feature = pred_f[i][j]\n",
        "      temp.append(feature)\n",
        "    predictor.append(temp)\n",
        "  # print(list2)\n",
        "  return predictor\n",
        "  # print(list1)\n",
        "\n",
        "\n",
        "# np.concatenate((a, b.T), axis=1)\n",
        "def get_predictors(months,top,models,w_start,w_end):\n",
        "  slp = predictor(months[0],models[0])\n",
        "  # print(slp.shape)\n",
        "  pred = get_top_pred(top, slp, w_start,w_end)\n",
        "  # print(len(pred[0]))\n",
        "  pred = np.array(pred)\n",
        "  for mod in models[1:]:\n",
        "    slp = predictor(months[0],mod)\n",
        "    b = get_top_pred(top, slp,w_start,w_end)\n",
        "    pred = np.concatenate((pred,b), axis=1)\n",
        "  if(len(months)>1):\n",
        "    for i in months[1:]:\n",
        "      for mod in models[0:]:\n",
        "        slp = predictor(i,mod)\n",
        "        b = get_top_pred(top, slp, w_start,w_end)\n",
        "        pred = np.concatenate((pred,b), axis=1)\n",
        "  return pred\n",
        "\n",
        "def window_solution(months,top):\n",
        "  reg = SVR(kernel = 'rbf',C=1.0,epsilon=0.45)\n",
        "  # reg = make_pipeline(StandardScaler(), SVR(kernel = 'rbf',C=1.0, epsilon=0.2))\n",
        "  # months = [0]\n",
        "  k=0\n",
        "  cor_all = []\n",
        "  for window in range(10,53):\n",
        "    k+=1\n",
        "    score = []\n",
        "    pred = get_predictors(months,top,models,53-window,53)\n",
        "    for i in range(14):\n",
        "      start = 53-window\n",
        "      end = 53+1\n",
        "      # pred = get_predictors(months,2,models,start,end)\n",
        "      reg.fit(pred[53-window:53+i], rain_fall_data[53-window:53+i])\n",
        "      score.append(reg.predict([pred[53+i]])[0])\n",
        "    # print(score)\n",
        "    corr, _ = pearsonr(rain_fall_data[53:67],score)\n",
        "    # print(window, end = \"  \")\n",
        "    cor_all.append(corr)\n",
        "  return min(cor_all),max(cor_all)\n",
        "#This is by taking correlation after every iteraion of each predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryFHs-NOwN57",
        "outputId": "5e439aba-fd37-4633-907d-6576df58cfa5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Month combination =  [4]     top =  1    min and max -0.6145509303176121     -0.04234819578077553\n",
            "\n",
            " Month combination =  [4]     top =  2    min and max -0.6653018932894806     -0.03242262029891711\n",
            "\n",
            " Month combination =  [4]     top =  3    min and max -0.6819400765689035     0.07597199145087893\n",
            "\n",
            " Month combination =  [4]     top =  4    min and max -0.6688136142354242     0.08631435902315937\n",
            "\n",
            " Month combination =  [4]     top =  5    min and max -0.6606463932674604     0.11735883021048579\n",
            "\n",
            " Month combination =  [4]     top =  6    min and max -0.6318778564358503     0.018320217337998098\n",
            "\n",
            " Month combination =  [4]     top =  7    min and max -0.6088530643966521     -0.020236375092117904\n",
            "\n",
            " Month combination =  [4]     top =  8    min and max -0.6463629673777789     -0.04394220215473648\n"
          ]
        }
      ],
      "source": [
        "months_comb = [[4]]\n",
        "top = 9\n",
        "# models = [model_final3 ]\n",
        "for month in months_comb:\n",
        "  for i in range(1,top):\n",
        "    left, right = window_solution(month,i)\n",
        "    print()\n",
        "    print(\" Month combination = \",month,\"    top = \",i,\"   min and max\",left,\"   \",right)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "U80m_v4rs6M3",
        "outputId": "809ef9ef-c7d9-449c-b7d0-a1d6a981c624"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Month combination =  (0,)     top =  1    min and max -0.4610828250383536     0.233735253621946\n",
            "Minimum: -0.4610828250383536, (0,), 1    Maximum: 0.233735253621946, (0,), 1\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0,)     top =  2    min and max -0.4612781075876328     0.3750715255196271\n",
            "Minimum: -0.4612781075876328, (0,), 2    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0,)     top =  3    min and max -0.47736700990999653     0.2707072610301472\n",
            "Minimum: -0.47736700990999653, (0,), 3    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0,)     top =  4    min and max -0.4698917121087001     0.2319162199246318\n",
            "Minimum: -0.47736700990999653, (0,), 3    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0,)     top =  5    min and max -0.4661184461234537     0.1913098306969703\n",
            "Minimum: -0.47736700990999653, (0,), 3    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0,)     top =  6    min and max -0.48005099916708893     0.1534298566688161\n",
            "Minimum: -0.48005099916708893, (0,), 6    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0,)     top =  7    min and max -0.48903148093948434     0.1294513524343531\n",
            "Minimum: -0.48903148093948434, (0,), 7    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0,)     top =  8    min and max -0.503259093370502     0.1738626221866157\n",
            "Minimum: -0.503259093370502, (0,), 8    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (1,)     top =  1    min and max -0.6028294179388528     0.16712418228203407\n",
            "Minimum: -0.6028294179388528, (1,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (1,)     top =  2    min and max -0.6304510926964183     0.0527456162055908\n",
            "Minimum: -0.6304510926964183, (1,), 2    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (1,)     top =  3    min and max -0.6087335906012522     0.09818198156165288\n",
            "Minimum: -0.6304510926964183, (1,), 2    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (1,)     top =  4    min and max -0.6235034961554302     0.029022901884137003\n",
            "Minimum: -0.6304510926964183, (1,), 2    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (1,)     top =  5    min and max -0.6116522735748291     -0.03492668034542892\n",
            "Minimum: -0.6304510926964183, (1,), 2    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (1,)     top =  6    min and max -0.6215994152074555     -0.04850149195338295\n",
            "Minimum: -0.6304510926964183, (1,), 2    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (1,)     top =  7    min and max -0.6179672250439964     -0.012816217738759909\n",
            "Minimum: -0.6304510926964183, (1,), 2    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (1,)     top =  8    min and max -0.6113590484740771     -0.14334561874223997\n",
            "Minimum: -0.6304510926964183, (1,), 2    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (2,)     top =  1    min and max -0.5203440894843401     0.06270090743038832\n",
            "Minimum: -0.6304510926964183, (1,), 2    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (2,)     top =  2    min and max -0.5218273191698033     0.09335186502653275\n",
            "Minimum: -0.6304510926964183, (1,), 2    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (2,)     top =  3    min and max -0.5162140088480046     0.06426888131790301\n",
            "Minimum: -0.6304510926964183, (1,), 2    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (2,)     top =  4    min and max -0.5098453050906071     0.03576768743632436\n",
            "Minimum: -0.6304510926964183, (1,), 2    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (2,)     top =  5    min and max -0.513809760451085     0.0018110010712025087\n",
            "Minimum: -0.6304510926964183, (1,), 2    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (2,)     top =  6    min and max -0.5138146975768496     -0.07330249671668634\n",
            "Minimum: -0.6304510926964183, (1,), 2    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (2,)     top =  7    min and max -0.5203202506164997     -0.1148991689125482\n",
            "Minimum: -0.6304510926964183, (1,), 2    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (2,)     top =  8    min and max -0.5245501922372445     -0.17062481976856514\n",
            "Minimum: -0.6304510926964183, (1,), 2    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (3,)     top =  1    min and max -0.5521955304344408     -0.22926414540217213\n",
            "Minimum: -0.6304510926964183, (1,), 2    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (3,)     top =  2    min and max -0.5312686534968832     -0.016235397586342654\n",
            "Minimum: -0.6304510926964183, (1,), 2    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (3,)     top =  3    min and max -0.5333428848335151     -0.054596817309825914\n",
            "Minimum: -0.6304510926964183, (1,), 2    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (3,)     top =  4    min and max -0.5284997947437786     -0.10037391805715107\n",
            "Minimum: -0.6304510926964183, (1,), 2    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (3,)     top =  5    min and max -0.5283242651333571     -0.12039573527154177\n",
            "Minimum: -0.6304510926964183, (1,), 2    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (3,)     top =  6    min and max -0.5226343237296395     -0.10437372454384744\n",
            "Minimum: -0.6304510926964183, (1,), 2    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (3,)     top =  7    min and max -0.5229134792048045     -0.10970625441235257\n",
            "Minimum: -0.6304510926964183, (1,), 2    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (3,)     top =  8    min and max -0.5186734907921696     -0.1541746420744361\n",
            "Minimum: -0.6304510926964183, (1,), 2    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (4,)     top =  1    min and max -0.6145509303176121     -0.04234819578077553\n",
            "Minimum: -0.6304510926964183, (1,), 2    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (4,)     top =  2    min and max -0.6653018932894806     -0.03242262029891711\n",
            "Minimum: -0.6653018932894806, (4,), 2    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (4,)     top =  3    min and max -0.6819400765689035     0.07597199145087893\n",
            "Minimum: -0.6819400765689035, (4,), 3    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (4,)     top =  4    min and max -0.6688136142354242     0.08631435902315937\n",
            "Minimum: -0.6819400765689035, (4,), 3    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (4,)     top =  5    min and max -0.6606463932674604     0.11735883021048579\n",
            "Minimum: -0.6819400765689035, (4,), 3    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (4,)     top =  6    min and max -0.6318778564358503     0.018320217337998098\n",
            "Minimum: -0.6819400765689035, (4,), 3    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (4,)     top =  7    min and max -0.6088530643966521     -0.020236375092117904\n",
            "Minimum: -0.6819400765689035, (4,), 3    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (4,)     top =  8    min and max -0.6463629673777789     -0.04394220215473648\n",
            "Minimum: -0.6819400765689035, (4,), 3    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (5,)     top =  1    min and max -0.5331776295504875     0.11154986409472394\n",
            "Minimum: -0.6819400765689035, (4,), 3    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (5,)     top =  2    min and max -0.5514669947368744     0.039196644247089546\n",
            "Minimum: -0.6819400765689035, (4,), 3    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (5,)     top =  3    min and max -0.5520309508165752     0.012541261251177022\n",
            "Minimum: -0.6819400765689035, (4,), 3    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (5,)     top =  4    min and max -0.5514281345138657     0.0021855413914266125\n",
            "Minimum: -0.6819400765689035, (4,), 3    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (5,)     top =  5    min and max -0.5509200499419014     -0.06625584023956183\n",
            "Minimum: -0.6819400765689035, (4,), 3    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (5,)     top =  6    min and max -0.5599107895513852     -0.06679821083252538\n",
            "Minimum: -0.6819400765689035, (4,), 3    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (5,)     top =  7    min and max -0.5664573453146294     -0.07285797920726839\n",
            "Minimum: -0.6819400765689035, (4,), 3    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (5,)     top =  8    min and max -0.5767457255191809     -0.07355816162117008\n",
            "Minimum: -0.6819400765689035, (4,), 3    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (6,)     top =  1    min and max -0.7036560505138313     0.21111867387662436\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (6,)     top =  2    min and max -0.6006619968840676     0.14265318238059493\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (6,)     top =  3    min and max -0.5831275180723123     -0.021283051280124088\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (6,)     top =  4    min and max -0.6017598023410726     -0.030304596658276985\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (6,)     top =  5    min and max -0.5863101031330309     0.0033194811688729425\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (6,)     top =  6    min and max -0.5664708686428942     -0.009433776884555295\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (6,)     top =  7    min and max -0.5627781828939483     0.05713107406370746\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (6,)     top =  8    min and max -0.5590800344263297     0.010983774360180817\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (7,)     top =  1    min and max -0.570934579769013     0.2670967832461629\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (7,)     top =  2    min and max -0.5531080287712296     0.06550355949521755\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (7,)     top =  3    min and max -0.5177825835021291     0.1184031023101319\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (7,)     top =  4    min and max -0.5511802162111505     0.12546531526454582\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (7,)     top =  5    min and max -0.5605014317434692     0.09291005418247586\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (7,)     top =  6    min and max -0.5154710573096598     0.08286716272886652\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (7,)     top =  7    min and max -0.5276969072032661     0.019292570055357817\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (7,)     top =  8    min and max -0.5286199471939308     0.005855444783182284\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (8,)     top =  1    min and max -0.6360381083291499     -0.14568914932220983\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (8,)     top =  2    min and max -0.5813415084129673     -0.17943886582714672\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (8,)     top =  3    min and max -0.5952332556272776     -0.009181204895033719\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (8,)     top =  4    min and max -0.5870116109865899     0.0025688710202347795\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (8,)     top =  5    min and max -0.5641233701728444     -0.13819357648433594\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (8,)     top =  6    min and max -0.5590224853343437     -0.08478617945699558\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (8,)     top =  7    min and max -0.5575094642462048     -0.08189835840016807\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (8,)     top =  8    min and max -0.5642096356859154     -0.0575067673076789\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (9,)     top =  1    min and max -0.5807739759246155     0.2882252974342649\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (9,)     top =  2    min and max -0.596690824746137     0.28727271991928827\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (9,)     top =  3    min and max -0.6100005403389821     0.21100185116333878\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (9,)     top =  4    min and max -0.5981082445374315     0.1888814970425857\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (9,)     top =  5    min and max -0.5855285099834538     0.23593064087533383\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (9,)     top =  6    min and max -0.5835722596565859     0.24284245585623673\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (9,)     top =  7    min and max -0.5925163348639017     0.3527353481812442\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (9,)     top =  8    min and max -0.582213006581043     0.33566577217169535\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (10,)     top =  1    min and max -0.42615023105957156     0.3184533119861096\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (10,)     top =  2    min and max -0.5146971602961883     0.11738865231735825\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (10,)     top =  3    min and max -0.5541741346269135     0.09452636906375697\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (10,)     top =  4    min and max -0.5791856783330354     0.109008360206868\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (10,)     top =  5    min and max -0.5914565047379244     0.10185504112365872\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (10,)     top =  6    min and max -0.5858744882651643     0.04524490046376302\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (10,)     top =  7    min and max -0.5850234345274967     0.049025112314735296\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (10,)     top =  8    min and max -0.5865858673698223     0.15826598287359722\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (11,)     top =  1    min and max -0.5642504972429732     0.2548372382671127\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (11,)     top =  2    min and max -0.5162679365565762     0.01397554928890625\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (11,)     top =  3    min and max -0.5026939267938623     0.0001001935588413605\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (11,)     top =  4    min and max -0.4231325870354396     -0.00479611324692622\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (11,)     top =  5    min and max -0.4269427493988929     0.0063064046476043745\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (11,)     top =  6    min and max -0.44052067283136176     0.005394756202297943\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (11,)     top =  7    min and max -0.43352102293666817     0.020638128215272028\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (11,)     top =  8    min and max -0.43515620052096415     0.022460197924734124\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 1)     top =  1    min and max -0.5515072234970207     0.22337804520879395\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 1)     top =  2    min and max -0.5574904891666315     0.24974909870666528\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 1)     top =  3    min and max -0.5732166437767496     0.15621558687189177\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 1)     top =  4    min and max -0.5707515984594498     0.12949239856413888\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 1)     top =  5    min and max -0.5602293058399744     0.09161549604075601\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 1)     top =  6    min and max -0.5648708384267069     0.04391152675485535\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 1)     top =  7    min and max -0.5673597057984059     -0.018799738103366055\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 1)     top =  8    min and max -0.5716790357546143     -0.08396403318519113\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 2)     top =  1    min and max -0.497943885433319     0.12140414226654095\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 2)     top =  2    min and max -0.501640672293504     0.18669997665407173\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 2)     top =  3    min and max -0.5010524897369468     0.10700796587359665\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 2)     top =  4    min and max -0.5094141814228477     0.022743458175299817\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 2)     top =  5    min and max -0.5121277014268113     -0.05289543251612144\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 2)     top =  6    min and max -0.5286694399724088     -0.006243476435810713\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 2)     top =  7    min and max -0.5228852449010357     -0.0038705821430067427\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 2)     top =  8    min and max -0.5279510838178935     0.02512764083227695\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 3)     top =  1    min and max -0.4562634133229599     0.2176804185209629\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 3)     top =  2    min and max -0.4896233137774657     0.35818171498504947\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 3)     top =  3    min and max -0.5025758618186168     0.20428826249108145\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 3)     top =  4    min and max -0.4956315000733279     0.16238837623124686\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 3)     top =  5    min and max -0.4936102639503099     0.06283903396510336\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 3)     top =  6    min and max -0.5035433465505104     0.13826522264101396\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 3)     top =  7    min and max -0.5072023433758917     0.09002455079991101\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 3)     top =  8    min and max -0.5170985673979305     0.11716848067293359\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 4)     top =  1    min and max -0.5023588901622135     0.027394791440407854\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 4)     top =  2    min and max -0.5246696566787467     0.18578434165953978\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 4)     top =  3    min and max -0.5446058901176764     0.14577400457790757\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 4)     top =  4    min and max -0.544151820588126     0.0917468657572484\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 4)     top =  5    min and max -0.5450829292306957     0.05868320505767381\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 4)     top =  6    min and max -0.5474639121880421     0.08450263652408535\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 4)     top =  7    min and max -0.5360062579735451     0.06303246107892689\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 4)     top =  8    min and max -0.5334153107929359     0.0941608465277052\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 5)     top =  1    min and max -0.45222058680414867     0.29084998752739327\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 5)     top =  2    min and max -0.4786751256666599     0.2993748294096347\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 5)     top =  3    min and max -0.5140237951160541     0.1911415712737431\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 5)     top =  4    min and max -0.5089587687129424     0.10794968590758872\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 5)     top =  5    min and max -0.5019792413011922     0.1346917493999647\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 5)     top =  6    min and max -0.5139119674406608     0.2379169203814262\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 5)     top =  7    min and max -0.5186597452359416     0.19683577646440573\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 5)     top =  8    min and max -0.5245599934231537     0.18723327082119723\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 6)     top =  1    min and max -0.5221808281176211     0.1395164975984963\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 6)     top =  2    min and max -0.5195097431884343     0.16104923908629082\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 6)     top =  3    min and max -0.5368230918549447     0.027913134116027957\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 6)     top =  4    min and max -0.5319480485011886     0.07772970847920728\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 6)     top =  5    min and max -0.5333529094582349     0.05269806838570338\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 6)     top =  6    min and max -0.5317067258439409     0.1414076691684435\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 6)     top =  7    min and max -0.5304565261011503     0.10474181969267138\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 6)     top =  8    min and max -0.5399260905903082     0.09475094965494996\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 7)     top =  1    min and max -0.46266026351124245     0.3717164417423614\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 7)     top =  2    min and max -0.5028777854321557     0.20584021039214082\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 7)     top =  3    min and max -0.5239841289631666     0.15986433257195215\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 7)     top =  4    min and max -0.519322355272021     0.1535152822868843\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 7)     top =  5    min and max -0.5097986445500873     0.13669964890261757\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 7)     top =  6    min and max -0.5162542582154228     0.12973958327505924\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 7)     top =  7    min and max -0.5337216364820526     0.14882102478419434\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 7)     top =  8    min and max -0.5396913338989063     0.17193538504348332\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 8)     top =  1    min and max -0.4850748165228746     0.09769337867161992\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 8)     top =  2    min and max -0.4939007174701186     0.12707112969427284\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 8)     top =  3    min and max -0.5170321860455309     0.06558895671101296\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 8)     top =  4    min and max -0.5200647456728591     0.002971029821623221\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 8)     top =  5    min and max -0.5197794531887604     -0.038795879920973574\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 8)     top =  6    min and max -0.52477945501903     0.0342428266793929\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 8)     top =  7    min and max -0.5245991641053591     0.0027774414846011633\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 8)     top =  8    min and max -0.5336722977823984     0.023494542989151167\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 9)     top =  1    min and max -0.5589903515448156     0.25255734619715603\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 9)     top =  2    min and max -0.5273325749408523     0.2800621593266188\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 9)     top =  3    min and max -0.5278948798577813     0.23967928135333755\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 9)     top =  4    min and max -0.5456438588530822     0.11743535730462627\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 9)     top =  5    min and max -0.5407366145149604     0.09609521163548573\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 9)     top =  6    min and max -0.5457103037269208     0.10602634797397174\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 9)     top =  7    min and max -0.5461912940933812     0.1671423906811767\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 9)     top =  8    min and max -0.5506282203364833     0.16513477887772446\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 10)     top =  1    min and max -0.41513943762849537     0.15919644808876254\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 10)     top =  2    min and max -0.4931456240762062     0.12370708584013956\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 10)     top =  3    min and max -0.49825139536106267     0.05774253492191371\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 10)     top =  4    min and max -0.5050369874386241     0.1328257159048209\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 10)     top =  5    min and max -0.5137320174192902     0.13231854594727127\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 10)     top =  6    min and max -0.5255616510849377     0.1513598968688694\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 10)     top =  7    min and max -0.522516085381035     0.17103885166210164\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 10)     top =  8    min and max -0.5291682581467991     0.24724877501644807\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 11)     top =  1    min and max -0.49992135349858163     0.2264506080687905\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 11)     top =  2    min and max -0.4893840294354648     0.08094708191017651\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 11)     top =  3    min and max -0.48891109243667286     0.11280845187061503\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 11)     top =  4    min and max -0.4851571734100791     0.017174807619924938\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 11)     top =  5    min and max -0.4480008845575677     0.045815946747031516\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n",
            "\n",
            "\n",
            "Month combination =  (0, 11)     top =  6    min and max -0.46526360692398305     0.01846261635148258\n",
            "Minimum: -0.7036560505138313, (6,), 1    Maximum: 0.3750715255196271, (0,), 2\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from itertools import combinations\n",
        "months_comb = [j for i in range(12) for j in combinations(range(12), i+1)]\n",
        "top = 9\n",
        "models = [model_final1, model_final2, model_final3, model_final4]\n",
        "minimum, maximum = 1, -1\n",
        "for month in months_comb:\n",
        "  for i in range(1,top):\n",
        "    left, right = window_solution(month,i)\n",
        "    print(\"\\n\\nMonth combination = \",month,\"    top = \",i,\"   min and max\",left,\"   \",right)\n",
        "    if minimum > left:  minimum, min_month, min_top = left, month, i\n",
        "    if maximum < right: maximum, max_month, max_top = right, month, i\n",
        "    print(f'Minimum: {minimum}, {min_month}, {min_top}    Maximum: {maximum}, {max_month}, {max_top}\\n')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Copy of rainfall_encoder2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
